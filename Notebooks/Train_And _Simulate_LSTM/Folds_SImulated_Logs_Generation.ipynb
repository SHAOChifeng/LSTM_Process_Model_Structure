{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFONNTMiXKK-",
        "outputId": "77a6feb9-b796-47d3-e237-79e55374c9d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Bidirectional, LSTM, Activation, Dropout, Embedding, Input\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "import math\n",
        "\n",
        "import os.path\n",
        "\n",
        "def save_log(loglist, filename): #save a list of lists \n",
        "  df = pd.DataFrame.from_records(loglist)\n",
        "  df.to_csv(filename, index=False)\n",
        "\n",
        "def remove_nan(lists):\n",
        "  newlists = []\n",
        "  for tr in lists:\n",
        "    newlists.append([int(x) for x in tr if str(x) != 'nan'])\n",
        "  return(newlists)\n",
        "\n",
        "def import_log(filepath):\n",
        "  df = pd.read_csv(filepath)\n",
        "  return(remove_nan(df.values.tolist()))\n",
        "\n",
        "\n",
        "\n",
        "def number_to_one_hot_X(X, dict_size): #if we want \n",
        "  newX = []\n",
        "  for example in X:\n",
        "    new_ex = []\n",
        "    for i in range(len(example)):\n",
        "      onehot = [0]*dict_size #changed\n",
        "      if example[i] != 0:\n",
        "        onehot[example[i] - 1] = 1 #-1 because begin counting at 0\n",
        "      new_ex.append(onehot)\n",
        "    newX.append(new_ex)\n",
        "  return(np.array(newX))\n",
        "\n",
        "def create_XY_prefix(log, mappingsize, prefixlen):\n",
        "  X = []\n",
        "  Y = []\n",
        "  for i in range(0, len(log)):\n",
        "    for k in range(1, len(log[i])):\n",
        "      X.append(log[i][max(0, k-prefixlen):k]) #get the prefix of 'encoded' activities\n",
        "      y = [0] *(mappingsize)\n",
        "      y[int(log[i][k])-1] = 1\n",
        "      Y.append(y)        \n",
        "  X = keras.preprocessing.sequence.pad_sequences(X, maxlen=prefixlen, padding='pre')\n",
        "  X = number_to_one_hot_X(X, mappingsize)\n",
        "  return(np.array(X), np.array(Y))\n",
        "\n",
        "def get_startend(log): \n",
        "  return log[0][0], log[0][-1]\n",
        "\n",
        "def get_model(maxlen, num_chars, bidirec, n_layers, lstmsize, dropout, l1, l2):\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=(maxlen, num_chars))) #If you don't use an embedding layer input should be one-hot-encoded\n",
        "  if bidirec == False:   \n",
        "    model.add(LSTM(lstmsize,kernel_initializer='glorot_uniform',return_sequences=(n_layers != 1),kernel_regularizer=regularizers.l1_l2(l1,l2),\n",
        "                   recurrent_regularizer=regularizers.l1_l2(l1,l2),input_shape=(maxlen, num_chars)))\n",
        "    model.add(Dropout(dropout))\n",
        "    for i in range(1, n_layers):\n",
        "      return_sequences = (i+1 != n_layers)\n",
        "      model.add(LSTM(lstmsize,kernel_initializer='glorot_uniform',return_sequences=return_sequences,\n",
        "                     kernel_regularizer=regularizers.l1_l2(l1,l2),recurrent_regularizer=regularizers.l1_l2(l1,l2)))\n",
        "      model.add(Dropout(dropout))\n",
        "  else:\n",
        "    model.add(Bidirectional(LSTM(lstmsize,kernel_initializer='glorot_uniform',return_sequences=(n_layers != 1),kernel_regularizer=regularizers.l1_l2(l1,l2),\n",
        "                   recurrent_regularizer=regularizers.l1_l2(l1,l2),input_shape=(maxlen, num_chars))))\n",
        "    model.add(Dropout(dropout))\n",
        "    for i in range(1, n_layers):\n",
        "      return_sequences = (i+1 != n_layers)\n",
        "      model.add(Bidirectional(LSTM(lstmsize,kernel_initializer='glorot_uniform',return_sequences=return_sequences,\n",
        "                     kernel_regularizer=regularizers.l1_l2(l1,l2),recurrent_regularizer=regularizers.l1_l2(l1,l2))))\n",
        "      model.add(Dropout(dropout))\n",
        "  model.add(Dense(num_chars, kernel_initializer='glorot_uniform',activation='softmax'))\n",
        "  opt = Adam(learning_rate=0.005)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics='accuracy')\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(X_train, y_train,batch_size, maxlen, num_chars, bidirec, n_layers, lstmsize, dropout, l1, l2):\n",
        "  model = get_model(maxlen, num_chars, bidirec, n_layers, lstmsize, dropout, l1, l2)\n",
        "  model.summary()\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
        "  lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "  #train_model\n",
        "  history = model.fit(X_train, y_train, validation_split=0.2, callbacks=[early_stopping, lr_reducer], batch_size=batch_size, epochs=600, verbose=2)\n",
        "  return model\n",
        "\n",
        "def cut_end(log, endact):\n",
        "  logsize, tracesize = log.shape\n",
        "  print(log.shape)\n",
        "  newlog = []\n",
        "  for i in range(0, logsize):\n",
        "    trace = []\n",
        "    for j in range(0, tracesize):\n",
        "      if log[i][j] == endact:\n",
        "        trace.append(log[i][j])\n",
        "        break\n",
        "      else:\n",
        "        trace.append(log[i][j])\n",
        "    newlog.append(trace)\n",
        "  return(newlog)\n",
        "\n",
        "def normalize(probs): #normalize probabilities to sum to 1\n",
        "  examplesize, actsize = probs.shape\n",
        "  newy = []\n",
        "  for i in range(examplesize):\n",
        "    normalizer = 1 / float( sum(probs[i]) )\n",
        "    ynorm = [float(l) * normalizer for l in probs[i]]\n",
        "    newy.append(ynorm)\n",
        "  return newy\n",
        "\n",
        "\n",
        "def choose_act_all(all_y): #randomly choose an activity, stochastically\n",
        "  #p want a list of probabilities    \n",
        "  chosen_acts = []\n",
        "  for i in range(len(all_y)):\n",
        "      chosen_acts.append(np.random.choice(np.arange(0, len(all_y[i])), p=all_y[i])+1)  \n",
        "  return(chosen_acts)   # +1 because number encodig starts at 1 not 0\n",
        "\n",
        "def OHget_probabilities(rnnmodel, xlists,  nr_act, maxlen, prefixlen):\n",
        "  #assume xlist is a list with the x (prefix) untill now \n",
        "  all_x = keras.preprocessing.sequence.pad_sequences(xlists, maxlen=maxlen, padding=\"pre\")\n",
        "  all_x = all_x[:,-(prefixlen):]\n",
        "  all_x = number_to_one_hot_X(all_x, nr_act)\n",
        "  results = rnnmodel.predict(all_x)\n",
        "  return results\n",
        "\n",
        "def OHsimulate_log(RNNmodel, logsize, startact, endact, maxlen, mapping, prefixlen): #Use RNN to simulate log\n",
        "  log = np.zeros((logsize, maxlen+1), int)\n",
        "  for i in range(0, logsize): #start every trace with the start activity\n",
        "    log[i][0] = startact\n",
        "  print(log)\n",
        "  for j in range(1,maxlen+1): #check if 0 or 1 and ml or ml - 1 #we took 50 for with loops   \n",
        "    print(\"finding activity nr\", j+1)   \n",
        "    prefixes = np.array([log[i][0:j] for i in range(0, logsize)])\n",
        "    print(prefixes)\n",
        "    probs = OHget_probabilities(RNNmodel, prefixes, len(mapping), maxlen, prefixlen)\n",
        "    #we need to do this because otherwise probabilities sum over 1 \n",
        "    ynorm = normalize(probs) \n",
        "    nextacts = choose_act_all(ynorm) \n",
        "    for i in range(0, logsize):\n",
        "      log[i][j] = nextacts[i]\n",
        "  print(log)\n",
        "  corrected_log = cut_end(log, endact)      \n",
        "  return(corrected_log) \n",
        "\n",
        "\n",
        "def do_experiment(modelname, fold, full_prefix, opt_prefixlen, number_of_variants):\n",
        "  path = '/content/drive/MyDrive/FoldExperiment/'+modelname +\"/\"\n",
        "  full_log = remove_nan(import_log(path+\"Log_\"+modelname+\".csv\"))\n",
        "\n",
        "  maxlen = len(max(full_log,key=len))\n",
        "  #if we want to use the full prefix each time or not\n",
        "  if full_prefix == True:\n",
        "    prefixlen=maxlen - 1\n",
        "    print(\"prefix length:\", prefixlen)\n",
        "  else:\n",
        "    prefixlen=opt_prefixlen\n",
        "\n",
        "  #reload mapping\n",
        "  mappingfilename = path+\"Mapping_\"+modelname+\".txt\"\n",
        "  with open(mappingfilename) as f:\n",
        "    mapping = json.loads(f.read())\n",
        "\n",
        "  batch_size = 128\n",
        "\n",
        "\n",
        "  for i in range(0, fold):\n",
        "    SimLogPath = path + \"Simulated_Logs/Fold\"+str(fold)+\"/Sim\"+str(i)+\".csv\"\n",
        "    if os.path.exists(SimLogPath):\n",
        "      print(\"Already done: \", i)\n",
        "      continue\n",
        "    train_log = import_log(path + \"Training_Logs/Fold\"+str(fold)+\"/Train\"+str(i)+\".csv\")\n",
        "    start,end = get_startend(train_log)\n",
        "    X_train, y_train = create_XY_prefix(train_log, len(mapping), prefixlen)\n",
        "    model = train_model(X_train, y_train,batch_size, maxlen=prefixlen, num_chars=len(mapping), bidirec=True, n_layers=1, lstmsize=64, dropout=0.4, l1=0.001, l2=0.001)\n",
        "\n",
        "    simlog = OHsimulate_log(model, number_of_variants*100, start, end, maxlen-1, mapping, prefixlen)\n",
        "    \n",
        "    save_log(simlog, SimLogPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OatFJtL3X-8k",
        "outputId": "fca2b112-2551-46ec-dece-38b1fa0aa507"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prefix length: 20\n",
            "Already done:  0\n",
            "Already done:  1\n",
            "Already done:  2\n",
            "Already done:  3\n",
            "Already done:  4\n",
            "Already done:  5\n",
            "Already done:  6\n",
            "Already done:  7\n",
            "Already done:  8\n",
            "Already done:  9\n",
            "Already done:  10\n",
            "Already done:  11\n",
            "Already done:  12\n",
            "Already done:  13\n",
            "Already done:  14\n",
            "Already done:  15\n",
            "Already done:  16\n",
            "Already done:  17\n",
            "Already done:  18\n",
            "Already done:  19\n"
          ]
        }
      ],
      "source": [
        "do_experiment('Model3', 20, True, 0, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gidjpiBrYTER",
        "outputId": "b05b0dcd-6b62-4bb8-dabd-fcec0e3db740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prefix length: 20\n",
            "Already done:  0\n",
            "Already done:  1\n",
            "Already done:  2\n",
            "Already done:  3\n",
            "Already done:  4\n",
            "Already done:  5\n",
            "Already done:  6\n",
            "Already done:  7\n",
            "Already done:  8\n",
            "Already done:  9\n",
            "Already done:  10\n",
            "Already done:  11\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 128)              48128     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1502/1502 - 16s - loss: 0.6436 - accuracy: 0.7870 - val_loss: 0.3517 - val_accuracy: 0.8270 - lr: 0.0050 - 16s/epoch - 11ms/step\n",
            "Epoch 2/600\n",
            "1502/1502 - 9s - loss: 0.3863 - accuracy: 0.8229 - val_loss: 0.3218 - val_accuracy: 0.8319 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 3/600\n",
            "1502/1502 - 9s - loss: 0.4305 - accuracy: 0.8216 - val_loss: 0.3264 - val_accuracy: 0.8254 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 4/600\n",
            "1502/1502 - 9s - loss: 0.3559 - accuracy: 0.8249 - val_loss: 0.3181 - val_accuracy: 0.8281 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 5/600\n",
            "1502/1502 - 9s - loss: 0.4739 - accuracy: 0.8192 - val_loss: 0.3294 - val_accuracy: 0.8254 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 6/600\n",
            "1502/1502 - 9s - loss: 0.3227 - accuracy: 0.8267 - val_loss: 3.9293 - val_accuracy: 0.3422 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 7/600\n",
            "1502/1502 - 9s - loss: 0.4082 - accuracy: 0.8232 - val_loss: 0.3041 - val_accuracy: 0.8289 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 8/600\n",
            "1502/1502 - 9s - loss: 0.4146 - accuracy: 0.8226 - val_loss: 0.3230 - val_accuracy: 0.8317 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 9/600\n",
            "1502/1502 - 9s - loss: 0.3932 - accuracy: 0.8250 - val_loss: 0.3191 - val_accuracy: 0.8244 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 10/600\n",
            "1502/1502 - 9s - loss: 0.3170 - accuracy: 0.8265 - val_loss: 1.5010 - val_accuracy: 0.5798 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 11/600\n",
            "1502/1502 - 9s - loss: 0.3344 - accuracy: 0.8259 - val_loss: 0.2850 - val_accuracy: 0.8282 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 12/600\n",
            "1502/1502 - 9s - loss: 0.3199 - accuracy: 0.8252 - val_loss: 0.3544 - val_accuracy: 0.8283 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 13/600\n",
            "1502/1502 - 9s - loss: 0.3032 - accuracy: 0.8269 - val_loss: 0.2861 - val_accuracy: 0.8278 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 14/600\n",
            "1502/1502 - 9s - loss: 0.2988 - accuracy: 0.8272 - val_loss: 0.2807 - val_accuracy: 0.8284 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 15/600\n",
            "1502/1502 - 9s - loss: 0.3088 - accuracy: 0.8265 - val_loss: 0.2849 - val_accuracy: 0.8250 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 16/600\n",
            "1502/1502 - 9s - loss: 0.2852 - accuracy: 0.8273 - val_loss: 0.2784 - val_accuracy: 0.8317 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 17/600\n",
            "1502/1502 - 9s - loss: 0.3333 - accuracy: 0.8262 - val_loss: 0.2878 - val_accuracy: 0.8320 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 18/600\n",
            "1502/1502 - 9s - loss: 0.2839 - accuracy: 0.8279 - val_loss: 0.2810 - val_accuracy: 0.8246 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 19/600\n",
            "1502/1502 - 9s - loss: 0.3024 - accuracy: 0.8269 - val_loss: 0.2761 - val_accuracy: 0.8310 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 20/600\n",
            "1502/1502 - 9s - loss: 0.3251 - accuracy: 0.8251 - val_loss: 0.3560 - val_accuracy: 0.8281 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 21/600\n",
            "1502/1502 - 9s - loss: 0.2969 - accuracy: 0.8275 - val_loss: 0.2782 - val_accuracy: 0.8316 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 22/600\n",
            "1502/1502 - 9s - loss: 0.3117 - accuracy: 0.8260 - val_loss: 0.2837 - val_accuracy: 0.8319 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 23/600\n",
            "1502/1502 - 9s - loss: 0.2744 - accuracy: 0.8289 - val_loss: 0.2697 - val_accuracy: 0.8319 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 24/600\n",
            "1502/1502 - 9s - loss: 0.2708 - accuracy: 0.8287 - val_loss: 0.2678 - val_accuracy: 0.8318 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 25/600\n",
            "1502/1502 - 9s - loss: 0.2798 - accuracy: 0.8270 - val_loss: 0.2680 - val_accuracy: 0.8285 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 26/600\n",
            "1502/1502 - 9s - loss: 0.2692 - accuracy: 0.8294 - val_loss: 0.2661 - val_accuracy: 0.8318 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 27/600\n",
            "1502/1502 - 9s - loss: 0.2851 - accuracy: 0.8281 - val_loss: 0.2677 - val_accuracy: 0.8314 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 28/600\n",
            "1502/1502 - 9s - loss: 0.2688 - accuracy: 0.8285 - val_loss: 0.2666 - val_accuracy: 0.8247 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 29/600\n",
            "1502/1502 - 9s - loss: 0.2813 - accuracy: 0.8284 - val_loss: 0.2709 - val_accuracy: 0.8316 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 30/600\n",
            "1502/1502 - 9s - loss: 0.2651 - accuracy: 0.8299 - val_loss: 0.2623 - val_accuracy: 0.8320 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 31/600\n",
            "1502/1502 - 9s - loss: 0.2636 - accuracy: 0.8288 - val_loss: 0.2612 - val_accuracy: 0.8287 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 32/600\n",
            "1502/1502 - 9s - loss: 0.2630 - accuracy: 0.8305 - val_loss: 0.2607 - val_accuracy: 0.8319 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 33/600\n",
            "1502/1502 - 9s - loss: 0.2674 - accuracy: 0.8297 - val_loss: 0.2610 - val_accuracy: 0.8316 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 34/600\n",
            "1502/1502 - 9s - loss: 0.2620 - accuracy: 0.8307 - val_loss: 0.2601 - val_accuracy: 0.8317 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 35/600\n",
            "1502/1502 - 9s - loss: 0.2687 - accuracy: 0.8295 - val_loss: 0.2658 - val_accuracy: 0.8319 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 36/600\n",
            "1502/1502 - 9s - loss: 0.2628 - accuracy: 0.8291 - val_loss: 0.2609 - val_accuracy: 0.8247 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 37/600\n",
            "1502/1502 - 9s - loss: 0.2617 - accuracy: 0.8305 - val_loss: 0.2602 - val_accuracy: 0.8312 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 38/600\n",
            "1502/1502 - 9s - loss: 0.2592 - accuracy: 0.8300 - val_loss: 0.2580 - val_accuracy: 0.8310 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 39/600\n",
            "1502/1502 - 9s - loss: 0.2590 - accuracy: 0.8315 - val_loss: 0.2575 - val_accuracy: 0.8317 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 40/600\n",
            "1502/1502 - 9s - loss: 0.2588 - accuracy: 0.8305 - val_loss: 0.2574 - val_accuracy: 0.8321 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 41/600\n",
            "1502/1502 - 9s - loss: 0.2598 - accuracy: 0.8314 - val_loss: 0.2571 - val_accuracy: 0.8325 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 42/600\n",
            "1502/1502 - 9s - loss: 0.2582 - accuracy: 0.8315 - val_loss: 0.2571 - val_accuracy: 0.8324 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 43/600\n",
            "1502/1502 - 9s - loss: 0.2582 - accuracy: 0.8316 - val_loss: 0.2571 - val_accuracy: 0.8319 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 44/600\n",
            "1502/1502 - 9s - loss: 0.2594 - accuracy: 0.8304 - val_loss: 0.2572 - val_accuracy: 0.8314 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 45/600\n",
            "1502/1502 - 9s - loss: 0.2570 - accuracy: 0.8310 - val_loss: 0.2557 - val_accuracy: 0.8319 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 46/600\n",
            "1502/1502 - 9s - loss: 0.2568 - accuracy: 0.8317 - val_loss: 0.2555 - val_accuracy: 0.8319 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 47/600\n",
            "1502/1502 - 9s - loss: 0.2567 - accuracy: 0.8307 - val_loss: 0.2556 - val_accuracy: 0.8320 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 48/600\n",
            "1502/1502 - 9s - loss: 0.2566 - accuracy: 0.8305 - val_loss: 0.2554 - val_accuracy: 0.8312 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 49/600\n",
            "1502/1502 - 9s - loss: 0.2566 - accuracy: 0.8314 - val_loss: 0.2555 - val_accuracy: 0.8314 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 50/600\n",
            "1502/1502 - 9s - loss: 0.2564 - accuracy: 0.8318 - val_loss: 0.2553 - val_accuracy: 0.8317 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 51/600\n",
            "1502/1502 - 9s - loss: 0.2569 - accuracy: 0.8309 - val_loss: 0.2553 - val_accuracy: 0.8318 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 52/600\n",
            "1502/1502 - 9s - loss: 0.2557 - accuracy: 0.8313 - val_loss: 0.2546 - val_accuracy: 0.8315 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 53/600\n",
            "1502/1502 - 9s - loss: 0.2556 - accuracy: 0.8317 - val_loss: 0.2545 - val_accuracy: 0.8317 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 54/600\n",
            "1502/1502 - 9s - loss: 0.2556 - accuracy: 0.8315 - val_loss: 0.2545 - val_accuracy: 0.8317 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 55/600\n",
            "1502/1502 - 9s - loss: 0.2556 - accuracy: 0.8316 - val_loss: 0.2544 - val_accuracy: 0.8319 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 56/600\n",
            "1502/1502 - 9s - loss: 0.2555 - accuracy: 0.8320 - val_loss: 0.2544 - val_accuracy: 0.8320 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 57/600\n",
            "1502/1502 - 9s - loss: 0.2554 - accuracy: 0.8323 - val_loss: 0.2544 - val_accuracy: 0.8320 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 58/600\n",
            "1502/1502 - 9s - loss: 0.2550 - accuracy: 0.8322 - val_loss: 0.2540 - val_accuracy: 0.8317 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 59/600\n",
            "1502/1502 - 9s - loss: 0.2551 - accuracy: 0.8320 - val_loss: 0.2540 - val_accuracy: 0.8317 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 60/600\n",
            "1502/1502 - 9s - loss: 0.2550 - accuracy: 0.8318 - val_loss: 0.2540 - val_accuracy: 0.8320 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 61/600\n",
            "1502/1502 - 9s - loss: 0.2550 - accuracy: 0.8317 - val_loss: 0.2539 - val_accuracy: 0.8318 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 62/600\n",
            "1502/1502 - 9s - loss: 0.2550 - accuracy: 0.8312 - val_loss: 0.2540 - val_accuracy: 0.8320 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 63/600\n",
            "1502/1502 - 9s - loss: 0.2549 - accuracy: 0.8321 - val_loss: 0.2539 - val_accuracy: 0.8314 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 64/600\n",
            "1502/1502 - 9s - loss: 0.2549 - accuracy: 0.8315 - val_loss: 0.2539 - val_accuracy: 0.8318 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 65/600\n",
            "1502/1502 - 9s - loss: 0.2548 - accuracy: 0.8320 - val_loss: 0.2537 - val_accuracy: 0.8318 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 66/600\n",
            "1502/1502 - 9s - loss: 0.2547 - accuracy: 0.8315 - val_loss: 0.2537 - val_accuracy: 0.8327 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 67/600\n",
            "1502/1502 - 9s - loss: 0.2547 - accuracy: 0.8322 - val_loss: 0.2536 - val_accuracy: 0.8317 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 68/600\n",
            "1502/1502 - 9s - loss: 0.2547 - accuracy: 0.8314 - val_loss: 0.2536 - val_accuracy: 0.8317 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 69/600\n",
            "1502/1502 - 9s - loss: 0.2546 - accuracy: 0.8316 - val_loss: 0.2535 - val_accuracy: 0.8316 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 70/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8320 - val_loss: 0.2536 - val_accuracy: 0.8317 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 71/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8324 - val_loss: 0.2535 - val_accuracy: 0.8317 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 72/600\n",
            "1502/1502 - 9s - loss: 0.2546 - accuracy: 0.8317 - val_loss: 0.2535 - val_accuracy: 0.8317 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 73/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8318 - val_loss: 0.2535 - val_accuracy: 0.8317 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 74/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8321 - val_loss: 0.2535 - val_accuracy: 0.8317 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 75/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8319 - val_loss: 0.2535 - val_accuracy: 0.8317 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 76/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8330 - val_loss: 0.2535 - val_accuracy: 0.8317 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 77/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8323 - val_loss: 0.2535 - val_accuracy: 0.8317 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 78/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8317 - val_loss: 0.2535 - val_accuracy: 0.8317 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 79/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8319 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 80/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8321 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 81/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8316 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 82/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8323 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 83/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8326 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 84/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8318 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 85/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8320 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 86/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8325 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 87/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8318 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 88/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8317 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 89/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8315 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 90/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8312 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 91/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8315 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 92/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8319 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 93/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8318 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 94/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8318 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 95/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8316 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 96/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8329 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 97/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8322 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 98/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8316 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 99/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8323 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 100/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8321 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 101/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8316 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 102/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8318 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 103/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8315 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 104/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8317 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 105/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8323 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 106/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8319 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 107/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8316 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 108/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8313 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 109/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8320 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 110/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8321 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 111/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8320 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 112/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8310 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 113/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8326 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 5.9605e-10 - 9s/epoch - 6ms/step\n",
            "Epoch 114/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8323 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 5.9605e-10 - 9s/epoch - 6ms/step\n",
            "Epoch 115/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8317 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 5.9605e-10 - 9s/epoch - 6ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " ...\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " ...\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12  2]\n",
            " [28 27 10 ...  6 12 14]\n",
            " [28 27 10 ...  6 12 14]\n",
            " ...\n",
            " [28 27 10 ...  6 12 14]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 24]\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ... 14 11 24]\n",
            " ...\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ... 14 11 20]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 24 25  7]\n",
            " ...\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 20 25  7]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " ...\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ...  7 18 23]\n",
            " ...\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ...  7 18 13]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  1]\n",
            " ...\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 13 17  9]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " ...\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21  4]\n",
            " ...\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  8]\n",
            " ...\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " ...\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " ...\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_1 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1502/1502 - 14s - loss: 0.6129 - accuracy: 0.7948 - val_loss: 0.3419 - val_accuracy: 0.8247 - lr: 0.0050 - 14s/epoch - 9ms/step\n",
            "Epoch 2/600\n",
            "1502/1502 - 9s - loss: 0.4531 - accuracy: 0.8213 - val_loss: 0.3209 - val_accuracy: 0.8320 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 3/600\n",
            "1502/1502 - 9s - loss: 0.4148 - accuracy: 0.8233 - val_loss: 0.3201 - val_accuracy: 0.8213 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 4/600\n",
            "1502/1502 - 9s - loss: 0.3862 - accuracy: 0.8244 - val_loss: 0.3148 - val_accuracy: 0.8254 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 5/600\n",
            "1502/1502 - 9s - loss: 0.3500 - accuracy: 0.8246 - val_loss: 0.3078 - val_accuracy: 0.8316 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 6/600\n",
            "1502/1502 - 9s - loss: 0.3625 - accuracy: 0.8248 - val_loss: 0.3190 - val_accuracy: 0.8209 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 7/600\n",
            "1502/1502 - 10s - loss: 0.3754 - accuracy: 0.8253 - val_loss: 0.3113 - val_accuracy: 0.8307 - lr: 0.0050 - 10s/epoch - 6ms/step\n",
            "Epoch 8/600\n",
            "1502/1502 - 9s - loss: 0.3662 - accuracy: 0.8233 - val_loss: 0.5330 - val_accuracy: 0.8217 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 9/600\n",
            "1502/1502 - 9s - loss: 0.3191 - accuracy: 0.8287 - val_loss: 0.2944 - val_accuracy: 0.8279 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 10/600\n",
            "1502/1502 - 9s - loss: 0.3188 - accuracy: 0.8258 - val_loss: 0.2968 - val_accuracy: 0.8284 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 11/600\n",
            "1502/1502 - 9s - loss: 0.2903 - accuracy: 0.8283 - val_loss: 0.2831 - val_accuracy: 0.8324 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 12/600\n",
            "1502/1502 - 9s - loss: 0.3275 - accuracy: 0.8236 - val_loss: 0.3004 - val_accuracy: 0.8251 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 13/600\n",
            "1502/1502 - 9s - loss: 0.2941 - accuracy: 0.8288 - val_loss: 0.2901 - val_accuracy: 0.8313 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 14/600\n",
            "1502/1502 - 9s - loss: 0.3114 - accuracy: 0.8277 - val_loss: 0.2834 - val_accuracy: 0.8278 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 15/600\n",
            "1502/1502 - 9s - loss: 0.2771 - accuracy: 0.8303 - val_loss: 0.2726 - val_accuracy: 0.8321 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 16/600\n",
            "1502/1502 - 9s - loss: 0.2789 - accuracy: 0.8292 - val_loss: 0.2720 - val_accuracy: 0.8289 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 17/600\n",
            "1502/1502 - 9s - loss: 0.2866 - accuracy: 0.8281 - val_loss: 0.2724 - val_accuracy: 0.8283 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 18/600\n",
            "1502/1502 - 9s - loss: 0.2735 - accuracy: 0.8289 - val_loss: 0.2696 - val_accuracy: 0.8323 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 19/600\n",
            "1502/1502 - 9s - loss: 0.2909 - accuracy: 0.8293 - val_loss: 0.2739 - val_accuracy: 0.8325 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 20/600\n",
            "1502/1502 - 9s - loss: 0.2740 - accuracy: 0.8301 - val_loss: 0.2726 - val_accuracy: 0.8253 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 21/600\n",
            "1502/1502 - 9s - loss: 0.2882 - accuracy: 0.8271 - val_loss: 0.2712 - val_accuracy: 0.8253 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 22/600\n",
            "1502/1502 - 9s - loss: 0.2682 - accuracy: 0.8308 - val_loss: 0.2653 - val_accuracy: 0.8315 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 23/600\n",
            "1502/1502 - 9s - loss: 0.2672 - accuracy: 0.8310 - val_loss: 0.2646 - val_accuracy: 0.8315 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 24/600\n",
            "1502/1502 - 9s - loss: 0.2664 - accuracy: 0.8308 - val_loss: 0.2644 - val_accuracy: 0.8318 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 25/600\n",
            "1502/1502 - 9s - loss: 0.2706 - accuracy: 0.8298 - val_loss: 0.2638 - val_accuracy: 0.8279 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 26/600\n",
            "1502/1502 - 9s - loss: 0.2650 - accuracy: 0.8308 - val_loss: 0.2634 - val_accuracy: 0.8331 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 27/600\n",
            "1502/1502 - 9s - loss: 0.2688 - accuracy: 0.8300 - val_loss: 0.2633 - val_accuracy: 0.8320 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 28/600\n",
            "1502/1502 - 11s - loss: 0.2645 - accuracy: 0.8304 - val_loss: 0.2624 - val_accuracy: 0.8311 - lr: 6.2500e-04 - 11s/epoch - 7ms/step\n",
            "Epoch 29/600\n",
            "1502/1502 - 10s - loss: 0.2644 - accuracy: 0.8305 - val_loss: 0.2619 - val_accuracy: 0.8317 - lr: 6.2500e-04 - 10s/epoch - 6ms/step\n",
            "Epoch 30/600\n",
            "1502/1502 - 11s - loss: 0.2663 - accuracy: 0.8304 - val_loss: 0.2621 - val_accuracy: 0.8316 - lr: 6.2500e-04 - 11s/epoch - 7ms/step\n",
            "Epoch 31/600\n",
            "1502/1502 - 10s - loss: 0.2637 - accuracy: 0.8309 - val_loss: 0.2616 - val_accuracy: 0.8307 - lr: 6.2500e-04 - 10s/epoch - 6ms/step\n",
            "Epoch 32/600\n",
            "1502/1502 - 9s - loss: 0.2714 - accuracy: 0.8291 - val_loss: 0.2651 - val_accuracy: 0.8286 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 33/600\n",
            "1502/1502 - 11s - loss: 0.2638 - accuracy: 0.8302 - val_loss: 0.2609 - val_accuracy: 0.8308 - lr: 6.2500e-04 - 11s/epoch - 7ms/step\n",
            "Epoch 34/600\n",
            "1502/1502 - 11s - loss: 0.2627 - accuracy: 0.8303 - val_loss: 0.2608 - val_accuracy: 0.8315 - lr: 6.2500e-04 - 11s/epoch - 7ms/step\n",
            "Epoch 35/600\n",
            "1502/1502 - 11s - loss: 0.2671 - accuracy: 0.8297 - val_loss: 0.2788 - val_accuracy: 0.8315 - lr: 6.2500e-04 - 11s/epoch - 7ms/step\n",
            "Epoch 36/600\n",
            "1502/1502 - 10s - loss: 0.2651 - accuracy: 0.8303 - val_loss: 0.2614 - val_accuracy: 0.8269 - lr: 6.2500e-04 - 10s/epoch - 6ms/step\n",
            "Epoch 37/600\n",
            "1502/1502 - 9s - loss: 0.2627 - accuracy: 0.8311 - val_loss: 0.2615 - val_accuracy: 0.8314 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 38/600\n",
            "1502/1502 - 10s - loss: 0.2598 - accuracy: 0.8311 - val_loss: 0.2581 - val_accuracy: 0.8311 - lr: 3.1250e-04 - 10s/epoch - 6ms/step\n",
            "Epoch 39/600\n",
            "1502/1502 - 10s - loss: 0.2599 - accuracy: 0.8299 - val_loss: 0.2585 - val_accuracy: 0.8313 - lr: 3.1250e-04 - 10s/epoch - 6ms/step\n",
            "Epoch 40/600\n",
            "1502/1502 - 10s - loss: 0.2613 - accuracy: 0.8306 - val_loss: 0.2583 - val_accuracy: 0.8315 - lr: 3.1250e-04 - 10s/epoch - 6ms/step\n",
            "Epoch 41/600\n",
            "1502/1502 - 10s - loss: 0.2593 - accuracy: 0.8315 - val_loss: 0.2576 - val_accuracy: 0.8322 - lr: 3.1250e-04 - 10s/epoch - 6ms/step\n",
            "Epoch 42/600\n",
            "1502/1502 - 9s - loss: 0.2593 - accuracy: 0.8310 - val_loss: 0.2577 - val_accuracy: 0.8310 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 43/600\n",
            "1502/1502 - 9s - loss: 0.2596 - accuracy: 0.8309 - val_loss: 0.2576 - val_accuracy: 0.8318 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 44/600\n",
            "1502/1502 - 9s - loss: 0.2590 - accuracy: 0.8313 - val_loss: 0.2581 - val_accuracy: 0.8317 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 45/600\n",
            "1502/1502 - 11s - loss: 0.2574 - accuracy: 0.8316 - val_loss: 0.2559 - val_accuracy: 0.8314 - lr: 1.5625e-04 - 11s/epoch - 7ms/step\n",
            "Epoch 46/600\n",
            "1502/1502 - 9s - loss: 0.2574 - accuracy: 0.8311 - val_loss: 0.2564 - val_accuracy: 0.8317 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 47/600\n",
            "1502/1502 - 10s - loss: 0.2571 - accuracy: 0.8310 - val_loss: 0.2558 - val_accuracy: 0.8314 - lr: 1.5625e-04 - 10s/epoch - 6ms/step\n",
            "Epoch 48/600\n",
            "1502/1502 - 9s - loss: 0.2572 - accuracy: 0.8315 - val_loss: 0.2555 - val_accuracy: 0.8315 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 49/600\n",
            "1502/1502 - 9s - loss: 0.2569 - accuracy: 0.8315 - val_loss: 0.2555 - val_accuracy: 0.8306 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 50/600\n",
            "1502/1502 - 10s - loss: 0.2572 - accuracy: 0.8312 - val_loss: 0.2553 - val_accuracy: 0.8310 - lr: 1.5625e-04 - 10s/epoch - 6ms/step\n",
            "Epoch 51/600\n",
            "1502/1502 - 9s - loss: 0.2567 - accuracy: 0.8315 - val_loss: 0.2552 - val_accuracy: 0.8309 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 52/600\n",
            "1502/1502 - 11s - loss: 0.2567 - accuracy: 0.8313 - val_loss: 0.2555 - val_accuracy: 0.8309 - lr: 1.5625e-04 - 11s/epoch - 7ms/step\n",
            "Epoch 53/600\n",
            "1502/1502 - 11s - loss: 0.2568 - accuracy: 0.8314 - val_loss: 0.2556 - val_accuracy: 0.8319 - lr: 1.5625e-04 - 11s/epoch - 7ms/step\n",
            "Epoch 54/600\n",
            "1502/1502 - 10s - loss: 0.2567 - accuracy: 0.8309 - val_loss: 0.2550 - val_accuracy: 0.8320 - lr: 1.5625e-04 - 10s/epoch - 6ms/step\n",
            "Epoch 55/600\n",
            "1502/1502 - 10s - loss: 0.2565 - accuracy: 0.8317 - val_loss: 0.2549 - val_accuracy: 0.8313 - lr: 1.5625e-04 - 10s/epoch - 6ms/step\n",
            "Epoch 56/600\n",
            "1502/1502 - 9s - loss: 0.2566 - accuracy: 0.8323 - val_loss: 0.2548 - val_accuracy: 0.8320 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 57/600\n",
            "1502/1502 - 10s - loss: 0.2565 - accuracy: 0.8319 - val_loss: 0.2549 - val_accuracy: 0.8321 - lr: 1.5625e-04 - 10s/epoch - 6ms/step\n",
            "Epoch 58/600\n",
            "1502/1502 - 10s - loss: 0.2565 - accuracy: 0.8314 - val_loss: 0.2547 - val_accuracy: 0.8310 - lr: 1.5625e-04 - 10s/epoch - 6ms/step\n",
            "Epoch 59/600\n",
            "1502/1502 - 11s - loss: 0.2565 - accuracy: 0.8309 - val_loss: 0.2550 - val_accuracy: 0.8316 - lr: 1.5625e-04 - 11s/epoch - 7ms/step\n",
            "Epoch 60/600\n",
            "1502/1502 - 11s - loss: 0.2564 - accuracy: 0.8308 - val_loss: 0.2548 - val_accuracy: 0.8309 - lr: 1.5625e-04 - 11s/epoch - 7ms/step\n",
            "Epoch 61/600\n",
            "1502/1502 - 9s - loss: 0.2565 - accuracy: 0.8312 - val_loss: 0.2548 - val_accuracy: 0.8321 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 62/600\n",
            "1502/1502 - 9s - loss: 0.2553 - accuracy: 0.8326 - val_loss: 0.2539 - val_accuracy: 0.8315 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 63/600\n",
            "1502/1502 - 10s - loss: 0.2552 - accuracy: 0.8319 - val_loss: 0.2540 - val_accuracy: 0.8310 - lr: 7.8125e-05 - 10s/epoch - 6ms/step\n",
            "Epoch 64/600\n",
            "1502/1502 - 9s - loss: 0.2552 - accuracy: 0.8310 - val_loss: 0.2538 - val_accuracy: 0.8317 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 65/600\n",
            "1502/1502 - 11s - loss: 0.2551 - accuracy: 0.8317 - val_loss: 0.2537 - val_accuracy: 0.8308 - lr: 7.8125e-05 - 11s/epoch - 7ms/step\n",
            "Epoch 66/600\n",
            "1502/1502 - 9s - loss: 0.2550 - accuracy: 0.8319 - val_loss: 0.2537 - val_accuracy: 0.8324 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 67/600\n",
            "1502/1502 - 9s - loss: 0.2550 - accuracy: 0.8316 - val_loss: 0.2538 - val_accuracy: 0.8309 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 68/600\n",
            "1502/1502 - 10s - loss: 0.2547 - accuracy: 0.8312 - val_loss: 0.2535 - val_accuracy: 0.8313 - lr: 3.9062e-05 - 10s/epoch - 6ms/step\n",
            "Epoch 69/600\n",
            "1502/1502 - 10s - loss: 0.2546 - accuracy: 0.8320 - val_loss: 0.2533 - val_accuracy: 0.8325 - lr: 3.9062e-05 - 10s/epoch - 6ms/step\n",
            "Epoch 70/600\n",
            "1502/1502 - 10s - loss: 0.2546 - accuracy: 0.8314 - val_loss: 0.2533 - val_accuracy: 0.8321 - lr: 3.9062e-05 - 10s/epoch - 6ms/step\n",
            "Epoch 71/600\n",
            "1502/1502 - 10s - loss: 0.2546 - accuracy: 0.8310 - val_loss: 0.2534 - val_accuracy: 0.8327 - lr: 3.9062e-05 - 10s/epoch - 6ms/step\n",
            "Epoch 72/600\n",
            "1502/1502 - 10s - loss: 0.2545 - accuracy: 0.8320 - val_loss: 0.2533 - val_accuracy: 0.8328 - lr: 3.9062e-05 - 10s/epoch - 6ms/step\n",
            "Epoch 73/600\n",
            "1502/1502 - 9s - loss: 0.2543 - accuracy: 0.8323 - val_loss: 0.2532 - val_accuracy: 0.8311 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 74/600\n",
            "1502/1502 - 11s - loss: 0.2543 - accuracy: 0.8318 - val_loss: 0.2531 - val_accuracy: 0.8326 - lr: 1.9531e-05 - 11s/epoch - 7ms/step\n",
            "Epoch 75/600\n",
            "1502/1502 - 9s - loss: 0.2541 - accuracy: 0.8324 - val_loss: 0.2530 - val_accuracy: 0.8321 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 76/600\n",
            "1502/1502 - 10s - loss: 0.2542 - accuracy: 0.8321 - val_loss: 0.2531 - val_accuracy: 0.8314 - lr: 1.9531e-05 - 10s/epoch - 6ms/step\n",
            "Epoch 77/600\n",
            "1502/1502 - 10s - loss: 0.2542 - accuracy: 0.8324 - val_loss: 0.2531 - val_accuracy: 0.8318 - lr: 1.9531e-05 - 10s/epoch - 6ms/step\n",
            "Epoch 78/600\n",
            "1502/1502 - 9s - loss: 0.2542 - accuracy: 0.8318 - val_loss: 0.2530 - val_accuracy: 0.8321 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 79/600\n",
            "1502/1502 - 10s - loss: 0.2541 - accuracy: 0.8321 - val_loss: 0.2529 - val_accuracy: 0.8321 - lr: 9.7656e-06 - 10s/epoch - 6ms/step\n",
            "Epoch 80/600\n",
            "1502/1502 - 9s - loss: 0.2539 - accuracy: 0.8321 - val_loss: 0.2529 - val_accuracy: 0.8321 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 81/600\n",
            "1502/1502 - 9s - loss: 0.2541 - accuracy: 0.8322 - val_loss: 0.2530 - val_accuracy: 0.8321 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 82/600\n",
            "1502/1502 - 10s - loss: 0.2541 - accuracy: 0.8318 - val_loss: 0.2529 - val_accuracy: 0.8321 - lr: 9.7656e-06 - 10s/epoch - 6ms/step\n",
            "Epoch 83/600\n",
            "1502/1502 - 10s - loss: 0.2541 - accuracy: 0.8327 - val_loss: 0.2529 - val_accuracy: 0.8321 - lr: 9.7656e-06 - 10s/epoch - 6ms/step\n",
            "Epoch 84/600\n",
            "1502/1502 - 11s - loss: 0.2540 - accuracy: 0.8318 - val_loss: 0.2529 - val_accuracy: 0.8321 - lr: 4.8828e-06 - 11s/epoch - 7ms/step\n",
            "Epoch 85/600\n",
            "1502/1502 - 10s - loss: 0.2540 - accuracy: 0.8317 - val_loss: 0.2529 - val_accuracy: 0.8321 - lr: 4.8828e-06 - 10s/epoch - 6ms/step\n",
            "Epoch 86/600\n",
            "1502/1502 - 10s - loss: 0.2540 - accuracy: 0.8317 - val_loss: 0.2529 - val_accuracy: 0.8321 - lr: 4.8828e-06 - 10s/epoch - 6ms/step\n",
            "Epoch 87/600\n",
            "1502/1502 - 10s - loss: 0.2540 - accuracy: 0.8323 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 2.4414e-06 - 10s/epoch - 6ms/step\n",
            "Epoch 88/600\n",
            "1502/1502 - 10s - loss: 0.2539 - accuracy: 0.8328 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 2.4414e-06 - 10s/epoch - 7ms/step\n",
            "Epoch 89/600\n",
            "1502/1502 - 10s - loss: 0.2540 - accuracy: 0.8317 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 2.4414e-06 - 10s/epoch - 6ms/step\n",
            "Epoch 90/600\n",
            "1502/1502 - 10s - loss: 0.2539 - accuracy: 0.8331 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 1.2207e-06 - 10s/epoch - 6ms/step\n",
            "Epoch 91/600\n",
            "1502/1502 - 10s - loss: 0.2539 - accuracy: 0.8326 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 1.2207e-06 - 10s/epoch - 6ms/step\n",
            "Epoch 92/600\n",
            "1502/1502 - 10s - loss: 0.2540 - accuracy: 0.8324 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 1.2207e-06 - 10s/epoch - 6ms/step\n",
            "Epoch 93/600\n",
            "1502/1502 - 10s - loss: 0.2540 - accuracy: 0.8314 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 6.1035e-07 - 10s/epoch - 6ms/step\n",
            "Epoch 94/600\n",
            "1502/1502 - 10s - loss: 0.2540 - accuracy: 0.8328 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 6.1035e-07 - 10s/epoch - 6ms/step\n",
            "Epoch 95/600\n",
            "1502/1502 - 9s - loss: 0.2539 - accuracy: 0.8321 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 96/600\n",
            "1502/1502 - 9s - loss: 0.2539 - accuracy: 0.8328 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 97/600\n",
            "1502/1502 - 9s - loss: 0.2539 - accuracy: 0.8320 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 98/600\n",
            "1502/1502 - 9s - loss: 0.2539 - accuracy: 0.8321 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 99/600\n",
            "1502/1502 - 9s - loss: 0.2540 - accuracy: 0.8324 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 100/600\n",
            "1502/1502 - 9s - loss: 0.2539 - accuracy: 0.8326 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 101/600\n",
            "1502/1502 - 9s - loss: 0.2539 - accuracy: 0.8324 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 102/600\n",
            "1502/1502 - 9s - loss: 0.2540 - accuracy: 0.8321 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 103/600\n",
            "1502/1502 - 9s - loss: 0.2539 - accuracy: 0.8329 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 104/600\n",
            "1502/1502 - 9s - loss: 0.2539 - accuracy: 0.8323 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 105/600\n",
            "1502/1502 - 9s - loss: 0.2539 - accuracy: 0.8322 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 106/600\n",
            "1502/1502 - 9s - loss: 0.2538 - accuracy: 0.8326 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 107/600\n",
            "1502/1502 - 9s - loss: 0.2539 - accuracy: 0.8330 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 108/600\n",
            "1502/1502 - 10s - loss: 0.2540 - accuracy: 0.8322 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 3.8147e-08 - 10s/epoch - 6ms/step\n",
            "Epoch 109/600\n",
            "1502/1502 - 9s - loss: 0.2540 - accuracy: 0.8325 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 110/600\n",
            "1502/1502 - 11s - loss: 0.2539 - accuracy: 0.8317 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 1.9073e-08 - 11s/epoch - 7ms/step\n",
            "Epoch 111/600\n",
            "1502/1502 - 9s - loss: 0.2539 - accuracy: 0.8326 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 112/600\n",
            "1502/1502 - 9s - loss: 0.2540 - accuracy: 0.8320 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 113/600\n",
            "1502/1502 - 9s - loss: 0.2540 - accuracy: 0.8321 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 114/600\n",
            "1502/1502 - 10s - loss: 0.2539 - accuracy: 0.8319 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 9.5367e-09 - 10s/epoch - 6ms/step\n",
            "Epoch 115/600\n",
            "1502/1502 - 9s - loss: 0.2539 - accuracy: 0.8331 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 116/600\n",
            "1502/1502 - 10s - loss: 0.2539 - accuracy: 0.8318 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 4.7684e-09 - 10s/epoch - 6ms/step\n",
            "Epoch 117/600\n",
            "1502/1502 - 11s - loss: 0.2539 - accuracy: 0.8329 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 4.7684e-09 - 11s/epoch - 7ms/step\n",
            "Epoch 118/600\n",
            "1502/1502 - 10s - loss: 0.2540 - accuracy: 0.8322 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 2.3842e-09 - 10s/epoch - 6ms/step\n",
            "Epoch 119/600\n",
            "1502/1502 - 11s - loss: 0.2539 - accuracy: 0.8321 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 2.3842e-09 - 11s/epoch - 7ms/step\n",
            "Epoch 120/600\n",
            "1502/1502 - 9s - loss: 0.2540 - accuracy: 0.8322 - val_loss: 0.2528 - val_accuracy: 0.8321 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " ...\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " ...\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ...  6 12 14]\n",
            " ...\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ... 14 11 20]\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ... 14 11 20]\n",
            " ...\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 20]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 20 25 15]\n",
            " ...\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 20 25  7]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ...  7 18 23]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 23]\n",
            " ...\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ...  7 18 23]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  9]\n",
            " ...\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  9]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  9 21 22]\n",
            " ...\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ... 22  3  8]\n",
            " ...\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " ...\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " ...\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1502/1502 - 13s - loss: 0.6622 - accuracy: 0.7931 - val_loss: 0.3652 - val_accuracy: 0.8281 - lr: 0.0050 - 13s/epoch - 9ms/step\n",
            "Epoch 2/600\n",
            "1502/1502 - 9s - loss: 0.3908 - accuracy: 0.8247 - val_loss: 0.3265 - val_accuracy: 0.8253 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 3/600\n",
            "1502/1502 - 9s - loss: 0.3797 - accuracy: 0.8244 - val_loss: 0.3297 - val_accuracy: 0.8277 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 4/600\n",
            "1502/1502 - 10s - loss: 0.3733 - accuracy: 0.8238 - val_loss: 0.3322 - val_accuracy: 0.8289 - lr: 0.0050 - 10s/epoch - 6ms/step\n",
            "Epoch 5/600\n",
            "1502/1502 - 9s - loss: 0.4244 - accuracy: 0.8220 - val_loss: 0.5565 - val_accuracy: 0.8284 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 6/600\n",
            "1502/1502 - 9s - loss: 0.4138 - accuracy: 0.8267 - val_loss: 0.3757 - val_accuracy: 0.8280 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 7/600\n",
            "1502/1502 - 9s - loss: 0.3230 - accuracy: 0.8284 - val_loss: 0.2981 - val_accuracy: 0.8253 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 8/600\n",
            "1502/1502 - 9s - loss: 0.3798 - accuracy: 0.8191 - val_loss: 0.3170 - val_accuracy: 0.8216 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 9/600\n",
            "1502/1502 - 9s - loss: 0.3094 - accuracy: 0.8280 - val_loss: 0.2937 - val_accuracy: 0.8280 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 10/600\n",
            "1502/1502 - 9s - loss: 0.3354 - accuracy: 0.8262 - val_loss: 0.2932 - val_accuracy: 0.8281 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 11/600\n",
            "1502/1502 - 9s - loss: 0.2942 - accuracy: 0.8273 - val_loss: 0.3721 - val_accuracy: 0.8180 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 12/600\n",
            "1502/1502 - 9s - loss: 0.3142 - accuracy: 0.8258 - val_loss: 0.3053 - val_accuracy: 0.8268 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 13/600\n",
            "1502/1502 - 9s - loss: 0.2883 - accuracy: 0.8283 - val_loss: 0.2830 - val_accuracy: 0.8256 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 14/600\n",
            "1502/1502 - 9s - loss: 0.3237 - accuracy: 0.8255 - val_loss: 0.2939 - val_accuracy: 0.8284 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 15/600\n",
            "1502/1502 - 9s - loss: 0.3046 - accuracy: 0.8267 - val_loss: 0.3621 - val_accuracy: 0.8256 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 16/600\n",
            "1502/1502 - 9s - loss: 0.2920 - accuracy: 0.8278 - val_loss: 0.2794 - val_accuracy: 0.8279 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 17/600\n",
            "1502/1502 - 9s - loss: 0.3444 - accuracy: 0.8249 - val_loss: 0.3700 - val_accuracy: 0.8284 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 18/600\n",
            "1502/1502 - 9s - loss: 0.3049 - accuracy: 0.8277 - val_loss: 0.2837 - val_accuracy: 0.8311 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 19/600\n",
            "1502/1502 - 9s - loss: 0.2895 - accuracy: 0.8278 - val_loss: 0.2786 - val_accuracy: 0.8284 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 20/600\n",
            "1502/1502 - 9s - loss: 0.3192 - accuracy: 0.8270 - val_loss: 0.3026 - val_accuracy: 0.8287 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 21/600\n",
            "1502/1502 - 9s - loss: 0.2855 - accuracy: 0.8277 - val_loss: 0.2800 - val_accuracy: 0.8184 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 22/600\n",
            "1502/1502 - 9s - loss: 0.3421 - accuracy: 0.8241 - val_loss: 0.3146 - val_accuracy: 0.8247 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 23/600\n",
            "1502/1502 - 9s - loss: 0.2891 - accuracy: 0.8277 - val_loss: 0.2761 - val_accuracy: 0.8312 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 24/600\n",
            "1502/1502 - 11s - loss: 0.2772 - accuracy: 0.8285 - val_loss: 0.2731 - val_accuracy: 0.8316 - lr: 0.0012 - 11s/epoch - 7ms/step\n",
            "Epoch 25/600\n",
            "1502/1502 - 9s - loss: 0.2752 - accuracy: 0.8279 - val_loss: 0.2704 - val_accuracy: 0.8312 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 26/600\n",
            "1502/1502 - 9s - loss: 0.2819 - accuracy: 0.8295 - val_loss: 0.2931 - val_accuracy: 0.8279 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 27/600\n",
            "1502/1502 - 9s - loss: 0.2715 - accuracy: 0.8290 - val_loss: 0.2673 - val_accuracy: 0.8319 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 28/600\n",
            "1502/1502 - 9s - loss: 0.2712 - accuracy: 0.8283 - val_loss: 0.3890 - val_accuracy: 0.8041 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 29/600\n",
            "1502/1502 - 9s - loss: 0.2813 - accuracy: 0.8299 - val_loss: 0.2660 - val_accuracy: 0.8316 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 30/600\n",
            "1502/1502 - 9s - loss: 0.2728 - accuracy: 0.8293 - val_loss: 0.2689 - val_accuracy: 0.8313 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 31/600\n",
            "1502/1502 - 9s - loss: 0.2680 - accuracy: 0.8293 - val_loss: 0.2667 - val_accuracy: 0.8312 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 32/600\n",
            "1502/1502 - 9s - loss: 0.2855 - accuracy: 0.8282 - val_loss: 0.2689 - val_accuracy: 0.8320 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 33/600\n",
            "1502/1502 - 9s - loss: 0.2639 - accuracy: 0.8307 - val_loss: 0.2611 - val_accuracy: 0.8313 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 34/600\n",
            "1502/1502 - 9s - loss: 0.2629 - accuracy: 0.8302 - val_loss: 0.2621 - val_accuracy: 0.8317 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 35/600\n",
            "1502/1502 - 9s - loss: 0.2645 - accuracy: 0.8296 - val_loss: 0.2615 - val_accuracy: 0.8288 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 36/600\n",
            "1502/1502 - 9s - loss: 0.2632 - accuracy: 0.8299 - val_loss: 0.2607 - val_accuracy: 0.8312 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 37/600\n",
            "1502/1502 - 9s - loss: 0.2654 - accuracy: 0.8290 - val_loss: 0.2663 - val_accuracy: 0.8313 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 38/600\n",
            "1502/1502 - 9s - loss: 0.2627 - accuracy: 0.8311 - val_loss: 0.2600 - val_accuracy: 0.8317 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 39/600\n",
            "1502/1502 - 9s - loss: 0.2630 - accuracy: 0.8311 - val_loss: 0.2829 - val_accuracy: 0.8317 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 40/600\n",
            "1502/1502 - 9s - loss: 0.2626 - accuracy: 0.8297 - val_loss: 0.2606 - val_accuracy: 0.8282 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 41/600\n",
            "1502/1502 - 9s - loss: 0.2679 - accuracy: 0.8290 - val_loss: 0.2602 - val_accuracy: 0.8318 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 42/600\n",
            "1502/1502 - 9s - loss: 0.2591 - accuracy: 0.8302 - val_loss: 0.2573 - val_accuracy: 0.8316 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 43/600\n",
            "1502/1502 - 9s - loss: 0.2588 - accuracy: 0.8307 - val_loss: 0.2574 - val_accuracy: 0.8313 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 44/600\n",
            "1502/1502 - 9s - loss: 0.2589 - accuracy: 0.8302 - val_loss: 0.2573 - val_accuracy: 0.8283 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 45/600\n",
            "1502/1502 - 9s - loss: 0.2591 - accuracy: 0.8308 - val_loss: 0.2579 - val_accuracy: 0.8289 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 46/600\n",
            "1502/1502 - 9s - loss: 0.2573 - accuracy: 0.8317 - val_loss: 0.2561 - val_accuracy: 0.8316 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 47/600\n",
            "1502/1502 - 9s - loss: 0.2572 - accuracy: 0.8311 - val_loss: 0.2557 - val_accuracy: 0.8320 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 48/600\n",
            "1502/1502 - 9s - loss: 0.2571 - accuracy: 0.8314 - val_loss: 0.2557 - val_accuracy: 0.8319 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 49/600\n",
            "1502/1502 - 9s - loss: 0.2571 - accuracy: 0.8311 - val_loss: 0.2559 - val_accuracy: 0.8318 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 50/600\n",
            "1502/1502 - 9s - loss: 0.2569 - accuracy: 0.8312 - val_loss: 0.2555 - val_accuracy: 0.8324 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 51/600\n",
            "1502/1502 - 9s - loss: 0.2568 - accuracy: 0.8309 - val_loss: 0.2553 - val_accuracy: 0.8316 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 52/600\n",
            "1502/1502 - 9s - loss: 0.2569 - accuracy: 0.8311 - val_loss: 0.2555 - val_accuracy: 0.8317 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 53/600\n",
            "1502/1502 - 9s - loss: 0.2567 - accuracy: 0.8308 - val_loss: 0.2552 - val_accuracy: 0.8323 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 54/600\n",
            "1502/1502 - 9s - loss: 0.2567 - accuracy: 0.8310 - val_loss: 0.2554 - val_accuracy: 0.8319 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 55/600\n",
            "1502/1502 - 9s - loss: 0.2557 - accuracy: 0.8319 - val_loss: 0.2547 - val_accuracy: 0.8318 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 56/600\n",
            "1502/1502 - 9s - loss: 0.2557 - accuracy: 0.8311 - val_loss: 0.2548 - val_accuracy: 0.8316 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 57/600\n",
            "1502/1502 - 9s - loss: 0.2556 - accuracy: 0.8321 - val_loss: 0.2544 - val_accuracy: 0.8323 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 58/600\n",
            "1502/1502 - 9s - loss: 0.2556 - accuracy: 0.8311 - val_loss: 0.2545 - val_accuracy: 0.8310 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 59/600\n",
            "1502/1502 - 9s - loss: 0.2556 - accuracy: 0.8312 - val_loss: 0.2544 - val_accuracy: 0.8318 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 60/600\n",
            "1502/1502 - 9s - loss: 0.2555 - accuracy: 0.8315 - val_loss: 0.2545 - val_accuracy: 0.8306 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 61/600\n",
            "1502/1502 - 9s - loss: 0.2551 - accuracy: 0.8318 - val_loss: 0.2538 - val_accuracy: 0.8323 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 62/600\n",
            "1502/1502 - 9s - loss: 0.2551 - accuracy: 0.8314 - val_loss: 0.2538 - val_accuracy: 0.8312 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 63/600\n",
            "1502/1502 - 9s - loss: 0.2551 - accuracy: 0.8306 - val_loss: 0.2538 - val_accuracy: 0.8318 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 64/600\n",
            "1502/1502 - 9s - loss: 0.2550 - accuracy: 0.8311 - val_loss: 0.2538 - val_accuracy: 0.8323 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 65/600\n",
            "1502/1502 - 9s - loss: 0.2547 - accuracy: 0.8323 - val_loss: 0.2536 - val_accuracy: 0.8316 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 66/600\n",
            "1502/1502 - 9s - loss: 0.2547 - accuracy: 0.8324 - val_loss: 0.2536 - val_accuracy: 0.8323 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 67/600\n",
            "1502/1502 - 9s - loss: 0.2548 - accuracy: 0.8314 - val_loss: 0.2536 - val_accuracy: 0.8315 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 68/600\n",
            "1502/1502 - 9s - loss: 0.2547 - accuracy: 0.8312 - val_loss: 0.2535 - val_accuracy: 0.8320 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 69/600\n",
            "1502/1502 - 9s - loss: 0.2546 - accuracy: 0.8316 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 70/600\n",
            "1502/1502 - 10s - loss: 0.2546 - accuracy: 0.8317 - val_loss: 0.2534 - val_accuracy: 0.8320 - lr: 9.7656e-06 - 10s/epoch - 6ms/step\n",
            "Epoch 71/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8316 - val_loss: 0.2534 - val_accuracy: 0.8312 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 72/600\n",
            "1502/1502 - 9s - loss: 0.2546 - accuracy: 0.8314 - val_loss: 0.2534 - val_accuracy: 0.8317 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 73/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8320 - val_loss: 0.2533 - val_accuracy: 0.8317 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 74/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8321 - val_loss: 0.2533 - val_accuracy: 0.8317 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 75/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8319 - val_loss: 0.2533 - val_accuracy: 0.8320 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 76/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8314 - val_loss: 0.2533 - val_accuracy: 0.8312 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 77/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8315 - val_loss: 0.2533 - val_accuracy: 0.8317 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 78/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8322 - val_loss: 0.2533 - val_accuracy: 0.8316 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 79/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8316 - val_loss: 0.2533 - val_accuracy: 0.8317 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 80/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8315 - val_loss: 0.2533 - val_accuracy: 0.8311 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 81/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8323 - val_loss: 0.2533 - val_accuracy: 0.8317 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 82/600\n",
            "1502/1502 - 10s - loss: 0.2544 - accuracy: 0.8317 - val_loss: 0.2533 - val_accuracy: 0.8311 - lr: 1.2207e-06 - 10s/epoch - 6ms/step\n",
            "Epoch 83/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8318 - val_loss: 0.2533 - val_accuracy: 0.8311 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 84/600\n",
            "1502/1502 - 11s - loss: 0.2544 - accuracy: 0.8322 - val_loss: 0.2533 - val_accuracy: 0.8311 - lr: 6.1035e-07 - 11s/epoch - 7ms/step\n",
            "Epoch 85/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8316 - val_loss: 0.2533 - val_accuracy: 0.8317 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 86/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8324 - val_loss: 0.2533 - val_accuracy: 0.8317 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 87/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8323 - val_loss: 0.2533 - val_accuracy: 0.8317 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 88/600\n",
            "1502/1502 - 9s - loss: 0.2543 - accuracy: 0.8321 - val_loss: 0.2533 - val_accuracy: 0.8317 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 89/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8318 - val_loss: 0.2533 - val_accuracy: 0.8317 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 90/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8314 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 91/600\n",
            "1502/1502 - 9s - loss: 0.2543 - accuracy: 0.8325 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 92/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8318 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 93/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8317 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 94/600\n",
            "1502/1502 - 11s - loss: 0.2544 - accuracy: 0.8321 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 7.6294e-08 - 11s/epoch - 7ms/step\n",
            "Epoch 95/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8317 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 96/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8323 - val_loss: 0.2532 - val_accuracy: 0.8316 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 97/600\n",
            "1502/1502 - 9s - loss: 0.2543 - accuracy: 0.8324 - val_loss: 0.2532 - val_accuracy: 0.8316 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 98/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8314 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 99/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8322 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 100/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8318 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 101/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8319 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 102/600\n",
            "1502/1502 - 9s - loss: 0.2543 - accuracy: 0.8316 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 103/600\n",
            "1502/1502 - 10s - loss: 0.2545 - accuracy: 0.8310 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 9.5367e-09 - 10s/epoch - 6ms/step\n",
            "Epoch 104/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8319 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 105/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8313 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 106/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8321 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 107/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8318 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 108/600\n",
            "1502/1502 - 9s - loss: 0.2543 - accuracy: 0.8323 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 109/600\n",
            "1502/1502 - 9s - loss: 0.2544 - accuracy: 0.8314 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 110/600\n",
            "1502/1502 - 9s - loss: 0.2545 - accuracy: 0.8317 - val_loss: 0.2532 - val_accuracy: 0.8317 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " ...\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " ...\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12 14]\n",
            " ...\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ...  6 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 20]\n",
            " ...\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ... 14 11 24]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25 15]\n",
            " ...\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 24 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ...  7 18 23]\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ... 15 18 13]\n",
            " ...\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ... 15 18 23]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " ...\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 13 17  1]\n",
            " ...\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 23 17  1]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " ...\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  1 21  4]\n",
            " ...\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  1 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ... 22  3  8]\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ...  4  3  8]\n",
            " ...\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  8]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " ...\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]]\n",
            "[[28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " ...\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]]\n",
            "(12800, 21)\n"
          ]
        }
      ],
      "source": [
        "do_experiment('Model3', 15, True, 0, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rEq_c0v-YTHO",
        "outputId": "b8b5b136-502c-4c69-d01a-ada353971206"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prefix length: 20\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_3 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1436/1436 - 12s - loss: 0.7303 - accuracy: 0.7888 - val_loss: 0.3725 - val_accuracy: 0.8322 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 2/600\n",
            "1436/1436 - 9s - loss: 0.3824 - accuracy: 0.8285 - val_loss: 0.3301 - val_accuracy: 0.8293 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 3/600\n",
            "1436/1436 - 9s - loss: 0.3817 - accuracy: 0.8284 - val_loss: 0.3208 - val_accuracy: 0.8329 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 4/600\n",
            "1436/1436 - 9s - loss: 0.4107 - accuracy: 0.8273 - val_loss: 0.3123 - val_accuracy: 0.8346 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 5/600\n",
            "1436/1436 - 9s - loss: 0.4198 - accuracy: 0.8247 - val_loss: 0.3342 - val_accuracy: 0.8338 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 6/600\n",
            "1436/1436 - 9s - loss: 0.3818 - accuracy: 0.8282 - val_loss: 0.3116 - val_accuracy: 0.8295 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 7/600\n",
            "1436/1436 - 9s - loss: 0.4028 - accuracy: 0.8264 - val_loss: 0.3161 - val_accuracy: 0.8347 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 8/600\n",
            "1436/1436 - 9s - loss: 0.3454 - accuracy: 0.8301 - val_loss: 0.3060 - val_accuracy: 0.8319 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 9/600\n",
            "1436/1436 - 9s - loss: 0.3671 - accuracy: 0.8287 - val_loss: 0.3058 - val_accuracy: 0.8357 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 10/600\n",
            "1436/1436 - 9s - loss: 0.3498 - accuracy: 0.8265 - val_loss: 0.9752 - val_accuracy: 0.8243 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 11/600\n",
            "1436/1436 - 9s - loss: 0.3702 - accuracy: 0.8294 - val_loss: 0.3126 - val_accuracy: 0.8299 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 12/600\n",
            "1436/1436 - 9s - loss: 0.3925 - accuracy: 0.8271 - val_loss: 0.3128 - val_accuracy: 0.8340 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 13/600\n",
            "1436/1436 - 9s - loss: 0.2946 - accuracy: 0.8319 - val_loss: 0.2866 - val_accuracy: 0.8354 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 14/600\n",
            "1436/1436 - 9s - loss: 0.3142 - accuracy: 0.8308 - val_loss: 0.2869 - val_accuracy: 0.8344 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 15/600\n",
            "1436/1436 - 9s - loss: 0.2918 - accuracy: 0.8319 - val_loss: 0.6496 - val_accuracy: 0.7447 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 16/600\n",
            "1436/1436 - 9s - loss: 0.3049 - accuracy: 0.8312 - val_loss: 0.2831 - val_accuracy: 0.8328 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 17/600\n",
            "1436/1436 - 9s - loss: 0.3079 - accuracy: 0.8304 - val_loss: 0.3407 - val_accuracy: 0.8280 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 18/600\n",
            "1436/1436 - 9s - loss: 0.2919 - accuracy: 0.8331 - val_loss: 0.2808 - val_accuracy: 0.8303 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 19/600\n",
            "1436/1436 - 9s - loss: 0.3225 - accuracy: 0.8294 - val_loss: 0.3362 - val_accuracy: 0.8247 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 20/600\n",
            "1436/1436 - 9s - loss: 0.2947 - accuracy: 0.8324 - val_loss: 0.2813 - val_accuracy: 0.8346 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 21/600\n",
            "1436/1436 - 9s - loss: 0.3029 - accuracy: 0.8301 - val_loss: 0.2826 - val_accuracy: 0.8335 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 22/600\n",
            "1436/1436 - 9s - loss: 0.2761 - accuracy: 0.8328 - val_loss: 0.2726 - val_accuracy: 0.8360 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 23/600\n",
            "1436/1436 - 9s - loss: 0.2748 - accuracy: 0.8328 - val_loss: 0.2702 - val_accuracy: 0.8344 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 24/600\n",
            "1436/1436 - 9s - loss: 0.2748 - accuracy: 0.8327 - val_loss: 0.2691 - val_accuracy: 0.8354 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 25/600\n",
            "1436/1436 - 9s - loss: 0.2780 - accuracy: 0.8320 - val_loss: 0.2700 - val_accuracy: 0.8356 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 26/600\n",
            "1436/1436 - 9s - loss: 0.2831 - accuracy: 0.8320 - val_loss: 0.2753 - val_accuracy: 0.8319 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 27/600\n",
            "1436/1436 - 9s - loss: 0.2728 - accuracy: 0.8339 - val_loss: 0.2682 - val_accuracy: 0.8327 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 28/600\n",
            "1436/1436 - 9s - loss: 0.2815 - accuracy: 0.8326 - val_loss: 0.2954 - val_accuracy: 0.8341 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 29/600\n",
            "1436/1436 - 9s - loss: 0.2746 - accuracy: 0.8339 - val_loss: 0.2673 - val_accuracy: 0.8345 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 30/600\n",
            "1436/1436 - 9s - loss: 0.2706 - accuracy: 0.8339 - val_loss: 0.2737 - val_accuracy: 0.8352 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 31/600\n",
            "1436/1436 - 9s - loss: 0.2773 - accuracy: 0.8322 - val_loss: 0.3399 - val_accuracy: 0.8284 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 32/600\n",
            "1436/1436 - 9s - loss: 0.2763 - accuracy: 0.8346 - val_loss: 0.2676 - val_accuracy: 0.8336 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 33/600\n",
            "1436/1436 - 9s - loss: 0.2639 - accuracy: 0.8352 - val_loss: 0.2617 - val_accuracy: 0.8330 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 34/600\n",
            "1436/1436 - 9s - loss: 0.2639 - accuracy: 0.8336 - val_loss: 0.2616 - val_accuracy: 0.8317 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 35/600\n",
            "1436/1436 - 9s - loss: 0.2673 - accuracy: 0.8337 - val_loss: 0.2623 - val_accuracy: 0.8340 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 36/600\n",
            "1436/1436 - 9s - loss: 0.2629 - accuracy: 0.8347 - val_loss: 0.2605 - val_accuracy: 0.8344 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 37/600\n",
            "1436/1436 - 9s - loss: 0.2685 - accuracy: 0.8342 - val_loss: 0.2636 - val_accuracy: 0.8344 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 38/600\n",
            "1436/1436 - 9s - loss: 0.2627 - accuracy: 0.8344 - val_loss: 0.2603 - val_accuracy: 0.8335 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 39/600\n",
            "1436/1436 - 9s - loss: 0.2619 - accuracy: 0.8351 - val_loss: 0.2605 - val_accuracy: 0.8339 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 40/600\n",
            "1436/1436 - 9s - loss: 0.2678 - accuracy: 0.8351 - val_loss: 0.2606 - val_accuracy: 0.8331 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 41/600\n",
            "1436/1436 - 9s - loss: 0.2621 - accuracy: 0.8353 - val_loss: 0.2599 - val_accuracy: 0.8336 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 42/600\n",
            "1436/1436 - 9s - loss: 0.2620 - accuracy: 0.8347 - val_loss: 0.2606 - val_accuracy: 0.8354 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 43/600\n",
            "1436/1436 - 9s - loss: 0.2622 - accuracy: 0.8347 - val_loss: 0.2603 - val_accuracy: 0.8356 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 44/600\n",
            "1436/1436 - 9s - loss: 0.2714 - accuracy: 0.8332 - val_loss: 0.2598 - val_accuracy: 0.8356 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 45/600\n",
            "1436/1436 - 9s - loss: 0.2613 - accuracy: 0.8340 - val_loss: 0.2589 - val_accuracy: 0.8354 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 46/600\n",
            "1436/1436 - 9s - loss: 0.2642 - accuracy: 0.8337 - val_loss: 0.2604 - val_accuracy: 0.8340 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 47/600\n",
            "1436/1436 - 9s - loss: 0.2612 - accuracy: 0.8349 - val_loss: 0.2603 - val_accuracy: 0.8356 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 48/600\n",
            "1436/1436 - 9s - loss: 0.2657 - accuracy: 0.8337 - val_loss: 0.2622 - val_accuracy: 0.8332 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 49/600\n",
            "1436/1436 - 9s - loss: 0.2586 - accuracy: 0.8348 - val_loss: 0.2565 - val_accuracy: 0.8349 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 50/600\n",
            "1436/1436 - 9s - loss: 0.2583 - accuracy: 0.8360 - val_loss: 0.2563 - val_accuracy: 0.8341 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 51/600\n",
            "1436/1436 - 9s - loss: 0.2580 - accuracy: 0.8350 - val_loss: 0.2569 - val_accuracy: 0.8340 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 52/600\n",
            "1436/1436 - 9s - loss: 0.2582 - accuracy: 0.8351 - val_loss: 0.2569 - val_accuracy: 0.8346 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 53/600\n",
            "1436/1436 - 9s - loss: 0.2582 - accuracy: 0.8347 - val_loss: 0.2561 - val_accuracy: 0.8350 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 54/600\n",
            "1436/1436 - 9s - loss: 0.2582 - accuracy: 0.8350 - val_loss: 0.2563 - val_accuracy: 0.8361 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 55/600\n",
            "1436/1436 - 9s - loss: 0.2589 - accuracy: 0.8354 - val_loss: 0.2557 - val_accuracy: 0.8340 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 56/600\n",
            "1436/1436 - 9s - loss: 0.2575 - accuracy: 0.8349 - val_loss: 0.2563 - val_accuracy: 0.8339 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 57/600\n",
            "1436/1436 - 9s - loss: 0.2576 - accuracy: 0.8347 - val_loss: 0.2556 - val_accuracy: 0.8361 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 58/600\n",
            "1436/1436 - 9s - loss: 0.2595 - accuracy: 0.8344 - val_loss: 0.2573 - val_accuracy: 0.8321 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 59/600\n",
            "1436/1436 - 9s - loss: 0.2576 - accuracy: 0.8346 - val_loss: 0.2558 - val_accuracy: 0.8340 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 60/600\n",
            "1436/1436 - 9s - loss: 0.2573 - accuracy: 0.8353 - val_loss: 0.2563 - val_accuracy: 0.8347 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 61/600\n",
            "1436/1436 - 9s - loss: 0.2556 - accuracy: 0.8344 - val_loss: 0.2541 - val_accuracy: 0.8345 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 62/600\n",
            "1436/1436 - 9s - loss: 0.2557 - accuracy: 0.8350 - val_loss: 0.2541 - val_accuracy: 0.8356 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 63/600\n",
            "1436/1436 - 9s - loss: 0.2555 - accuracy: 0.8350 - val_loss: 0.2545 - val_accuracy: 0.8351 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 64/600\n",
            "1436/1436 - 9s - loss: 0.2556 - accuracy: 0.8354 - val_loss: 0.2541 - val_accuracy: 0.8361 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 65/600\n",
            "1436/1436 - 9s - loss: 0.2545 - accuracy: 0.8352 - val_loss: 0.2531 - val_accuracy: 0.8340 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 66/600\n",
            "1436/1436 - 9s - loss: 0.2543 - accuracy: 0.8364 - val_loss: 0.2533 - val_accuracy: 0.8343 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 67/600\n",
            "1436/1436 - 9s - loss: 0.2545 - accuracy: 0.8361 - val_loss: 0.2530 - val_accuracy: 0.8356 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 68/600\n",
            "1436/1436 - 9s - loss: 0.2544 - accuracy: 0.8355 - val_loss: 0.2530 - val_accuracy: 0.8340 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 69/600\n",
            "1436/1436 - 9s - loss: 0.2543 - accuracy: 0.8365 - val_loss: 0.2536 - val_accuracy: 0.8351 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 70/600\n",
            "1436/1436 - 9s - loss: 0.2543 - accuracy: 0.8355 - val_loss: 0.2531 - val_accuracy: 0.8351 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 71/600\n",
            "1436/1436 - 9s - loss: 0.2539 - accuracy: 0.8353 - val_loss: 0.2526 - val_accuracy: 0.8355 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 72/600\n",
            "1436/1436 - 9s - loss: 0.2539 - accuracy: 0.8350 - val_loss: 0.2525 - val_accuracy: 0.8350 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 73/600\n",
            "1436/1436 - 9s - loss: 0.2537 - accuracy: 0.8364 - val_loss: 0.2526 - val_accuracy: 0.8369 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 74/600\n",
            "1436/1436 - 9s - loss: 0.2538 - accuracy: 0.8359 - val_loss: 0.2527 - val_accuracy: 0.8354 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 75/600\n",
            "1436/1436 - 9s - loss: 0.2534 - accuracy: 0.8365 - val_loss: 0.2523 - val_accuracy: 0.8355 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 76/600\n",
            "1436/1436 - 9s - loss: 0.2535 - accuracy: 0.8358 - val_loss: 0.2523 - val_accuracy: 0.8347 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 77/600\n",
            "1436/1436 - 9s - loss: 0.2534 - accuracy: 0.8356 - val_loss: 0.2523 - val_accuracy: 0.8345 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 78/600\n",
            "1436/1436 - 9s - loss: 0.2534 - accuracy: 0.8365 - val_loss: 0.2524 - val_accuracy: 0.8344 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 79/600\n",
            "1436/1436 - 9s - loss: 0.2535 - accuracy: 0.8353 - val_loss: 0.2522 - val_accuracy: 0.8355 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 80/600\n",
            "1436/1436 - 9s - loss: 0.2533 - accuracy: 0.8364 - val_loss: 0.2522 - val_accuracy: 0.8352 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 81/600\n",
            "1436/1436 - 9s - loss: 0.2533 - accuracy: 0.8358 - val_loss: 0.2521 - val_accuracy: 0.8352 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 82/600\n",
            "1436/1436 - 9s - loss: 0.2533 - accuracy: 0.8369 - val_loss: 0.2521 - val_accuracy: 0.8355 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 83/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8363 - val_loss: 0.2521 - val_accuracy: 0.8352 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 84/600\n",
            "1436/1436 - 9s - loss: 0.2533 - accuracy: 0.8358 - val_loss: 0.2521 - val_accuracy: 0.8355 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 85/600\n",
            "1436/1436 - 9s - loss: 0.2532 - accuracy: 0.8359 - val_loss: 0.2521 - val_accuracy: 0.8352 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 86/600\n",
            "1436/1436 - 9s - loss: 0.2532 - accuracy: 0.8371 - val_loss: 0.2520 - val_accuracy: 0.8352 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 87/600\n",
            "1436/1436 - 9s - loss: 0.2532 - accuracy: 0.8351 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 88/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8367 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 89/600\n",
            "1436/1436 - 9s - loss: 0.2532 - accuracy: 0.8358 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 90/600\n",
            "1436/1436 - 9s - loss: 0.2532 - accuracy: 0.8360 - val_loss: 0.2520 - val_accuracy: 0.8352 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 91/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8365 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 92/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8365 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 93/600\n",
            "1436/1436 - 9s - loss: 0.2532 - accuracy: 0.8362 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 94/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8361 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 95/600\n",
            "1436/1436 - 9s - loss: 0.2530 - accuracy: 0.8372 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 96/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8361 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 97/600\n",
            "1436/1436 - 9s - loss: 0.2530 - accuracy: 0.8369 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 98/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8366 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 99/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8360 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 100/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8372 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 101/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8370 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 102/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8369 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 103/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8367 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 104/600\n",
            "1436/1436 - 9s - loss: 0.2530 - accuracy: 0.8363 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 105/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8362 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 106/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8361 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 107/600\n",
            "1436/1436 - 9s - loss: 0.2532 - accuracy: 0.8362 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 108/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8371 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 109/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8358 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 110/600\n",
            "1436/1436 - 9s - loss: 0.2532 - accuracy: 0.8359 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 111/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8362 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 112/600\n",
            "1436/1436 - 9s - loss: 0.2532 - accuracy: 0.8370 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 113/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8368 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 114/600\n",
            "1436/1436 - 9s - loss: 0.2533 - accuracy: 0.8359 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 115/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8363 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 116/600\n",
            "1436/1436 - 9s - loss: 0.2532 - accuracy: 0.8360 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 117/600\n",
            "1436/1436 - 9s - loss: 0.2531 - accuracy: 0.8364 - val_loss: 0.2520 - val_accuracy: 0.8355 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " ...\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " ...\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ...  6 12  2]\n",
            " ...\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ...  6 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ...  2 11 24]\n",
            " ...\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ... 14 11 24]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " ...\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 24 25  7]\n",
            " ...\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 24 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ...  7 18 23]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ...  7 18 13]\n",
            " ...\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ... 15 18 23]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " ...\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 13 17  9]\n",
            " ...\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 23 17  9]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  9 21  4]\n",
            " ...\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ... 22  3  5]\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ...  4  3  8]\n",
            " ...\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  8]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " ...\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " ...\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_4 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1442/1442 - 12s - loss: 0.6823 - accuracy: 0.7878 - val_loss: 1.1651 - val_accuracy: 0.7680 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 2/600\n",
            "1442/1442 - 9s - loss: 0.5340 - accuracy: 0.8215 - val_loss: 0.3914 - val_accuracy: 0.8285 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 3/600\n",
            "1442/1442 - 9s - loss: 0.4378 - accuracy: 0.8242 - val_loss: 0.3867 - val_accuracy: 0.8327 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 4/600\n",
            "1442/1442 - 9s - loss: 0.5124 - accuracy: 0.8206 - val_loss: 0.3878 - val_accuracy: 0.8304 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 5/600\n",
            "1442/1442 - 9s - loss: 0.3659 - accuracy: 0.8282 - val_loss: 0.3326 - val_accuracy: 0.8317 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 6/600\n",
            "1442/1442 - 9s - loss: 0.3450 - accuracy: 0.8280 - val_loss: 0.3231 - val_accuracy: 0.8274 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 7/600\n",
            "1442/1442 - 9s - loss: 0.3718 - accuracy: 0.8263 - val_loss: 0.3673 - val_accuracy: 0.8303 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 8/600\n",
            "1442/1442 - 9s - loss: 0.3645 - accuracy: 0.8276 - val_loss: 0.3307 - val_accuracy: 0.8319 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 9/600\n",
            "1442/1442 - 9s - loss: 0.3203 - accuracy: 0.8296 - val_loss: 0.3099 - val_accuracy: 0.8228 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 10/600\n",
            "1442/1442 - 9s - loss: 0.3503 - accuracy: 0.8283 - val_loss: 0.3100 - val_accuracy: 0.8316 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 11/600\n",
            "1442/1442 - 9s - loss: 0.3302 - accuracy: 0.8295 - val_loss: 0.3192 - val_accuracy: 0.8324 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 12/600\n",
            "1442/1442 - 9s - loss: 0.3781 - accuracy: 0.8264 - val_loss: 0.8701 - val_accuracy: 0.8301 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 13/600\n",
            "1442/1442 - 9s - loss: 0.4476 - accuracy: 0.8294 - val_loss: 0.3221 - val_accuracy: 0.8326 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 14/600\n",
            "1442/1442 - 9s - loss: 0.3110 - accuracy: 0.8304 - val_loss: 0.2932 - val_accuracy: 0.8293 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 15/600\n",
            "1442/1442 - 9s - loss: 0.3005 - accuracy: 0.8305 - val_loss: 0.2898 - val_accuracy: 0.8326 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 16/600\n",
            "1442/1442 - 9s - loss: 0.2953 - accuracy: 0.8308 - val_loss: 0.2901 - val_accuracy: 0.8312 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 17/600\n",
            "1442/1442 - 9s - loss: 0.2962 - accuracy: 0.8312 - val_loss: 0.2902 - val_accuracy: 0.8302 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 18/600\n",
            "1442/1442 - 9s - loss: 0.3004 - accuracy: 0.8306 - val_loss: 0.3022 - val_accuracy: 0.8304 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 19/600\n",
            "1442/1442 - 9s - loss: 0.2849 - accuracy: 0.8309 - val_loss: 0.2788 - val_accuracy: 0.8321 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 20/600\n",
            "1442/1442 - 9s - loss: 0.2829 - accuracy: 0.8323 - val_loss: 0.2779 - val_accuracy: 0.8328 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 21/600\n",
            "1442/1442 - 9s - loss: 0.2845 - accuracy: 0.8318 - val_loss: 0.2788 - val_accuracy: 0.8328 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 22/600\n",
            "1442/1442 - 9s - loss: 0.2826 - accuracy: 0.8316 - val_loss: 0.2790 - val_accuracy: 0.8313 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 23/600\n",
            "1442/1442 - 9s - loss: 0.2824 - accuracy: 0.8321 - val_loss: 0.2796 - val_accuracy: 0.8313 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 24/600\n",
            "1442/1442 - 9s - loss: 0.2763 - accuracy: 0.8325 - val_loss: 0.2730 - val_accuracy: 0.8320 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 25/600\n",
            "1442/1442 - 9s - loss: 0.2761 - accuracy: 0.8315 - val_loss: 0.2722 - val_accuracy: 0.8326 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 26/600\n",
            "1442/1442 - 9s - loss: 0.2760 - accuracy: 0.8330 - val_loss: 0.2720 - val_accuracy: 0.8331 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 27/600\n",
            "1442/1442 - 9s - loss: 0.2758 - accuracy: 0.8320 - val_loss: 0.2716 - val_accuracy: 0.8316 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 28/600\n",
            "1442/1442 - 9s - loss: 0.2758 - accuracy: 0.8320 - val_loss: 0.2718 - val_accuracy: 0.8327 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 29/600\n",
            "1442/1442 - 9s - loss: 0.2752 - accuracy: 0.8327 - val_loss: 0.2716 - val_accuracy: 0.8318 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 30/600\n",
            "1442/1442 - 9s - loss: 0.2752 - accuracy: 0.8312 - val_loss: 0.2718 - val_accuracy: 0.8332 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 31/600\n",
            "1442/1442 - 9s - loss: 0.2722 - accuracy: 0.8327 - val_loss: 0.2689 - val_accuracy: 0.8327 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 32/600\n",
            "1442/1442 - 9s - loss: 0.2721 - accuracy: 0.8325 - val_loss: 0.2686 - val_accuracy: 0.8316 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 33/600\n",
            "1442/1442 - 9s - loss: 0.2721 - accuracy: 0.8325 - val_loss: 0.2684 - val_accuracy: 0.8317 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 34/600\n",
            "1442/1442 - 9s - loss: 0.2720 - accuracy: 0.8330 - val_loss: 0.2686 - val_accuracy: 0.8320 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 35/600\n",
            "1442/1442 - 9s - loss: 0.2718 - accuracy: 0.8330 - val_loss: 0.2683 - val_accuracy: 0.8331 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 36/600\n",
            "1442/1442 - 9s - loss: 0.2716 - accuracy: 0.8326 - val_loss: 0.2682 - val_accuracy: 0.8324 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 37/600\n",
            "1442/1442 - 9s - loss: 0.2718 - accuracy: 0.8327 - val_loss: 0.2684 - val_accuracy: 0.8332 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 38/600\n",
            "1442/1442 - 9s - loss: 0.2717 - accuracy: 0.8330 - val_loss: 0.2683 - val_accuracy: 0.8309 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 39/600\n",
            "1442/1442 - 9s - loss: 0.2715 - accuracy: 0.8338 - val_loss: 0.2682 - val_accuracy: 0.8321 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 40/600\n",
            "1442/1442 - 9s - loss: 0.2702 - accuracy: 0.8327 - val_loss: 0.2669 - val_accuracy: 0.8333 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 41/600\n",
            "1442/1442 - 9s - loss: 0.2700 - accuracy: 0.8333 - val_loss: 0.2669 - val_accuracy: 0.8325 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 42/600\n",
            "1442/1442 - 9s - loss: 0.2700 - accuracy: 0.8333 - val_loss: 0.2667 - val_accuracy: 0.8331 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 43/600\n",
            "1442/1442 - 9s - loss: 0.2700 - accuracy: 0.8329 - val_loss: 0.2667 - val_accuracy: 0.8320 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 44/600\n",
            "1442/1442 - 9s - loss: 0.2700 - accuracy: 0.8327 - val_loss: 0.2667 - val_accuracy: 0.8331 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 45/600\n",
            "1442/1442 - 9s - loss: 0.2699 - accuracy: 0.8326 - val_loss: 0.2666 - val_accuracy: 0.8331 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 46/600\n",
            "1442/1442 - 9s - loss: 0.2692 - accuracy: 0.8333 - val_loss: 0.2660 - val_accuracy: 0.8327 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 47/600\n",
            "1442/1442 - 9s - loss: 0.2693 - accuracy: 0.8325 - val_loss: 0.2661 - val_accuracy: 0.8319 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 48/600\n",
            "1442/1442 - 9s - loss: 0.2692 - accuracy: 0.8329 - val_loss: 0.2660 - val_accuracy: 0.8327 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 49/600\n",
            "1442/1442 - 9s - loss: 0.2691 - accuracy: 0.8333 - val_loss: 0.2660 - val_accuracy: 0.8331 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 50/600\n",
            "1442/1442 - 9s - loss: 0.2688 - accuracy: 0.8336 - val_loss: 0.2657 - val_accuracy: 0.8331 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 51/600\n",
            "1442/1442 - 9s - loss: 0.2687 - accuracy: 0.8337 - val_loss: 0.2656 - val_accuracy: 0.8331 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 52/600\n",
            "1442/1442 - 9s - loss: 0.2688 - accuracy: 0.8332 - val_loss: 0.2656 - val_accuracy: 0.8331 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 53/600\n",
            "1442/1442 - 9s - loss: 0.2687 - accuracy: 0.8336 - val_loss: 0.2656 - val_accuracy: 0.8331 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 54/600\n",
            "1442/1442 - 9s - loss: 0.2686 - accuracy: 0.8337 - val_loss: 0.2655 - val_accuracy: 0.8331 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 55/600\n",
            "1442/1442 - 9s - loss: 0.2686 - accuracy: 0.8334 - val_loss: 0.2655 - val_accuracy: 0.8331 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 56/600\n",
            "1442/1442 - 9s - loss: 0.2686 - accuracy: 0.8333 - val_loss: 0.2655 - val_accuracy: 0.8331 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 57/600\n",
            "1442/1442 - 9s - loss: 0.2686 - accuracy: 0.8334 - val_loss: 0.2655 - val_accuracy: 0.8331 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 58/600\n",
            "1442/1442 - 9s - loss: 0.2684 - accuracy: 0.8332 - val_loss: 0.2654 - val_accuracy: 0.8331 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 59/600\n",
            "1442/1442 - 9s - loss: 0.2684 - accuracy: 0.8341 - val_loss: 0.2654 - val_accuracy: 0.8331 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 60/600\n",
            "1442/1442 - 9s - loss: 0.2684 - accuracy: 0.8339 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 61/600\n",
            "1442/1442 - 9s - loss: 0.2684 - accuracy: 0.8335 - val_loss: 0.2654 - val_accuracy: 0.8331 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 62/600\n",
            "1442/1442 - 9s - loss: 0.2684 - accuracy: 0.8338 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 63/600\n",
            "1442/1442 - 9s - loss: 0.2685 - accuracy: 0.8331 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 64/600\n",
            "1442/1442 - 9s - loss: 0.2684 - accuracy: 0.8342 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 65/600\n",
            "1442/1442 - 9s - loss: 0.2683 - accuracy: 0.8337 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 66/600\n",
            "1442/1442 - 9s - loss: 0.2684 - accuracy: 0.8333 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 67/600\n",
            "1442/1442 - 9s - loss: 0.2684 - accuracy: 0.8334 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 68/600\n",
            "1442/1442 - 9s - loss: 0.2684 - accuracy: 0.8332 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 69/600\n",
            "1442/1442 - 9s - loss: 0.2683 - accuracy: 0.8342 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 70/600\n",
            "1442/1442 - 10s - loss: 0.2685 - accuracy: 0.8339 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 1.2207e-06 - 10s/epoch - 7ms/step\n",
            "Epoch 71/600\n",
            "1442/1442 - 9s - loss: 0.2683 - accuracy: 0.8340 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 72/600\n",
            "1442/1442 - 10s - loss: 0.2684 - accuracy: 0.8337 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 6.1035e-07 - 10s/epoch - 7ms/step\n",
            "Epoch 73/600\n",
            "1442/1442 - 11s - loss: 0.2683 - accuracy: 0.8337 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 6.1035e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 74/600\n",
            "1442/1442 - 9s - loss: 0.2684 - accuracy: 0.8335 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 75/600\n",
            "1442/1442 - 10s - loss: 0.2684 - accuracy: 0.8339 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 3.0518e-07 - 10s/epoch - 7ms/step\n",
            "Epoch 76/600\n",
            "1442/1442 - 9s - loss: 0.2684 - accuracy: 0.8336 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 3.0518e-07 - 9s/epoch - 7ms/step\n",
            "Epoch 77/600\n",
            "1442/1442 - 10s - loss: 0.2683 - accuracy: 0.8336 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 1.5259e-07 - 10s/epoch - 7ms/step\n",
            "Epoch 78/600\n",
            "1442/1442 - 10s - loss: 0.2684 - accuracy: 0.8337 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 1.5259e-07 - 10s/epoch - 7ms/step\n",
            "Epoch 79/600\n",
            "1442/1442 - 10s - loss: 0.2683 - accuracy: 0.8341 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 1.5259e-07 - 10s/epoch - 7ms/step\n",
            "Epoch 80/600\n",
            "1442/1442 - 9s - loss: 0.2683 - accuracy: 0.8335 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 7.6294e-08 - 9s/epoch - 7ms/step\n",
            "Epoch 81/600\n",
            "1442/1442 - 10s - loss: 0.2683 - accuracy: 0.8344 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 7.6294e-08 - 10s/epoch - 7ms/step\n",
            "Epoch 82/600\n",
            "1442/1442 - 9s - loss: 0.2683 - accuracy: 0.8332 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 7.6294e-08 - 9s/epoch - 7ms/step\n",
            "Epoch 83/600\n",
            "1442/1442 - 10s - loss: 0.2683 - accuracy: 0.8335 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 3.8147e-08 - 10s/epoch - 7ms/step\n",
            "Epoch 84/600\n",
            "1442/1442 - 10s - loss: 0.2684 - accuracy: 0.8334 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 3.8147e-08 - 10s/epoch - 7ms/step\n",
            "Epoch 85/600\n",
            "1442/1442 - 10s - loss: 0.2683 - accuracy: 0.8345 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 3.8147e-08 - 10s/epoch - 7ms/step\n",
            "Epoch 86/600\n",
            "1442/1442 - 9s - loss: 0.2683 - accuracy: 0.8333 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 87/600\n",
            "1442/1442 - 10s - loss: 0.2685 - accuracy: 0.8332 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 1.9073e-08 - 10s/epoch - 7ms/step\n",
            "Epoch 88/600\n",
            "1442/1442 - 10s - loss: 0.2684 - accuracy: 0.8332 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 1.9073e-08 - 10s/epoch - 7ms/step\n",
            "Epoch 89/600\n",
            "1442/1442 - 10s - loss: 0.2683 - accuracy: 0.8334 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 9.5367e-09 - 10s/epoch - 7ms/step\n",
            "Epoch 90/600\n",
            "1442/1442 - 10s - loss: 0.2684 - accuracy: 0.8337 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 9.5367e-09 - 10s/epoch - 7ms/step\n",
            "Epoch 91/600\n",
            "1442/1442 - 10s - loss: 0.2684 - accuracy: 0.8337 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 9.5367e-09 - 10s/epoch - 7ms/step\n",
            "Epoch 92/600\n",
            "1442/1442 - 10s - loss: 0.2683 - accuracy: 0.8337 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 4.7684e-09 - 10s/epoch - 7ms/step\n",
            "Epoch 93/600\n",
            "1442/1442 - 10s - loss: 0.2683 - accuracy: 0.8338 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 4.7684e-09 - 10s/epoch - 7ms/step\n",
            "Epoch 94/600\n",
            "1442/1442 - 9s - loss: 0.2684 - accuracy: 0.8341 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 95/600\n",
            "1442/1442 - 10s - loss: 0.2683 - accuracy: 0.8330 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 2.3842e-09 - 10s/epoch - 7ms/step\n",
            "Epoch 96/600\n",
            "1442/1442 - 10s - loss: 0.2683 - accuracy: 0.8335 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 2.3842e-09 - 10s/epoch - 7ms/step\n",
            "Epoch 97/600\n",
            "1442/1442 - 10s - loss: 0.2684 - accuracy: 0.8341 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 2.3842e-09 - 10s/epoch - 7ms/step\n",
            "Epoch 98/600\n",
            "1442/1442 - 10s - loss: 0.2684 - accuracy: 0.8330 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 1.1921e-09 - 10s/epoch - 7ms/step\n",
            "Epoch 99/600\n",
            "1442/1442 - 10s - loss: 0.2684 - accuracy: 0.8339 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 1.1921e-09 - 10s/epoch - 7ms/step\n",
            "Epoch 100/600\n",
            "1442/1442 - 10s - loss: 0.2683 - accuracy: 0.8333 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 1.1921e-09 - 10s/epoch - 7ms/step\n",
            "Epoch 101/600\n",
            "1442/1442 - 10s - loss: 0.2685 - accuracy: 0.8334 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 5.9605e-10 - 10s/epoch - 7ms/step\n",
            "Epoch 102/600\n",
            "1442/1442 - 10s - loss: 0.2682 - accuracy: 0.8345 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 5.9605e-10 - 10s/epoch - 7ms/step\n",
            "Epoch 103/600\n",
            "1442/1442 - 9s - loss: 0.2682 - accuracy: 0.8342 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 5.9605e-10 - 9s/epoch - 6ms/step\n",
            "Epoch 104/600\n",
            "1442/1442 - 10s - loss: 0.2683 - accuracy: 0.8345 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 2.9802e-10 - 10s/epoch - 7ms/step\n",
            "Epoch 105/600\n",
            "1442/1442 - 10s - loss: 0.2683 - accuracy: 0.8329 - val_loss: 0.2653 - val_accuracy: 0.8331 - lr: 2.9802e-10 - 10s/epoch - 7ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " ...\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " ...\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12 14]\n",
            " ...\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 20]\n",
            " ...\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ... 14 11 24]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25 15]\n",
            " ...\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ...  7 18 23]\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ... 15 18 23]\n",
            " ...\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 23]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 23 17  9]\n",
            " ...\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 23 17  9]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  9 21  4]\n",
            " ...\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  9 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  8]\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ...  4  3  8]\n",
            " ...\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ... 22  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " ...\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " ...\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_5 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1437/1437 - 12s - loss: 0.6298 - accuracy: 0.7938 - val_loss: 0.3452 - val_accuracy: 0.8265 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 2/600\n",
            "1437/1437 - 9s - loss: 0.3970 - accuracy: 0.8252 - val_loss: 0.3257 - val_accuracy: 0.8228 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 3/600\n",
            "1437/1437 - 9s - loss: 0.3885 - accuracy: 0.8226 - val_loss: 0.3149 - val_accuracy: 0.8280 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 4/600\n",
            "1437/1437 - 9s - loss: 0.4269 - accuracy: 0.8211 - val_loss: 0.3177 - val_accuracy: 0.8305 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 5/600\n",
            "1437/1437 - 9s - loss: 0.4267 - accuracy: 0.8214 - val_loss: 0.3348 - val_accuracy: 0.8289 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 6/600\n",
            "1437/1437 - 9s - loss: 0.4049 - accuracy: 0.8224 - val_loss: 0.3735 - val_accuracy: 0.8285 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 7/600\n",
            "1437/1437 - 9s - loss: 0.3235 - accuracy: 0.8266 - val_loss: 0.3033 - val_accuracy: 0.8290 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 8/600\n",
            "1437/1437 - 9s - loss: 0.3505 - accuracy: 0.8246 - val_loss: 0.3404 - val_accuracy: 0.8290 - lr: 0.0025 - 9s/epoch - 7ms/step\n",
            "Epoch 9/600\n",
            "1437/1437 - 9s - loss: 0.3122 - accuracy: 0.8271 - val_loss: 0.2918 - val_accuracy: 0.8264 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 10/600\n",
            "1437/1437 - 9s - loss: 0.3054 - accuracy: 0.8269 - val_loss: 0.2906 - val_accuracy: 0.8283 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 11/600\n",
            "1437/1437 - 9s - loss: 0.2917 - accuracy: 0.8250 - val_loss: 0.2821 - val_accuracy: 0.8281 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 12/600\n",
            "1437/1437 - 9s - loss: 0.3069 - accuracy: 0.8263 - val_loss: 0.2840 - val_accuracy: 0.8273 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 13/600\n",
            "1437/1437 - 10s - loss: 0.3197 - accuracy: 0.8256 - val_loss: 0.3101 - val_accuracy: 0.8291 - lr: 0.0025 - 10s/epoch - 7ms/step\n",
            "Epoch 14/600\n",
            "1437/1437 - 9s - loss: 0.3175 - accuracy: 0.8259 - val_loss: 0.3204 - val_accuracy: 0.8301 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 15/600\n",
            "1437/1437 - 9s - loss: 0.2907 - accuracy: 0.8272 - val_loss: 0.2807 - val_accuracy: 0.8263 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 16/600\n",
            "1437/1437 - 9s - loss: 0.2817 - accuracy: 0.8275 - val_loss: 0.2760 - val_accuracy: 0.8319 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 17/600\n",
            "1437/1437 - 9s - loss: 0.2865 - accuracy: 0.8268 - val_loss: 0.3248 - val_accuracy: 0.8229 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 18/600\n",
            "1437/1437 - 9s - loss: 0.2799 - accuracy: 0.8275 - val_loss: 0.2715 - val_accuracy: 0.8298 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 19/600\n",
            "1437/1437 - 9s - loss: 0.2758 - accuracy: 0.8285 - val_loss: 0.2710 - val_accuracy: 0.8284 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 20/600\n",
            "1437/1437 - 9s - loss: 0.2955 - accuracy: 0.8261 - val_loss: 0.2733 - val_accuracy: 0.8274 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 21/600\n",
            "1437/1437 - 9s - loss: 0.2731 - accuracy: 0.8276 - val_loss: 0.2707 - val_accuracy: 0.8300 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 22/600\n",
            "1437/1437 - 11s - loss: 0.2736 - accuracy: 0.8272 - val_loss: 0.2690 - val_accuracy: 0.8301 - lr: 0.0012 - 11s/epoch - 7ms/step\n",
            "Epoch 23/600\n",
            "1437/1437 - 9s - loss: 0.2817 - accuracy: 0.8270 - val_loss: 0.3111 - val_accuracy: 0.8319 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 24/600\n",
            "1437/1437 - 9s - loss: 0.2751 - accuracy: 0.8282 - val_loss: 0.2688 - val_accuracy: 0.8279 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 25/600\n",
            "1437/1437 - 9s - loss: 0.2786 - accuracy: 0.8277 - val_loss: 0.2852 - val_accuracy: 0.8277 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 26/600\n",
            "1437/1437 - 9s - loss: 0.2723 - accuracy: 0.8283 - val_loss: 0.2676 - val_accuracy: 0.8318 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 27/600\n",
            "1437/1437 - 10s - loss: 0.2793 - accuracy: 0.8295 - val_loss: 0.2720 - val_accuracy: 0.8208 - lr: 0.0012 - 10s/epoch - 7ms/step\n",
            "Epoch 28/600\n",
            "1437/1437 - 9s - loss: 0.2718 - accuracy: 0.8291 - val_loss: 0.2679 - val_accuracy: 0.8294 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 29/600\n",
            "1437/1437 - 9s - loss: 0.2799 - accuracy: 0.8277 - val_loss: 0.3812 - val_accuracy: 0.8279 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 30/600\n",
            "1437/1437 - 9s - loss: 0.2895 - accuracy: 0.8269 - val_loss: 0.2667 - val_accuracy: 0.8313 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 31/600\n",
            "1437/1437 - 9s - loss: 0.2670 - accuracy: 0.8294 - val_loss: 0.2641 - val_accuracy: 0.8312 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 32/600\n",
            "1437/1437 - 9s - loss: 0.2665 - accuracy: 0.8302 - val_loss: 0.2636 - val_accuracy: 0.8332 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 33/600\n",
            "1437/1437 - 9s - loss: 0.2648 - accuracy: 0.8304 - val_loss: 0.2627 - val_accuracy: 0.8319 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 34/600\n",
            "1437/1437 - 9s - loss: 0.2683 - accuracy: 0.8295 - val_loss: 0.2621 - val_accuracy: 0.8322 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 35/600\n",
            "1437/1437 - 9s - loss: 0.2641 - accuracy: 0.8308 - val_loss: 0.2621 - val_accuracy: 0.8333 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 36/600\n",
            "1437/1437 - 9s - loss: 0.2667 - accuracy: 0.8299 - val_loss: 0.2626 - val_accuracy: 0.8325 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 37/600\n",
            "1437/1437 - 9s - loss: 0.2639 - accuracy: 0.8317 - val_loss: 0.2621 - val_accuracy: 0.8305 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 38/600\n",
            "1437/1437 - 9s - loss: 0.2611 - accuracy: 0.8323 - val_loss: 0.2591 - val_accuracy: 0.8310 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 39/600\n",
            "1437/1437 - 10s - loss: 0.2612 - accuracy: 0.8315 - val_loss: 0.2593 - val_accuracy: 0.8347 - lr: 3.1250e-04 - 10s/epoch - 7ms/step\n",
            "Epoch 40/600\n",
            "1437/1437 - 9s - loss: 0.2607 - accuracy: 0.8327 - val_loss: 0.2590 - val_accuracy: 0.8338 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 41/600\n",
            "1437/1437 - 9s - loss: 0.2606 - accuracy: 0.8313 - val_loss: 0.2601 - val_accuracy: 0.8332 - lr: 3.1250e-04 - 9s/epoch - 7ms/step\n",
            "Epoch 42/600\n",
            "1437/1437 - 9s - loss: 0.2604 - accuracy: 0.8321 - val_loss: 0.2585 - val_accuracy: 0.8309 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 43/600\n",
            "1437/1437 - 9s - loss: 0.2606 - accuracy: 0.8316 - val_loss: 0.2586 - val_accuracy: 0.8344 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 44/600\n",
            "1437/1437 - 9s - loss: 0.2603 - accuracy: 0.8315 - val_loss: 0.2585 - val_accuracy: 0.8309 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 45/600\n",
            "1437/1437 - 9s - loss: 0.2601 - accuracy: 0.8322 - val_loss: 0.2586 - val_accuracy: 0.8326 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 46/600\n",
            "1437/1437 - 9s - loss: 0.2584 - accuracy: 0.8320 - val_loss: 0.2570 - val_accuracy: 0.8323 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 47/600\n",
            "1437/1437 - 9s - loss: 0.2583 - accuracy: 0.8323 - val_loss: 0.2567 - val_accuracy: 0.8350 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 48/600\n",
            "1437/1437 - 9s - loss: 0.2583 - accuracy: 0.8329 - val_loss: 0.2571 - val_accuracy: 0.8328 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 49/600\n",
            "1437/1437 - 9s - loss: 0.2582 - accuracy: 0.8321 - val_loss: 0.2568 - val_accuracy: 0.8331 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 50/600\n",
            "1437/1437 - 9s - loss: 0.2580 - accuracy: 0.8325 - val_loss: 0.2564 - val_accuracy: 0.8347 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 51/600\n",
            "1437/1437 - 9s - loss: 0.2579 - accuracy: 0.8330 - val_loss: 0.2564 - val_accuracy: 0.8345 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 52/600\n",
            "1437/1437 - 9s - loss: 0.2581 - accuracy: 0.8327 - val_loss: 0.2563 - val_accuracy: 0.8335 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 53/600\n",
            "1437/1437 - 9s - loss: 0.2578 - accuracy: 0.8321 - val_loss: 0.2565 - val_accuracy: 0.8340 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 54/600\n",
            "1437/1437 - 9s - loss: 0.2571 - accuracy: 0.8332 - val_loss: 0.2555 - val_accuracy: 0.8350 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 55/600\n",
            "1437/1437 - 9s - loss: 0.2571 - accuracy: 0.8326 - val_loss: 0.2556 - val_accuracy: 0.8345 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 56/600\n",
            "1437/1437 - 9s - loss: 0.2569 - accuracy: 0.8338 - val_loss: 0.2555 - val_accuracy: 0.8326 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 57/600\n",
            "1437/1437 - 9s - loss: 0.2569 - accuracy: 0.8336 - val_loss: 0.2555 - val_accuracy: 0.8357 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 58/600\n",
            "1437/1437 - 9s - loss: 0.2564 - accuracy: 0.8331 - val_loss: 0.2551 - val_accuracy: 0.8327 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 59/600\n",
            "1437/1437 - 9s - loss: 0.2564 - accuracy: 0.8345 - val_loss: 0.2550 - val_accuracy: 0.8336 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 60/600\n",
            "1437/1437 - 9s - loss: 0.2563 - accuracy: 0.8338 - val_loss: 0.2552 - val_accuracy: 0.8339 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 61/600\n",
            "1437/1437 - 10s - loss: 0.2564 - accuracy: 0.8339 - val_loss: 0.2550 - val_accuracy: 0.8341 - lr: 3.9062e-05 - 10s/epoch - 7ms/step\n",
            "Epoch 62/600\n",
            "1437/1437 - 9s - loss: 0.2561 - accuracy: 0.8331 - val_loss: 0.2548 - val_accuracy: 0.8333 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 63/600\n",
            "1437/1437 - 9s - loss: 0.2562 - accuracy: 0.8342 - val_loss: 0.2548 - val_accuracy: 0.8333 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 64/600\n",
            "1437/1437 - 9s - loss: 0.2560 - accuracy: 0.8350 - val_loss: 0.2548 - val_accuracy: 0.8340 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 65/600\n",
            "1437/1437 - 9s - loss: 0.2561 - accuracy: 0.8330 - val_loss: 0.2548 - val_accuracy: 0.8331 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 66/600\n",
            "1437/1437 - 9s - loss: 0.2560 - accuracy: 0.8343 - val_loss: 0.2547 - val_accuracy: 0.8330 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 67/600\n",
            "1437/1437 - 9s - loss: 0.2559 - accuracy: 0.8343 - val_loss: 0.2546 - val_accuracy: 0.8341 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 68/600\n",
            "1437/1437 - 9s - loss: 0.2559 - accuracy: 0.8346 - val_loss: 0.2547 - val_accuracy: 0.8332 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 69/600\n",
            "1437/1437 - 9s - loss: 0.2559 - accuracy: 0.8343 - val_loss: 0.2546 - val_accuracy: 0.8343 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 70/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8342 - val_loss: 0.2546 - val_accuracy: 0.8341 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 71/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8354 - val_loss: 0.2546 - val_accuracy: 0.8341 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 72/600\n",
            "1437/1437 - 9s - loss: 0.2559 - accuracy: 0.8339 - val_loss: 0.2546 - val_accuracy: 0.8331 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 73/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8353 - val_loss: 0.2546 - val_accuracy: 0.8341 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 74/600\n",
            "1437/1437 - 9s - loss: 0.2559 - accuracy: 0.8340 - val_loss: 0.2546 - val_accuracy: 0.8333 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 75/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8343 - val_loss: 0.2546 - val_accuracy: 0.8335 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 76/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8345 - val_loss: 0.2546 - val_accuracy: 0.8341 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 77/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8341 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 78/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8340 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 79/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8352 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 80/600\n",
            "1437/1437 - 9s - loss: 0.2557 - accuracy: 0.8340 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 81/600\n",
            "1437/1437 - 9s - loss: 0.2557 - accuracy: 0.8348 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 82/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8339 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 83/600\n",
            "1437/1437 - 9s - loss: 0.2557 - accuracy: 0.8349 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 84/600\n",
            "1437/1437 - 9s - loss: 0.2557 - accuracy: 0.8352 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 85/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8343 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 86/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8353 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 87/600\n",
            "1437/1437 - 9s - loss: 0.2559 - accuracy: 0.8339 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 88/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8345 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 89/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8338 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 90/600\n",
            "1437/1437 - 9s - loss: 0.2559 - accuracy: 0.8337 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 91/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8340 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 92/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8342 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 93/600\n",
            "1437/1437 - 9s - loss: 0.2557 - accuracy: 0.8346 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 94/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8343 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 3.8147e-08 - 9s/epoch - 7ms/step\n",
            "Epoch 95/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8337 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 96/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8349 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 97/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8347 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 98/600\n",
            "1437/1437 - 9s - loss: 0.2557 - accuracy: 0.8348 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 99/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8343 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 100/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8347 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 101/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8344 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 102/600\n",
            "1437/1437 - 9s - loss: 0.2559 - accuracy: 0.8336 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 103/600\n",
            "1437/1437 - 9s - loss: 0.2557 - accuracy: 0.8341 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 104/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8342 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 105/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8338 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 106/600\n",
            "1437/1437 - 9s - loss: 0.2557 - accuracy: 0.8352 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 107/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8351 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 108/600\n",
            "1437/1437 - 9s - loss: 0.2558 - accuracy: 0.8352 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 109/600\n",
            "1437/1437 - 9s - loss: 0.2557 - accuracy: 0.8356 - val_loss: 0.2545 - val_accuracy: 0.8333 - lr: 1.1921e-09 - 9s/epoch - 7ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " ...\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " ...\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ...  6 12 14]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12  2]\n",
            " ...\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ...  6 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ... 14 11 20]\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 20]\n",
            " ...\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 20]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 20 25 15]\n",
            " ...\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 20 25  7]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ...  7 18 13]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 23]\n",
            " ...\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ...  7 18 23]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 23 17  9]\n",
            " ...\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  9]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " ...\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21  4]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " ...\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  8]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " ...\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]]\n",
            "[[28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " ...\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_6 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1439/1439 - 13s - loss: 0.8845 - accuracy: 0.7678 - val_loss: 0.4852 - val_accuracy: 0.8266 - lr: 0.0050 - 13s/epoch - 9ms/step\n",
            "Epoch 2/600\n",
            "1439/1439 - 9s - loss: 0.4676 - accuracy: 0.8237 - val_loss: 0.3739 - val_accuracy: 0.8309 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 3/600\n",
            "1439/1439 - 9s - loss: 0.3905 - accuracy: 0.8258 - val_loss: 0.6784 - val_accuracy: 0.7947 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 4/600\n",
            "1439/1439 - 9s - loss: 0.4025 - accuracy: 0.8269 - val_loss: 0.3379 - val_accuracy: 0.8320 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 5/600\n",
            "1439/1439 - 9s - loss: 0.3726 - accuracy: 0.8260 - val_loss: 0.3249 - val_accuracy: 0.8316 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 6/600\n",
            "1439/1439 - 9s - loss: 0.3983 - accuracy: 0.8252 - val_loss: 0.4062 - val_accuracy: 0.8298 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 7/600\n",
            "1439/1439 - 9s - loss: 0.3383 - accuracy: 0.8279 - val_loss: 0.4580 - val_accuracy: 0.8298 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 8/600\n",
            "1439/1439 - 9s - loss: 0.3622 - accuracy: 0.8268 - val_loss: 0.3241 - val_accuracy: 0.8318 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 9/600\n",
            "1439/1439 - 9s - loss: 0.3419 - accuracy: 0.8270 - val_loss: 0.3080 - val_accuracy: 0.8307 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 10/600\n",
            "1439/1439 - 9s - loss: 0.4805 - accuracy: 0.8231 - val_loss: 0.3786 - val_accuracy: 0.8297 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 11/600\n",
            "1439/1439 - 9s - loss: 0.3621 - accuracy: 0.8276 - val_loss: 0.3246 - val_accuracy: 0.8327 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 12/600\n",
            "1439/1439 - 9s - loss: 0.5376 - accuracy: 0.8206 - val_loss: 0.3606 - val_accuracy: 0.8326 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 13/600\n",
            "1439/1439 - 9s - loss: 0.3295 - accuracy: 0.8290 - val_loss: 0.3074 - val_accuracy: 0.8332 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 14/600\n",
            "1439/1439 - 9s - loss: 0.3105 - accuracy: 0.8296 - val_loss: 0.2961 - val_accuracy: 0.8309 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 15/600\n",
            "1439/1439 - 9s - loss: 0.2973 - accuracy: 0.8299 - val_loss: 0.2908 - val_accuracy: 0.8295 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 16/600\n",
            "1439/1439 - 9s - loss: 0.3497 - accuracy: 0.8264 - val_loss: 0.3178 - val_accuracy: 0.8285 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 17/600\n",
            "1439/1439 - 9s - loss: 0.3263 - accuracy: 0.8273 - val_loss: 0.3042 - val_accuracy: 0.8305 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 18/600\n",
            "1439/1439 - 9s - loss: 0.3064 - accuracy: 0.8285 - val_loss: 0.2860 - val_accuracy: 0.8309 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 19/600\n",
            "1439/1439 - 9s - loss: 0.2892 - accuracy: 0.8295 - val_loss: 0.3903 - val_accuracy: 0.7969 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 20/600\n",
            "1439/1439 - 9s - loss: 0.3068 - accuracy: 0.8285 - val_loss: 0.2843 - val_accuracy: 0.8311 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 21/600\n",
            "1439/1439 - 9s - loss: 0.2870 - accuracy: 0.8298 - val_loss: 0.2815 - val_accuracy: 0.8329 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 22/600\n",
            "1439/1439 - 9s - loss: 0.3147 - accuracy: 0.8281 - val_loss: 0.2841 - val_accuracy: 0.8318 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 23/600\n",
            "1439/1439 - 9s - loss: 0.3077 - accuracy: 0.8283 - val_loss: 0.2855 - val_accuracy: 0.8332 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 24/600\n",
            "1439/1439 - 9s - loss: 0.2862 - accuracy: 0.8308 - val_loss: 0.2826 - val_accuracy: 0.8320 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 25/600\n",
            "1439/1439 - 9s - loss: 0.2768 - accuracy: 0.8306 - val_loss: 0.2726 - val_accuracy: 0.8330 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 26/600\n",
            "1439/1439 - 9s - loss: 0.2761 - accuracy: 0.8310 - val_loss: 0.2724 - val_accuracy: 0.8318 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 27/600\n",
            "1439/1439 - 9s - loss: 0.3110 - accuracy: 0.8284 - val_loss: 0.2782 - val_accuracy: 0.8318 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 28/600\n",
            "1439/1439 - 9s - loss: 0.2780 - accuracy: 0.8313 - val_loss: 0.2722 - val_accuracy: 0.8348 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 29/600\n",
            "1439/1439 - 9s - loss: 0.2761 - accuracy: 0.8323 - val_loss: 0.2736 - val_accuracy: 0.8316 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 30/600\n",
            "1439/1439 - 9s - loss: 0.2795 - accuracy: 0.8325 - val_loss: 0.2785 - val_accuracy: 0.8347 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 31/600\n",
            "1439/1439 - 9s - loss: 0.2800 - accuracy: 0.8321 - val_loss: 0.2728 - val_accuracy: 0.8317 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 32/600\n",
            "1439/1439 - 9s - loss: 0.2703 - accuracy: 0.8323 - val_loss: 0.2675 - val_accuracy: 0.8341 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 33/600\n",
            "1439/1439 - 9s - loss: 0.2694 - accuracy: 0.8338 - val_loss: 0.2668 - val_accuracy: 0.8327 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 34/600\n",
            "1439/1439 - 9s - loss: 0.2692 - accuracy: 0.8341 - val_loss: 0.2667 - val_accuracy: 0.8345 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 35/600\n",
            "1439/1439 - 9s - loss: 0.2770 - accuracy: 0.8337 - val_loss: 0.2679 - val_accuracy: 0.8335 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 36/600\n",
            "1439/1439 - 9s - loss: 0.2687 - accuracy: 0.8338 - val_loss: 0.2657 - val_accuracy: 0.8349 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 37/600\n",
            "1439/1439 - 9s - loss: 0.2683 - accuracy: 0.8335 - val_loss: 0.2664 - val_accuracy: 0.8320 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 38/600\n",
            "1439/1439 - 9s - loss: 0.2684 - accuracy: 0.8339 - val_loss: 0.2655 - val_accuracy: 0.8348 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 39/600\n",
            "1439/1439 - 9s - loss: 0.2681 - accuracy: 0.8343 - val_loss: 0.2655 - val_accuracy: 0.8329 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 40/600\n",
            "1439/1439 - 9s - loss: 0.2684 - accuracy: 0.8334 - val_loss: 0.2649 - val_accuracy: 0.8337 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 41/600\n",
            "1439/1439 - 9s - loss: 0.2673 - accuracy: 0.8345 - val_loss: 0.2656 - val_accuracy: 0.8378 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 42/600\n",
            "1439/1439 - 9s - loss: 0.2806 - accuracy: 0.8320 - val_loss: 0.2656 - val_accuracy: 0.8346 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 43/600\n",
            "1439/1439 - 9s - loss: 0.2677 - accuracy: 0.8340 - val_loss: 0.2652 - val_accuracy: 0.8333 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 44/600\n",
            "1439/1439 - 9s - loss: 0.2650 - accuracy: 0.8347 - val_loss: 0.2629 - val_accuracy: 0.8343 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 45/600\n",
            "1439/1439 - 9s - loss: 0.2649 - accuracy: 0.8344 - val_loss: 0.2625 - val_accuracy: 0.8342 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 46/600\n",
            "1439/1439 - 9s - loss: 0.2648 - accuracy: 0.8345 - val_loss: 0.2622 - val_accuracy: 0.8348 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 47/600\n",
            "1439/1439 - 9s - loss: 0.2647 - accuracy: 0.8337 - val_loss: 0.2624 - val_accuracy: 0.8343 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 48/600\n",
            "1439/1439 - 9s - loss: 0.2644 - accuracy: 0.8341 - val_loss: 0.2623 - val_accuracy: 0.8354 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 49/600\n",
            "1439/1439 - 9s - loss: 0.2673 - accuracy: 0.8336 - val_loss: 0.2620 - val_accuracy: 0.8345 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 50/600\n",
            "1439/1439 - 9s - loss: 0.2642 - accuracy: 0.8341 - val_loss: 0.2619 - val_accuracy: 0.8343 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 51/600\n",
            "1439/1439 - 9s - loss: 0.2643 - accuracy: 0.8341 - val_loss: 0.2622 - val_accuracy: 0.8352 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 52/600\n",
            "1439/1439 - 9s - loss: 0.2642 - accuracy: 0.8347 - val_loss: 0.2617 - val_accuracy: 0.8349 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 53/600\n",
            "1439/1439 - 9s - loss: 0.2643 - accuracy: 0.8339 - val_loss: 0.2618 - val_accuracy: 0.8358 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 54/600\n",
            "1439/1439 - 9s - loss: 0.2641 - accuracy: 0.8349 - val_loss: 0.2622 - val_accuracy: 0.8350 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 55/600\n",
            "1439/1439 - 9s - loss: 0.2642 - accuracy: 0.8350 - val_loss: 0.2617 - val_accuracy: 0.8355 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 56/600\n",
            "1439/1439 - 9s - loss: 0.2628 - accuracy: 0.8339 - val_loss: 0.2607 - val_accuracy: 0.8357 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 57/600\n",
            "1439/1439 - 9s - loss: 0.2629 - accuracy: 0.8345 - val_loss: 0.2605 - val_accuracy: 0.8326 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 58/600\n",
            "1439/1439 - 9s - loss: 0.2628 - accuracy: 0.8343 - val_loss: 0.2602 - val_accuracy: 0.8357 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 59/600\n",
            "1439/1439 - 9s - loss: 0.2626 - accuracy: 0.8349 - val_loss: 0.2603 - val_accuracy: 0.8365 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 60/600\n",
            "1439/1439 - 9s - loss: 0.2625 - accuracy: 0.8351 - val_loss: 0.2603 - val_accuracy: 0.8358 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 61/600\n",
            "1439/1439 - 9s - loss: 0.2626 - accuracy: 0.8352 - val_loss: 0.2610 - val_accuracy: 0.8344 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 62/600\n",
            "1439/1439 - 9s - loss: 0.2618 - accuracy: 0.8354 - val_loss: 0.2597 - val_accuracy: 0.8348 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 63/600\n",
            "1439/1439 - 9s - loss: 0.2618 - accuracy: 0.8355 - val_loss: 0.2596 - val_accuracy: 0.8351 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 64/600\n",
            "1439/1439 - 9s - loss: 0.2618 - accuracy: 0.8340 - val_loss: 0.2596 - val_accuracy: 0.8334 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 65/600\n",
            "1439/1439 - 9s - loss: 0.2617 - accuracy: 0.8355 - val_loss: 0.2595 - val_accuracy: 0.8363 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 66/600\n",
            "1439/1439 - 9s - loss: 0.2617 - accuracy: 0.8349 - val_loss: 0.2595 - val_accuracy: 0.8354 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 67/600\n",
            "1439/1439 - 9s - loss: 0.2617 - accuracy: 0.8355 - val_loss: 0.2595 - val_accuracy: 0.8354 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 68/600\n",
            "1439/1439 - 9s - loss: 0.2616 - accuracy: 0.8359 - val_loss: 0.2594 - val_accuracy: 0.8363 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 69/600\n",
            "1439/1439 - 9s - loss: 0.2613 - accuracy: 0.8354 - val_loss: 0.2591 - val_accuracy: 0.8359 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 70/600\n",
            "1439/1439 - 9s - loss: 0.2612 - accuracy: 0.8364 - val_loss: 0.2591 - val_accuracy: 0.8353 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 71/600\n",
            "1439/1439 - 9s - loss: 0.2612 - accuracy: 0.8364 - val_loss: 0.2591 - val_accuracy: 0.8366 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 72/600\n",
            "1439/1439 - 9s - loss: 0.2613 - accuracy: 0.8360 - val_loss: 0.2591 - val_accuracy: 0.8362 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 73/600\n",
            "1439/1439 - 9s - loss: 0.2611 - accuracy: 0.8352 - val_loss: 0.2590 - val_accuracy: 0.8358 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 74/600\n",
            "1439/1439 - 9s - loss: 0.2609 - accuracy: 0.8355 - val_loss: 0.2589 - val_accuracy: 0.8355 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 75/600\n",
            "1439/1439 - 9s - loss: 0.2610 - accuracy: 0.8361 - val_loss: 0.2589 - val_accuracy: 0.8357 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 76/600\n",
            "1439/1439 - 9s - loss: 0.2610 - accuracy: 0.8363 - val_loss: 0.2589 - val_accuracy: 0.8363 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 77/600\n",
            "1439/1439 - 9s - loss: 0.2609 - accuracy: 0.8361 - val_loss: 0.2588 - val_accuracy: 0.8358 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 78/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8354 - val_loss: 0.2588 - val_accuracy: 0.8357 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 79/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8356 - val_loss: 0.2588 - val_accuracy: 0.8356 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 80/600\n",
            "1439/1439 - 9s - loss: 0.2609 - accuracy: 0.8353 - val_loss: 0.2588 - val_accuracy: 0.8356 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 81/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8354 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 82/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8357 - val_loss: 0.2588 - val_accuracy: 0.8364 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 83/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8356 - val_loss: 0.2587 - val_accuracy: 0.8361 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 84/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8360 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 85/600\n",
            "1439/1439 - 9s - loss: 0.2609 - accuracy: 0.8354 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 86/600\n",
            "1439/1439 - 9s - loss: 0.2607 - accuracy: 0.8356 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 87/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8360 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 88/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8365 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 89/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8352 - val_loss: 0.2587 - val_accuracy: 0.8361 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 90/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8362 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 91/600\n",
            "1439/1439 - 9s - loss: 0.2607 - accuracy: 0.8361 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 92/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8349 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 93/600\n",
            "1439/1439 - 9s - loss: 0.2609 - accuracy: 0.8363 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 94/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8360 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 95/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8361 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 96/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8352 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 97/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8355 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 98/600\n",
            "1439/1439 - 9s - loss: 0.2609 - accuracy: 0.8349 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 99/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8354 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 100/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8364 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 101/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8359 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 102/600\n",
            "1439/1439 - 9s - loss: 0.2607 - accuracy: 0.8359 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 103/600\n",
            "1439/1439 - 9s - loss: 0.2607 - accuracy: 0.8360 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 104/600\n",
            "1439/1439 - 9s - loss: 0.2607 - accuracy: 0.8358 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 105/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8360 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 106/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8354 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 107/600\n",
            "1439/1439 - 9s - loss: 0.2609 - accuracy: 0.8347 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 108/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8364 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 109/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8362 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 110/600\n",
            "1439/1439 - 9s - loss: 0.2609 - accuracy: 0.8361 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 111/600\n",
            "1439/1439 - 9s - loss: 0.2607 - accuracy: 0.8356 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 112/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8363 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 113/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8362 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 114/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8361 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 115/600\n",
            "1439/1439 - 9s - loss: 0.2607 - accuracy: 0.8360 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 116/600\n",
            "1439/1439 - 9s - loss: 0.2609 - accuracy: 0.8357 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 117/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8362 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 118/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8362 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 119/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8357 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 120/600\n",
            "1439/1439 - 9s - loss: 0.2608 - accuracy: 0.8355 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 121/600\n",
            "1439/1439 - 9s - loss: 0.2609 - accuracy: 0.8355 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 5.9605e-10 - 9s/epoch - 6ms/step\n",
            "Epoch 122/600\n",
            "1439/1439 - 9s - loss: 0.2607 - accuracy: 0.8361 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 5.9605e-10 - 9s/epoch - 6ms/step\n",
            "Epoch 123/600\n",
            "1439/1439 - 9s - loss: 0.2607 - accuracy: 0.8360 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 5.9605e-10 - 9s/epoch - 6ms/step\n",
            "Epoch 124/600\n",
            "1439/1439 - 9s - loss: 0.2607 - accuracy: 0.8361 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 2.9802e-10 - 9s/epoch - 6ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " ...\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " ...\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ...  6 12  2]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12 14]\n",
            " ...\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12  2]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 24]\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ... 14 11 24]\n",
            " ...\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ...  2 11 24]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25  7]\n",
            " ...\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 24 25  7]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " ...\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ...  7 18 13]\n",
            " ...\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ...  7 18 13]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " ...\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  9]\n",
            " ...\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 13 17  1]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " ...\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  1 21  4]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ... 22  3  8]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " ...\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " ...\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " ...\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_7 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1435/1435 - 13s - loss: 0.6245 - accuracy: 0.7908 - val_loss: 0.4233 - val_accuracy: 0.7958 - lr: 0.0050 - 13s/epoch - 9ms/step\n",
            "Epoch 2/600\n",
            "1435/1435 - 9s - loss: 0.4530 - accuracy: 0.8241 - val_loss: 0.3974 - val_accuracy: 0.8318 - lr: 0.0050 - 9s/epoch - 7ms/step\n",
            "Epoch 3/600\n",
            "1435/1435 - 9s - loss: 0.3654 - accuracy: 0.8287 - val_loss: 0.3260 - val_accuracy: 0.8246 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 4/600\n",
            "1435/1435 - 9s - loss: 0.4516 - accuracy: 0.8245 - val_loss: 0.3285 - val_accuracy: 0.8325 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 5/600\n",
            "1435/1435 - 9s - loss: 0.3537 - accuracy: 0.8281 - val_loss: 0.3156 - val_accuracy: 0.8252 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 6/600\n",
            "1435/1435 - 10s - loss: 0.4408 - accuracy: 0.8228 - val_loss: 0.3304 - val_accuracy: 0.8329 - lr: 0.0050 - 10s/epoch - 7ms/step\n",
            "Epoch 7/600\n",
            "1435/1435 - 9s - loss: 0.3626 - accuracy: 0.8288 - val_loss: 0.3589 - val_accuracy: 0.8287 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 8/600\n",
            "1435/1435 - 9s - loss: 0.3381 - accuracy: 0.8274 - val_loss: 0.3351 - val_accuracy: 0.8318 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 9/600\n",
            "1435/1435 - 9s - loss: 0.2995 - accuracy: 0.8320 - val_loss: 0.2870 - val_accuracy: 0.8345 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 10/600\n",
            "1435/1435 - 9s - loss: 0.3119 - accuracy: 0.8294 - val_loss: 0.2915 - val_accuracy: 0.8278 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 11/600\n",
            "1435/1435 - 9s - loss: 0.2893 - accuracy: 0.8314 - val_loss: 0.2834 - val_accuracy: 0.8268 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 12/600\n",
            "1435/1435 - 9s - loss: 0.3134 - accuracy: 0.8293 - val_loss: 0.2842 - val_accuracy: 0.8305 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 13/600\n",
            "1435/1435 - 9s - loss: 0.2883 - accuracy: 0.8307 - val_loss: 0.2816 - val_accuracy: 0.8329 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 14/600\n",
            "1435/1435 - 9s - loss: 0.3096 - accuracy: 0.8294 - val_loss: 0.2803 - val_accuracy: 0.8326 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 15/600\n",
            "1435/1435 - 9s - loss: 0.2867 - accuracy: 0.8310 - val_loss: 0.2795 - val_accuracy: 0.8290 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 16/600\n",
            "1435/1435 - 9s - loss: 0.3211 - accuracy: 0.8281 - val_loss: 0.2847 - val_accuracy: 0.8344 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 17/600\n",
            "1435/1435 - 9s - loss: 0.2902 - accuracy: 0.8314 - val_loss: 0.2796 - val_accuracy: 0.8337 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 18/600\n",
            "1435/1435 - 9s - loss: 0.3080 - accuracy: 0.8288 - val_loss: 0.2834 - val_accuracy: 0.8324 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 19/600\n",
            "1435/1435 - 9s - loss: 0.2752 - accuracy: 0.8331 - val_loss: 0.2707 - val_accuracy: 0.8364 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 20/600\n",
            "1435/1435 - 9s - loss: 0.2727 - accuracy: 0.8326 - val_loss: 0.2699 - val_accuracy: 0.8339 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 21/600\n",
            "1435/1435 - 9s - loss: 0.2796 - accuracy: 0.8315 - val_loss: 0.2685 - val_accuracy: 0.8266 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 22/600\n",
            "1435/1435 - 9s - loss: 0.2716 - accuracy: 0.8324 - val_loss: 0.2869 - val_accuracy: 0.8353 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 23/600\n",
            "1435/1435 - 9s - loss: 0.2705 - accuracy: 0.8328 - val_loss: 0.2683 - val_accuracy: 0.8303 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 24/600\n",
            "1435/1435 - 9s - loss: 0.2804 - accuracy: 0.8316 - val_loss: 0.2672 - val_accuracy: 0.8357 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 25/600\n",
            "1435/1435 - 9s - loss: 0.2685 - accuracy: 0.8323 - val_loss: 0.2664 - val_accuracy: 0.8289 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 26/600\n",
            "1435/1435 - 9s - loss: 0.2735 - accuracy: 0.8317 - val_loss: 0.2673 - val_accuracy: 0.8309 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 27/600\n",
            "1435/1435 - 9s - loss: 0.2898 - accuracy: 0.8308 - val_loss: 0.2801 - val_accuracy: 0.8360 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 28/600\n",
            "1435/1435 - 9s - loss: 0.2704 - accuracy: 0.8333 - val_loss: 0.2659 - val_accuracy: 0.8341 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 29/600\n",
            "1435/1435 - 9s - loss: 0.2679 - accuracy: 0.8328 - val_loss: 0.2655 - val_accuracy: 0.8356 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 30/600\n",
            "1435/1435 - 9s - loss: 0.2725 - accuracy: 0.8324 - val_loss: 0.2655 - val_accuracy: 0.8356 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 31/600\n",
            "1435/1435 - 9s - loss: 0.2845 - accuracy: 0.8317 - val_loss: 0.2669 - val_accuracy: 0.8360 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 32/600\n",
            "1435/1435 - 9s - loss: 0.2682 - accuracy: 0.8322 - val_loss: 0.2662 - val_accuracy: 0.8348 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 33/600\n",
            "1435/1435 - 9s - loss: 0.2628 - accuracy: 0.8339 - val_loss: 0.2609 - val_accuracy: 0.8343 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 34/600\n",
            "1435/1435 - 9s - loss: 0.2677 - accuracy: 0.8340 - val_loss: 0.2622 - val_accuracy: 0.8358 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 35/600\n",
            "1435/1435 - 9s - loss: 0.2623 - accuracy: 0.8340 - val_loss: 0.2602 - val_accuracy: 0.8352 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 36/600\n",
            "1435/1435 - 9s - loss: 0.2620 - accuracy: 0.8338 - val_loss: 0.2600 - val_accuracy: 0.8349 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 37/600\n",
            "1435/1435 - 9s - loss: 0.2640 - accuracy: 0.8334 - val_loss: 0.2603 - val_accuracy: 0.8372 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 38/600\n",
            "1435/1435 - 9s - loss: 0.2616 - accuracy: 0.8350 - val_loss: 0.2601 - val_accuracy: 0.8368 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 39/600\n",
            "1435/1435 - 9s - loss: 0.2673 - accuracy: 0.8325 - val_loss: 0.2616 - val_accuracy: 0.8351 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 40/600\n",
            "1435/1435 - 9s - loss: 0.2595 - accuracy: 0.8345 - val_loss: 0.2575 - val_accuracy: 0.8360 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 41/600\n",
            "1435/1435 - 9s - loss: 0.2591 - accuracy: 0.8347 - val_loss: 0.2573 - val_accuracy: 0.8362 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 42/600\n",
            "1435/1435 - 9s - loss: 0.2588 - accuracy: 0.8336 - val_loss: 0.2572 - val_accuracy: 0.8366 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 43/600\n",
            "1435/1435 - 9s - loss: 0.2590 - accuracy: 0.8348 - val_loss: 0.2577 - val_accuracy: 0.8353 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 44/600\n",
            "1435/1435 - 9s - loss: 0.2585 - accuracy: 0.8344 - val_loss: 0.2574 - val_accuracy: 0.8338 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 45/600\n",
            "1435/1435 - 9s - loss: 0.2587 - accuracy: 0.8346 - val_loss: 0.2573 - val_accuracy: 0.8345 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 46/600\n",
            "1435/1435 - 9s - loss: 0.2569 - accuracy: 0.8338 - val_loss: 0.2558 - val_accuracy: 0.8353 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 47/600\n",
            "1435/1435 - 9s - loss: 0.2567 - accuracy: 0.8350 - val_loss: 0.2560 - val_accuracy: 0.8336 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 48/600\n",
            "1435/1435 - 9s - loss: 0.2565 - accuracy: 0.8349 - val_loss: 0.2554 - val_accuracy: 0.8364 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 49/600\n",
            "1435/1435 - 9s - loss: 0.2566 - accuracy: 0.8343 - val_loss: 0.2555 - val_accuracy: 0.8340 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 50/600\n",
            "1435/1435 - 9s - loss: 0.2564 - accuracy: 0.8343 - val_loss: 0.2549 - val_accuracy: 0.8354 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 51/600\n",
            "1435/1435 - 9s - loss: 0.2564 - accuracy: 0.8347 - val_loss: 0.2549 - val_accuracy: 0.8375 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 52/600\n",
            "1435/1435 - 9s - loss: 0.2565 - accuracy: 0.8338 - val_loss: 0.2548 - val_accuracy: 0.8358 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 53/600\n",
            "1435/1435 - 9s - loss: 0.2563 - accuracy: 0.8355 - val_loss: 0.2549 - val_accuracy: 0.8341 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 54/600\n",
            "1435/1435 - 9s - loss: 0.2553 - accuracy: 0.8357 - val_loss: 0.2540 - val_accuracy: 0.8348 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 55/600\n",
            "1435/1435 - 9s - loss: 0.2552 - accuracy: 0.8357 - val_loss: 0.2539 - val_accuracy: 0.8365 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 56/600\n",
            "1435/1435 - 9s - loss: 0.2553 - accuracy: 0.8360 - val_loss: 0.2540 - val_accuracy: 0.8357 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 57/600\n",
            "1435/1435 - 9s - loss: 0.2552 - accuracy: 0.8345 - val_loss: 0.2537 - val_accuracy: 0.8353 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 58/600\n",
            "1435/1435 - 9s - loss: 0.2552 - accuracy: 0.8344 - val_loss: 0.2539 - val_accuracy: 0.8363 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 59/600\n",
            "1435/1435 - 9s - loss: 0.2551 - accuracy: 0.8345 - val_loss: 0.2538 - val_accuracy: 0.8362 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 60/600\n",
            "1435/1435 - 9s - loss: 0.2551 - accuracy: 0.8344 - val_loss: 0.2537 - val_accuracy: 0.8373 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 61/600\n",
            "1435/1435 - 9s - loss: 0.2546 - accuracy: 0.8355 - val_loss: 0.2532 - val_accuracy: 0.8375 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 62/600\n",
            "1435/1435 - 9s - loss: 0.2546 - accuracy: 0.8350 - val_loss: 0.2532 - val_accuracy: 0.8357 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 63/600\n",
            "1435/1435 - 9s - loss: 0.2545 - accuracy: 0.8347 - val_loss: 0.2533 - val_accuracy: 0.8361 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 64/600\n",
            "1435/1435 - 9s - loss: 0.2546 - accuracy: 0.8342 - val_loss: 0.2532 - val_accuracy: 0.8357 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 65/600\n",
            "1435/1435 - 9s - loss: 0.2543 - accuracy: 0.8346 - val_loss: 0.2530 - val_accuracy: 0.8375 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 66/600\n",
            "1435/1435 - 9s - loss: 0.2542 - accuracy: 0.8362 - val_loss: 0.2529 - val_accuracy: 0.8361 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 67/600\n",
            "1435/1435 - 9s - loss: 0.2543 - accuracy: 0.8348 - val_loss: 0.2529 - val_accuracy: 0.8375 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 68/600\n",
            "1435/1435 - 9s - loss: 0.2542 - accuracy: 0.8352 - val_loss: 0.2530 - val_accuracy: 0.8366 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 69/600\n",
            "1435/1435 - 9s - loss: 0.2540 - accuracy: 0.8357 - val_loss: 0.2529 - val_accuracy: 0.8370 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 70/600\n",
            "1435/1435 - 9s - loss: 0.2540 - accuracy: 0.8348 - val_loss: 0.2528 - val_accuracy: 0.8370 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 71/600\n",
            "1435/1435 - 9s - loss: 0.2540 - accuracy: 0.8348 - val_loss: 0.2528 - val_accuracy: 0.8375 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 72/600\n",
            "1435/1435 - 9s - loss: 0.2540 - accuracy: 0.8351 - val_loss: 0.2528 - val_accuracy: 0.8375 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 73/600\n",
            "1435/1435 - 9s - loss: 0.2539 - accuracy: 0.8357 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 74/600\n",
            "1435/1435 - 9s - loss: 0.2539 - accuracy: 0.8360 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 75/600\n",
            "1435/1435 - 9s - loss: 0.2539 - accuracy: 0.8351 - val_loss: 0.2528 - val_accuracy: 0.8361 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 76/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8360 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 77/600\n",
            "1435/1435 - 9s - loss: 0.2539 - accuracy: 0.8356 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 78/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8355 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 79/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8358 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 80/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8367 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 81/600\n",
            "1435/1435 - 9s - loss: 0.2539 - accuracy: 0.8351 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 82/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8362 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 83/600\n",
            "1435/1435 - 9s - loss: 0.2539 - accuracy: 0.8356 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 84/600\n",
            "1435/1435 - 9s - loss: 0.2537 - accuracy: 0.8353 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 85/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8353 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 86/600\n",
            "1435/1435 - 9s - loss: 0.2539 - accuracy: 0.8354 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 87/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8359 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 88/600\n",
            "1435/1435 - 9s - loss: 0.2539 - accuracy: 0.8346 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 89/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8357 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 90/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8355 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 91/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8353 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 92/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8346 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 93/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8349 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 94/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8345 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 95/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8359 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 96/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8362 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 97/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8348 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 98/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8356 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 99/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8354 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 100/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8356 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 101/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8363 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 102/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8358 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 103/600\n",
            "1435/1435 - 9s - loss: 0.2537 - accuracy: 0.8357 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 104/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8360 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 105/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8349 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 106/600\n",
            "1435/1435 - 9s - loss: 0.2539 - accuracy: 0.8351 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 107/600\n",
            "1435/1435 - 9s - loss: 0.2537 - accuracy: 0.8362 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 108/600\n",
            "1435/1435 - 9s - loss: 0.2538 - accuracy: 0.8354 - val_loss: 0.2527 - val_accuracy: 0.8366 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " ...\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " ...\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ...  6 12 14]\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12 14]\n",
            " ...\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12  2]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ... 14 11 20]\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 20]\n",
            " ...\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 20]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 20 25  7]\n",
            " ...\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ...  7 18 23]\n",
            " ...\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ... 15 18 13]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 23 17  1]\n",
            " ...\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 13 17  9]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " ...\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  1 21  4]\n",
            " ...\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  9 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  8]\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ...  4  3  8]\n",
            " ...\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ... 22  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " ...\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " ...\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_8 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1440/1440 - 13s - loss: 0.6563 - accuracy: 0.7895 - val_loss: 0.3547 - val_accuracy: 0.8333 - lr: 0.0050 - 13s/epoch - 9ms/step\n",
            "Epoch 2/600\n",
            "1440/1440 - 9s - loss: 0.3862 - accuracy: 0.8266 - val_loss: 1.8499 - val_accuracy: 0.5556 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 3/600\n",
            "1440/1440 - 9s - loss: 0.4545 - accuracy: 0.8250 - val_loss: 0.3223 - val_accuracy: 0.8288 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 4/600\n",
            "1440/1440 - 9s - loss: 0.3675 - accuracy: 0.8280 - val_loss: 0.3169 - val_accuracy: 0.8343 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 5/600\n",
            "1440/1440 - 9s - loss: 0.3768 - accuracy: 0.8272 - val_loss: 0.3231 - val_accuracy: 0.8330 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 6/600\n",
            "1440/1440 - 9s - loss: 0.4216 - accuracy: 0.8243 - val_loss: 0.3160 - val_accuracy: 0.8277 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 7/600\n",
            "1440/1440 - 9s - loss: 0.3440 - accuracy: 0.8286 - val_loss: 0.3084 - val_accuracy: 0.8327 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 8/600\n",
            "1440/1440 - 9s - loss: 0.3457 - accuracy: 0.8284 - val_loss: 0.3101 - val_accuracy: 0.8275 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 9/600\n",
            "1440/1440 - 9s - loss: 0.3582 - accuracy: 0.8266 - val_loss: 0.3111 - val_accuracy: 0.8341 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 10/600\n",
            "1440/1440 - 9s - loss: 0.4174 - accuracy: 0.8249 - val_loss: 0.3778 - val_accuracy: 0.8272 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 11/600\n",
            "1440/1440 - 9s - loss: 0.3213 - accuracy: 0.8314 - val_loss: 0.3025 - val_accuracy: 0.8327 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 12/600\n",
            "1440/1440 - 9s - loss: 0.3000 - accuracy: 0.8308 - val_loss: 0.2896 - val_accuracy: 0.8328 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 13/600\n",
            "1440/1440 - 9s - loss: 0.2966 - accuracy: 0.8322 - val_loss: 0.2846 - val_accuracy: 0.8332 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 14/600\n",
            "1440/1440 - 9s - loss: 0.2879 - accuracy: 0.8315 - val_loss: 0.2786 - val_accuracy: 0.8324 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 15/600\n",
            "1440/1440 - 9s - loss: 0.3089 - accuracy: 0.8290 - val_loss: 0.2784 - val_accuracy: 0.8335 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 16/600\n",
            "1440/1440 - 9s - loss: 0.3235 - accuracy: 0.8283 - val_loss: 0.2982 - val_accuracy: 0.8294 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 17/600\n",
            "1440/1440 - 9s - loss: 0.2930 - accuracy: 0.8314 - val_loss: 0.3057 - val_accuracy: 0.8339 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 18/600\n",
            "1440/1440 - 9s - loss: 0.3087 - accuracy: 0.8294 - val_loss: 0.3172 - val_accuracy: 0.8338 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 19/600\n",
            "1440/1440 - 9s - loss: 0.2832 - accuracy: 0.8325 - val_loss: 0.2718 - val_accuracy: 0.8345 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 20/600\n",
            "1440/1440 - 9s - loss: 0.2733 - accuracy: 0.8320 - val_loss: 0.2692 - val_accuracy: 0.8336 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 21/600\n",
            "1440/1440 - 9s - loss: 0.2723 - accuracy: 0.8325 - val_loss: 0.2685 - val_accuracy: 0.8321 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 22/600\n",
            "1440/1440 - 9s - loss: 0.2851 - accuracy: 0.8309 - val_loss: 0.2701 - val_accuracy: 0.8325 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 23/600\n",
            "1440/1440 - 9s - loss: 0.2703 - accuracy: 0.8333 - val_loss: 0.2674 - val_accuracy: 0.8331 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 24/600\n",
            "1440/1440 - 9s - loss: 0.2771 - accuracy: 0.8318 - val_loss: 0.2688 - val_accuracy: 0.8333 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 25/600\n",
            "1440/1440 - 9s - loss: 0.2695 - accuracy: 0.8332 - val_loss: 0.2657 - val_accuracy: 0.8330 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 26/600\n",
            "1440/1440 - 9s - loss: 0.2808 - accuracy: 0.8317 - val_loss: 0.2666 - val_accuracy: 0.8338 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 27/600\n",
            "1440/1440 - 9s - loss: 0.2682 - accuracy: 0.8329 - val_loss: 0.2645 - val_accuracy: 0.8340 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 28/600\n",
            "1440/1440 - 9s - loss: 0.2780 - accuracy: 0.8319 - val_loss: 0.2926 - val_accuracy: 0.8336 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 29/600\n",
            "1440/1440 - 9s - loss: 0.2696 - accuracy: 0.8330 - val_loss: 0.2646 - val_accuracy: 0.8336 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 30/600\n",
            "1440/1440 - 9s - loss: 0.2822 - accuracy: 0.8320 - val_loss: 0.2753 - val_accuracy: 0.8338 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 31/600\n",
            "1440/1440 - 9s - loss: 0.2654 - accuracy: 0.8333 - val_loss: 0.2627 - val_accuracy: 0.8342 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 32/600\n",
            "1440/1440 - 9s - loss: 0.2627 - accuracy: 0.8334 - val_loss: 0.2617 - val_accuracy: 0.8335 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 33/600\n",
            "1440/1440 - 9s - loss: 0.2625 - accuracy: 0.8328 - val_loss: 0.2602 - val_accuracy: 0.8320 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 34/600\n",
            "1440/1440 - 9s - loss: 0.2633 - accuracy: 0.8335 - val_loss: 0.2605 - val_accuracy: 0.8336 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 35/600\n",
            "1440/1440 - 9s - loss: 0.2626 - accuracy: 0.8323 - val_loss: 0.2599 - val_accuracy: 0.8325 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 36/600\n",
            "1440/1440 - 9s - loss: 0.2608 - accuracy: 0.8332 - val_loss: 0.2590 - val_accuracy: 0.8330 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 37/600\n",
            "1440/1440 - 9s - loss: 0.2669 - accuracy: 0.8322 - val_loss: 0.2617 - val_accuracy: 0.8332 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 38/600\n",
            "1440/1440 - 9s - loss: 0.2607 - accuracy: 0.8332 - val_loss: 0.2586 - val_accuracy: 0.8331 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 39/600\n",
            "1440/1440 - 9s - loss: 0.2601 - accuracy: 0.8328 - val_loss: 0.2583 - val_accuracy: 0.8283 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 40/600\n",
            "1440/1440 - 9s - loss: 0.2604 - accuracy: 0.8331 - val_loss: 0.2589 - val_accuracy: 0.8339 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 41/600\n",
            "1440/1440 - 9s - loss: 0.2609 - accuracy: 0.8336 - val_loss: 0.2577 - val_accuracy: 0.8317 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 42/600\n",
            "1440/1440 - 9s - loss: 0.2638 - accuracy: 0.8325 - val_loss: 0.2586 - val_accuracy: 0.8329 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 43/600\n",
            "1440/1440 - 9s - loss: 0.2595 - accuracy: 0.8332 - val_loss: 0.2591 - val_accuracy: 0.8327 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 44/600\n",
            "1440/1440 - 9s - loss: 0.2601 - accuracy: 0.8344 - val_loss: 0.2577 - val_accuracy: 0.8346 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 45/600\n",
            "1440/1440 - 9s - loss: 0.2565 - accuracy: 0.8338 - val_loss: 0.2552 - val_accuracy: 0.8341 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 46/600\n",
            "1440/1440 - 9s - loss: 0.2568 - accuracy: 0.8341 - val_loss: 0.2556 - val_accuracy: 0.8338 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 47/600\n",
            "1440/1440 - 9s - loss: 0.2564 - accuracy: 0.8339 - val_loss: 0.2551 - val_accuracy: 0.8333 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 48/600\n",
            "1440/1440 - 9s - loss: 0.2565 - accuracy: 0.8333 - val_loss: 0.2550 - val_accuracy: 0.8328 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 49/600\n",
            "1440/1440 - 10s - loss: 0.2558 - accuracy: 0.8343 - val_loss: 0.2549 - val_accuracy: 0.8328 - lr: 3.1250e-04 - 10s/epoch - 7ms/step\n",
            "Epoch 50/600\n",
            "1440/1440 - 9s - loss: 0.2561 - accuracy: 0.8339 - val_loss: 0.2549 - val_accuracy: 0.8332 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 51/600\n",
            "1440/1440 - 9s - loss: 0.2572 - accuracy: 0.8339 - val_loss: 0.2548 - val_accuracy: 0.8341 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 52/600\n",
            "1440/1440 - 10s - loss: 0.2557 - accuracy: 0.8335 - val_loss: 0.2543 - val_accuracy: 0.8338 - lr: 3.1250e-04 - 10s/epoch - 7ms/step\n",
            "Epoch 53/600\n",
            "1440/1440 - 9s - loss: 0.2556 - accuracy: 0.8338 - val_loss: 0.2547 - val_accuracy: 0.8343 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 54/600\n",
            "1440/1440 - 9s - loss: 0.2571 - accuracy: 0.8339 - val_loss: 0.2548 - val_accuracy: 0.8337 - lr: 3.1250e-04 - 9s/epoch - 7ms/step\n",
            "Epoch 55/600\n",
            "1440/1440 - 9s - loss: 0.2559 - accuracy: 0.8336 - val_loss: 0.2542 - val_accuracy: 0.8320 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 56/600\n",
            "1440/1440 - 9s - loss: 0.2539 - accuracy: 0.8345 - val_loss: 0.2529 - val_accuracy: 0.8338 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 57/600\n",
            "1440/1440 - 9s - loss: 0.2539 - accuracy: 0.8335 - val_loss: 0.2530 - val_accuracy: 0.8341 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 58/600\n",
            "1440/1440 - 9s - loss: 0.2538 - accuracy: 0.8345 - val_loss: 0.2530 - val_accuracy: 0.8334 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 59/600\n",
            "1440/1440 - 9s - loss: 0.2537 - accuracy: 0.8342 - val_loss: 0.2527 - val_accuracy: 0.8343 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 60/600\n",
            "1440/1440 - 9s - loss: 0.2537 - accuracy: 0.8346 - val_loss: 0.2527 - val_accuracy: 0.8352 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 61/600\n",
            "1440/1440 - 9s - loss: 0.2536 - accuracy: 0.8339 - val_loss: 0.2527 - val_accuracy: 0.8341 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 62/600\n",
            "1440/1440 - 9s - loss: 0.2536 - accuracy: 0.8343 - val_loss: 0.2528 - val_accuracy: 0.8341 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 63/600\n",
            "1440/1440 - 9s - loss: 0.2526 - accuracy: 0.8343 - val_loss: 0.2520 - val_accuracy: 0.8332 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 64/600\n",
            "1440/1440 - 9s - loss: 0.2526 - accuracy: 0.8341 - val_loss: 0.2518 - val_accuracy: 0.8352 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 65/600\n",
            "1440/1440 - 9s - loss: 0.2527 - accuracy: 0.8336 - val_loss: 0.2517 - val_accuracy: 0.8337 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 66/600\n",
            "1440/1440 - 9s - loss: 0.2525 - accuracy: 0.8344 - val_loss: 0.2518 - val_accuracy: 0.8345 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 67/600\n",
            "1440/1440 - 9s - loss: 0.2525 - accuracy: 0.8347 - val_loss: 0.2518 - val_accuracy: 0.8332 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 68/600\n",
            "1440/1440 - 9s - loss: 0.2520 - accuracy: 0.8346 - val_loss: 0.2514 - val_accuracy: 0.8337 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 69/600\n",
            "1440/1440 - 9s - loss: 0.2520 - accuracy: 0.8339 - val_loss: 0.2513 - val_accuracy: 0.8328 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 70/600\n",
            "1440/1440 - 9s - loss: 0.2520 - accuracy: 0.8343 - val_loss: 0.2514 - val_accuracy: 0.8327 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 71/600\n",
            "1440/1440 - 9s - loss: 0.2519 - accuracy: 0.8352 - val_loss: 0.2514 - val_accuracy: 0.8337 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 72/600\n",
            "1440/1440 - 9s - loss: 0.2517 - accuracy: 0.8352 - val_loss: 0.2512 - val_accuracy: 0.8327 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 73/600\n",
            "1440/1440 - 9s - loss: 0.2518 - accuracy: 0.8343 - val_loss: 0.2512 - val_accuracy: 0.8343 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 74/600\n",
            "1440/1440 - 9s - loss: 0.2517 - accuracy: 0.8354 - val_loss: 0.2511 - val_accuracy: 0.8337 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 75/600\n",
            "1440/1440 - 9s - loss: 0.2518 - accuracy: 0.8347 - val_loss: 0.2512 - val_accuracy: 0.8342 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 76/600\n",
            "1440/1440 - 9s - loss: 0.2516 - accuracy: 0.8350 - val_loss: 0.2510 - val_accuracy: 0.8338 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 77/600\n",
            "1440/1440 - 9s - loss: 0.2517 - accuracy: 0.8341 - val_loss: 0.2510 - val_accuracy: 0.8334 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 78/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8358 - val_loss: 0.2511 - val_accuracy: 0.8334 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 79/600\n",
            "1440/1440 - 9s - loss: 0.2516 - accuracy: 0.8356 - val_loss: 0.2510 - val_accuracy: 0.8328 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 80/600\n",
            "1440/1440 - 9s - loss: 0.2516 - accuracy: 0.8342 - val_loss: 0.2510 - val_accuracy: 0.8330 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 81/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8348 - val_loss: 0.2510 - val_accuracy: 0.8334 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 82/600\n",
            "1440/1440 - 9s - loss: 0.2516 - accuracy: 0.8352 - val_loss: 0.2510 - val_accuracy: 0.8336 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 83/600\n",
            "1440/1440 - 9s - loss: 0.2514 - accuracy: 0.8356 - val_loss: 0.2510 - val_accuracy: 0.8330 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 84/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8349 - val_loss: 0.2510 - val_accuracy: 0.8334 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 85/600\n",
            "1440/1440 - 9s - loss: 0.2514 - accuracy: 0.8350 - val_loss: 0.2510 - val_accuracy: 0.8330 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 86/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8349 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 87/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8345 - val_loss: 0.2509 - val_accuracy: 0.8327 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 88/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8353 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 89/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8353 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 90/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8346 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 91/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8343 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 92/600\n",
            "1440/1440 - 9s - loss: 0.2516 - accuracy: 0.8348 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 93/600\n",
            "1440/1440 - 9s - loss: 0.2514 - accuracy: 0.8346 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 94/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8344 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 95/600\n",
            "1440/1440 - 9s - loss: 0.2514 - accuracy: 0.8343 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 96/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8344 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 97/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8356 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 98/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8345 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 99/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8348 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 100/600\n",
            "1440/1440 - 9s - loss: 0.2514 - accuracy: 0.8349 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 101/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8349 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 102/600\n",
            "1440/1440 - 9s - loss: 0.2514 - accuracy: 0.8350 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 103/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8352 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 3.8147e-08 - 9s/epoch - 7ms/step\n",
            "Epoch 104/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8342 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 105/600\n",
            "1440/1440 - 9s - loss: 0.2514 - accuracy: 0.8348 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 106/600\n",
            "1440/1440 - 9s - loss: 0.2514 - accuracy: 0.8352 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 107/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8342 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 108/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8347 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 109/600\n",
            "1440/1440 - 9s - loss: 0.2514 - accuracy: 0.8350 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 110/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8348 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 111/600\n",
            "1440/1440 - 9s - loss: 0.2514 - accuracy: 0.8355 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 112/600\n",
            "1440/1440 - 9s - loss: 0.2514 - accuracy: 0.8352 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 113/600\n",
            "1440/1440 - 9s - loss: 0.2514 - accuracy: 0.8350 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 114/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8352 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 115/600\n",
            "1440/1440 - 9s - loss: 0.2514 - accuracy: 0.8354 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 116/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8349 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 117/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8349 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 118/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8344 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 119/600\n",
            "1440/1440 - 9s - loss: 0.2514 - accuracy: 0.8347 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 5.9605e-10 - 9s/epoch - 6ms/step\n",
            "Epoch 120/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8351 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 5.9605e-10 - 9s/epoch - 6ms/step\n",
            "Epoch 121/600\n",
            "1440/1440 - 9s - loss: 0.2515 - accuracy: 0.8356 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 5.9605e-10 - 9s/epoch - 6ms/step\n",
            "Epoch 122/600\n",
            "1440/1440 - 9s - loss: 0.2513 - accuracy: 0.8355 - val_loss: 0.2509 - val_accuracy: 0.8330 - lr: 2.9802e-10 - 9s/epoch - 6ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " ...\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " ...\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ... 26 12  2]\n",
            " ...\n",
            " [28 27 10 ...  6 12 14]\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12  2]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " ...\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 24]\n",
            " ...\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 24]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " ...\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25  7]\n",
            " ...\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 24 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ...  7 18 13]\n",
            " ...\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 23]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " ...\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 13 17  9]\n",
            " ...\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  1]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  9 21  4]\n",
            " ...\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21  4]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  8]\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ...  4  3  5]\n",
            " ...\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  8]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " ...\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]]\n",
            "[[28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " ...\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_9 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1438/1438 - 13s - loss: 0.6442 - accuracy: 0.7954 - val_loss: 0.3435 - val_accuracy: 0.8257 - lr: 0.0050 - 13s/epoch - 9ms/step\n",
            "Epoch 2/600\n",
            "1438/1438 - 9s - loss: 0.4309 - accuracy: 0.8235 - val_loss: 0.3490 - val_accuracy: 0.8326 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 3/600\n",
            "1438/1438 - 9s - loss: 0.3924 - accuracy: 0.8255 - val_loss: 0.4927 - val_accuracy: 0.8328 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 4/600\n",
            "1438/1438 - 9s - loss: 0.3796 - accuracy: 0.8265 - val_loss: 0.3242 - val_accuracy: 0.8179 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 5/600\n",
            "1438/1438 - 9s - loss: 0.3404 - accuracy: 0.8285 - val_loss: 0.3148 - val_accuracy: 0.8324 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 6/600\n",
            "1438/1438 - 9s - loss: 0.3196 - accuracy: 0.8290 - val_loss: 0.3049 - val_accuracy: 0.8313 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 7/600\n",
            "1438/1438 - 9s - loss: 0.4527 - accuracy: 0.8234 - val_loss: 0.3153 - val_accuracy: 0.8331 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 8/600\n",
            "1438/1438 - 9s - loss: 0.3434 - accuracy: 0.8280 - val_loss: 0.3135 - val_accuracy: 0.8322 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 9/600\n",
            "1438/1438 - 9s - loss: 0.3561 - accuracy: 0.8281 - val_loss: 0.3075 - val_accuracy: 0.8344 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 10/600\n",
            "1438/1438 - 9s - loss: 0.2932 - accuracy: 0.8321 - val_loss: 0.2873 - val_accuracy: 0.8333 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 11/600\n",
            "1438/1438 - 9s - loss: 0.3098 - accuracy: 0.8289 - val_loss: 0.2871 - val_accuracy: 0.8313 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 12/600\n",
            "1438/1438 - 9s - loss: 0.3036 - accuracy: 0.8294 - val_loss: 0.2863 - val_accuracy: 0.8318 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 13/600\n",
            "1438/1438 - 9s - loss: 0.2874 - accuracy: 0.8308 - val_loss: 0.2814 - val_accuracy: 0.8347 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 14/600\n",
            "1438/1438 - 9s - loss: 0.3130 - accuracy: 0.8284 - val_loss: 0.2827 - val_accuracy: 0.8303 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 15/600\n",
            "1438/1438 - 9s - loss: 0.3261 - accuracy: 0.8279 - val_loss: 0.3223 - val_accuracy: 0.8322 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 16/600\n",
            "1438/1438 - 9s - loss: 0.2971 - accuracy: 0.8314 - val_loss: 0.2852 - val_accuracy: 0.8332 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 17/600\n",
            "1438/1438 - 9s - loss: 0.2779 - accuracy: 0.8331 - val_loss: 0.2730 - val_accuracy: 0.8344 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 18/600\n",
            "1438/1438 - 9s - loss: 0.2794 - accuracy: 0.8307 - val_loss: 0.2720 - val_accuracy: 0.8343 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 19/600\n",
            "1438/1438 - 9s - loss: 0.2761 - accuracy: 0.8310 - val_loss: 0.2806 - val_accuracy: 0.8313 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 20/600\n",
            "1438/1438 - 9s - loss: 0.2799 - accuracy: 0.8315 - val_loss: 0.2734 - val_accuracy: 0.8338 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 21/600\n",
            "1438/1438 - 9s - loss: 0.2739 - accuracy: 0.8321 - val_loss: 0.2716 - val_accuracy: 0.8319 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 22/600\n",
            "1438/1438 - 9s - loss: 0.2817 - accuracy: 0.8297 - val_loss: 0.5551 - val_accuracy: 0.7953 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 23/600\n",
            "1438/1438 - 9s - loss: 0.2954 - accuracy: 0.8307 - val_loss: 0.2695 - val_accuracy: 0.8328 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 24/600\n",
            "1438/1438 - 9s - loss: 0.2710 - accuracy: 0.8304 - val_loss: 0.2676 - val_accuracy: 0.8341 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 25/600\n",
            "1438/1438 - 9s - loss: 0.2705 - accuracy: 0.8320 - val_loss: 0.2712 - val_accuracy: 0.8329 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 26/600\n",
            "1438/1438 - 9s - loss: 0.2834 - accuracy: 0.8309 - val_loss: 0.2693 - val_accuracy: 0.8276 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 27/600\n",
            "1438/1438 - 9s - loss: 0.2696 - accuracy: 0.8325 - val_loss: 0.2666 - val_accuracy: 0.8322 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 28/600\n",
            "1438/1438 - 9s - loss: 0.2889 - accuracy: 0.8293 - val_loss: 0.3314 - val_accuracy: 0.8323 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 29/600\n",
            "1438/1438 - 9s - loss: 0.2803 - accuracy: 0.8309 - val_loss: 0.2672 - val_accuracy: 0.8334 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 30/600\n",
            "1438/1438 - 9s - loss: 0.2687 - accuracy: 0.8323 - val_loss: 0.2677 - val_accuracy: 0.8289 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 31/600\n",
            "1438/1438 - 9s - loss: 0.2639 - accuracy: 0.8316 - val_loss: 0.2616 - val_accuracy: 0.8319 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 32/600\n",
            "1438/1438 - 9s - loss: 0.2638 - accuracy: 0.8322 - val_loss: 0.2612 - val_accuracy: 0.8335 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 33/600\n",
            "1438/1438 - 9s - loss: 0.2688 - accuracy: 0.8320 - val_loss: 0.2922 - val_accuracy: 0.8316 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 34/600\n",
            "1438/1438 - 9s - loss: 0.2656 - accuracy: 0.8323 - val_loss: 0.2610 - val_accuracy: 0.8322 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 35/600\n",
            "1438/1438 - 9s - loss: 0.2630 - accuracy: 0.8325 - val_loss: 0.2616 - val_accuracy: 0.8313 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 36/600\n",
            "1438/1438 - 9s - loss: 0.2641 - accuracy: 0.8313 - val_loss: 0.2606 - val_accuracy: 0.8358 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 37/600\n",
            "1438/1438 - 9s - loss: 0.2628 - accuracy: 0.8328 - val_loss: 0.2627 - val_accuracy: 0.8334 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 38/600\n",
            "1438/1438 - 9s - loss: 0.2789 - accuracy: 0.8304 - val_loss: 0.2616 - val_accuracy: 0.8338 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 39/600\n",
            "1438/1438 - 9s - loss: 0.2625 - accuracy: 0.8324 - val_loss: 0.2607 - val_accuracy: 0.8330 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 40/600\n",
            "1438/1438 - 9s - loss: 0.2600 - accuracy: 0.8337 - val_loss: 0.2582 - val_accuracy: 0.8343 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 41/600\n",
            "1438/1438 - 9s - loss: 0.2600 - accuracy: 0.8337 - val_loss: 0.2580 - val_accuracy: 0.8349 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 42/600\n",
            "1438/1438 - 9s - loss: 0.2598 - accuracy: 0.8332 - val_loss: 0.2578 - val_accuracy: 0.8331 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 43/600\n",
            "1438/1438 - 9s - loss: 0.2607 - accuracy: 0.8326 - val_loss: 0.2584 - val_accuracy: 0.8317 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 44/600\n",
            "1438/1438 - 9s - loss: 0.2596 - accuracy: 0.8342 - val_loss: 0.2581 - val_accuracy: 0.8332 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 45/600\n",
            "1438/1438 - 9s - loss: 0.2596 - accuracy: 0.8327 - val_loss: 0.2583 - val_accuracy: 0.8345 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 46/600\n",
            "1438/1438 - 9s - loss: 0.2579 - accuracy: 0.8345 - val_loss: 0.2562 - val_accuracy: 0.8336 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 47/600\n",
            "1438/1438 - 9s - loss: 0.2578 - accuracy: 0.8340 - val_loss: 0.2561 - val_accuracy: 0.8340 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 48/600\n",
            "1438/1438 - 9s - loss: 0.2578 - accuracy: 0.8329 - val_loss: 0.2562 - val_accuracy: 0.8363 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 49/600\n",
            "1438/1438 - 9s - loss: 0.2576 - accuracy: 0.8334 - val_loss: 0.2558 - val_accuracy: 0.8348 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 50/600\n",
            "1438/1438 - 9s - loss: 0.2576 - accuracy: 0.8345 - val_loss: 0.2560 - val_accuracy: 0.8333 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 51/600\n",
            "1438/1438 - 11s - loss: 0.2577 - accuracy: 0.8334 - val_loss: 0.2561 - val_accuracy: 0.8322 - lr: 1.5625e-04 - 11s/epoch - 7ms/step\n",
            "Epoch 52/600\n",
            "1438/1438 - 9s - loss: 0.2575 - accuracy: 0.8333 - val_loss: 0.2559 - val_accuracy: 0.8321 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 53/600\n",
            "1438/1438 - 9s - loss: 0.2564 - accuracy: 0.8335 - val_loss: 0.2549 - val_accuracy: 0.8357 - lr: 7.8125e-05 - 9s/epoch - 7ms/step\n",
            "Epoch 54/600\n",
            "1438/1438 - 9s - loss: 0.2563 - accuracy: 0.8352 - val_loss: 0.2549 - val_accuracy: 0.8341 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 55/600\n",
            "1438/1438 - 9s - loss: 0.2564 - accuracy: 0.8346 - val_loss: 0.2551 - val_accuracy: 0.8349 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 56/600\n",
            "1438/1438 - 9s - loss: 0.2564 - accuracy: 0.8335 - val_loss: 0.2550 - val_accuracy: 0.8352 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 57/600\n",
            "1438/1438 - 9s - loss: 0.2559 - accuracy: 0.8346 - val_loss: 0.2545 - val_accuracy: 0.8355 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 58/600\n",
            "1438/1438 - 9s - loss: 0.2558 - accuracy: 0.8332 - val_loss: 0.2545 - val_accuracy: 0.8334 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 59/600\n",
            "1438/1438 - 9s - loss: 0.2559 - accuracy: 0.8343 - val_loss: 0.2545 - val_accuracy: 0.8361 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 60/600\n",
            "1438/1438 - 9s - loss: 0.2558 - accuracy: 0.8343 - val_loss: 0.2543 - val_accuracy: 0.8347 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 61/600\n",
            "1438/1438 - 9s - loss: 0.2558 - accuracy: 0.8333 - val_loss: 0.2544 - val_accuracy: 0.8346 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 62/600\n",
            "1438/1438 - 9s - loss: 0.2557 - accuracy: 0.8350 - val_loss: 0.2544 - val_accuracy: 0.8330 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 63/600\n",
            "1438/1438 - 9s - loss: 0.2558 - accuracy: 0.8336 - val_loss: 0.2543 - val_accuracy: 0.8359 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 64/600\n",
            "1438/1438 - 9s - loss: 0.2555 - accuracy: 0.8334 - val_loss: 0.2541 - val_accuracy: 0.8364 - lr: 1.9531e-05 - 9s/epoch - 7ms/step\n",
            "Epoch 65/600\n",
            "1438/1438 - 9s - loss: 0.2554 - accuracy: 0.8353 - val_loss: 0.2542 - val_accuracy: 0.8358 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 66/600\n",
            "1438/1438 - 9s - loss: 0.2553 - accuracy: 0.8351 - val_loss: 0.2541 - val_accuracy: 0.8350 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 67/600\n",
            "1438/1438 - 9s - loss: 0.2555 - accuracy: 0.8344 - val_loss: 0.2541 - val_accuracy: 0.8365 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 68/600\n",
            "1438/1438 - 9s - loss: 0.2553 - accuracy: 0.8346 - val_loss: 0.2540 - val_accuracy: 0.8366 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 69/600\n",
            "1438/1438 - 9s - loss: 0.2553 - accuracy: 0.8343 - val_loss: 0.2540 - val_accuracy: 0.8358 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 70/600\n",
            "1438/1438 - 9s - loss: 0.2554 - accuracy: 0.8343 - val_loss: 0.2540 - val_accuracy: 0.8361 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 71/600\n",
            "1438/1438 - 10s - loss: 0.2552 - accuracy: 0.8347 - val_loss: 0.2540 - val_accuracy: 0.8362 - lr: 9.7656e-06 - 10s/epoch - 7ms/step\n",
            "Epoch 72/600\n",
            "1438/1438 - 9s - loss: 0.2553 - accuracy: 0.8345 - val_loss: 0.2539 - val_accuracy: 0.8362 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 73/600\n",
            "1438/1438 - 9s - loss: 0.2553 - accuracy: 0.8342 - val_loss: 0.2539 - val_accuracy: 0.8359 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 74/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8347 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 75/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8345 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 76/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8334 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 77/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8351 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 78/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8334 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 79/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8348 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 80/600\n",
            "1438/1438 - 9s - loss: 0.2551 - accuracy: 0.8348 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 81/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8347 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 82/600\n",
            "1438/1438 - 9s - loss: 0.2553 - accuracy: 0.8349 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 83/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8351 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 84/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8346 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 85/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8342 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 86/600\n",
            "1438/1438 - 9s - loss: 0.2553 - accuracy: 0.8326 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 87/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8341 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 88/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8344 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 89/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8341 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 90/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8347 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 91/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8350 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 92/600\n",
            "1438/1438 - 9s - loss: 0.2551 - accuracy: 0.8343 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 93/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8337 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 94/600\n",
            "1438/1438 - 9s - loss: 0.2551 - accuracy: 0.8348 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 95/600\n",
            "1438/1438 - 9s - loss: 0.2551 - accuracy: 0.8343 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 96/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8335 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 97/600\n",
            "1438/1438 - 9s - loss: 0.2551 - accuracy: 0.8348 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 98/600\n",
            "1438/1438 - 9s - loss: 0.2553 - accuracy: 0.8328 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 99/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8341 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 100/600\n",
            "1438/1438 - 9s - loss: 0.2550 - accuracy: 0.8342 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 101/600\n",
            "1438/1438 - 9s - loss: 0.2551 - accuracy: 0.8346 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 102/600\n",
            "1438/1438 - 9s - loss: 0.2551 - accuracy: 0.8347 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 103/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8337 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 104/600\n",
            "1438/1438 - 9s - loss: 0.2551 - accuracy: 0.8346 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 105/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8346 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 106/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8346 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 107/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8351 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 108/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8346 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 109/600\n",
            "1438/1438 - 9s - loss: 0.2553 - accuracy: 0.8339 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 110/600\n",
            "1438/1438 - 9s - loss: 0.2552 - accuracy: 0.8344 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 111/600\n",
            "1438/1438 - 9s - loss: 0.2551 - accuracy: 0.8352 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 112/600\n",
            "1438/1438 - 9s - loss: 0.2553 - accuracy: 0.8341 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 5.9605e-10 - 9s/epoch - 6ms/step\n",
            "Epoch 113/600\n",
            "1438/1438 - 9s - loss: 0.2551 - accuracy: 0.8339 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 5.9605e-10 - 9s/epoch - 6ms/step\n",
            "Epoch 114/600\n",
            "1438/1438 - 9s - loss: 0.2551 - accuracy: 0.8347 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 5.9605e-10 - 9s/epoch - 6ms/step\n",
            "Epoch 115/600\n",
            "1438/1438 - 9s - loss: 0.2551 - accuracy: 0.8346 - val_loss: 0.2539 - val_accuracy: 0.8366 - lr: 2.9802e-10 - 9s/epoch - 6ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " ...\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " ...\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12  2]\n",
            " ...\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 20]\n",
            " ...\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ... 14 11 20]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " ...\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 20 25  7]\n",
            " ...\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 20 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " ...\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ...  7 18 23]\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ...  7 18 13]\n",
            " ...\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 13]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " ...\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 13 17  9]\n",
            " ...\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  1]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  9 21  4]\n",
            " ...\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  1 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  8]\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ...  4  3  8]\n",
            " ...\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ... 22  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " ...\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " ...\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_10 (Bidirecti  (None, 128)              48128     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1433/1433 - 13s - loss: 0.7231 - accuracy: 0.7829 - val_loss: 0.3627 - val_accuracy: 0.8300 - lr: 0.0050 - 13s/epoch - 9ms/step\n",
            "Epoch 2/600\n",
            "1433/1433 - 9s - loss: 0.4107 - accuracy: 0.8229 - val_loss: 0.3275 - val_accuracy: 0.8299 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 3/600\n",
            "1433/1433 - 9s - loss: 0.3605 - accuracy: 0.8258 - val_loss: 0.3142 - val_accuracy: 0.8281 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 4/600\n",
            "1433/1433 - 9s - loss: 0.3916 - accuracy: 0.8239 - val_loss: 0.3197 - val_accuracy: 0.8238 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 5/600\n",
            "1433/1433 - 9s - loss: 0.3696 - accuracy: 0.8227 - val_loss: 0.5403 - val_accuracy: 0.7768 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 6/600\n",
            "1433/1433 - 9s - loss: 0.3284 - accuracy: 0.8266 - val_loss: 1.5494 - val_accuracy: 0.5442 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 7/600\n",
            "1433/1433 - 9s - loss: 0.3369 - accuracy: 0.8256 - val_loss: 0.2981 - val_accuracy: 0.8225 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 8/600\n",
            "1433/1433 - 9s - loss: 0.3117 - accuracy: 0.8265 - val_loss: 0.2910 - val_accuracy: 0.8290 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 9/600\n",
            "1433/1433 - 9s - loss: 0.2943 - accuracy: 0.8276 - val_loss: 0.2961 - val_accuracy: 0.8291 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 10/600\n",
            "1433/1433 - 9s - loss: 0.3123 - accuracy: 0.8273 - val_loss: 0.2875 - val_accuracy: 0.8332 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 11/600\n",
            "1433/1433 - 9s - loss: 0.2953 - accuracy: 0.8280 - val_loss: 0.2873 - val_accuracy: 0.8290 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 12/600\n",
            "1433/1433 - 9s - loss: 0.3227 - accuracy: 0.8261 - val_loss: 0.2869 - val_accuracy: 0.8295 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 13/600\n",
            "1433/1433 - 9s - loss: 0.3039 - accuracy: 0.8273 - val_loss: 0.2957 - val_accuracy: 0.8309 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 14/600\n",
            "1433/1433 - 9s - loss: 0.2890 - accuracy: 0.8290 - val_loss: 0.2812 - val_accuracy: 0.8273 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 15/600\n",
            "1433/1433 - 9s - loss: 0.3245 - accuracy: 0.8268 - val_loss: 0.2869 - val_accuracy: 0.8293 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 16/600\n",
            "1433/1433 - 9s - loss: 0.2929 - accuracy: 0.8291 - val_loss: 0.2832 - val_accuracy: 0.8308 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 17/600\n",
            "1433/1433 - 9s - loss: 0.3131 - accuracy: 0.8256 - val_loss: 0.3731 - val_accuracy: 0.8309 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 18/600\n",
            "1433/1433 - 9s - loss: 0.2979 - accuracy: 0.8297 - val_loss: 0.2773 - val_accuracy: 0.8281 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 19/600\n",
            "1433/1433 - 9s - loss: 0.2776 - accuracy: 0.8310 - val_loss: 0.2739 - val_accuracy: 0.8277 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 20/600\n",
            "1433/1433 - 9s - loss: 0.2764 - accuracy: 0.8308 - val_loss: 0.2702 - val_accuracy: 0.8321 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 21/600\n",
            "1433/1433 - 9s - loss: 0.2799 - accuracy: 0.8303 - val_loss: 0.2701 - val_accuracy: 0.8346 - lr: 0.0012 - 9s/epoch - 7ms/step\n",
            "Epoch 22/600\n",
            "1433/1433 - 9s - loss: 0.2786 - accuracy: 0.8297 - val_loss: 0.2824 - val_accuracy: 0.8340 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 23/600\n",
            "1433/1433 - 9s - loss: 0.2729 - accuracy: 0.8312 - val_loss: 0.2681 - val_accuracy: 0.8331 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 24/600\n",
            "1433/1433 - 9s - loss: 0.2804 - accuracy: 0.8304 - val_loss: 0.3350 - val_accuracy: 0.8311 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 25/600\n",
            "1433/1433 - 9s - loss: 0.2781 - accuracy: 0.8289 - val_loss: 0.2695 - val_accuracy: 0.8326 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 26/600\n",
            "1433/1433 - 9s - loss: 0.2711 - accuracy: 0.8316 - val_loss: 0.2683 - val_accuracy: 0.8310 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 27/600\n",
            "1433/1433 - 9s - loss: 0.2654 - accuracy: 0.8322 - val_loss: 0.2654 - val_accuracy: 0.8308 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 28/600\n",
            "1433/1433 - 9s - loss: 0.2690 - accuracy: 0.8323 - val_loss: 0.2628 - val_accuracy: 0.8340 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 29/600\n",
            "1433/1433 - 9s - loss: 0.2647 - accuracy: 0.8327 - val_loss: 0.2628 - val_accuracy: 0.8362 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 30/600\n",
            "1433/1433 - 9s - loss: 0.2649 - accuracy: 0.8325 - val_loss: 0.2629 - val_accuracy: 0.8333 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 31/600\n",
            "1433/1433 - 9s - loss: 0.2715 - accuracy: 0.8310 - val_loss: 0.2625 - val_accuracy: 0.8337 - lr: 6.2500e-04 - 9s/epoch - 7ms/step\n",
            "Epoch 32/600\n",
            "1433/1433 - 9s - loss: 0.2643 - accuracy: 0.8317 - val_loss: 0.2621 - val_accuracy: 0.8358 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 33/600\n",
            "1433/1433 - 9s - loss: 0.2644 - accuracy: 0.8323 - val_loss: 0.2627 - val_accuracy: 0.8306 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 34/600\n",
            "1433/1433 - 9s - loss: 0.2664 - accuracy: 0.8325 - val_loss: 0.2626 - val_accuracy: 0.8237 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 35/600\n",
            "1433/1433 - 9s - loss: 0.2699 - accuracy: 0.8311 - val_loss: 0.2635 - val_accuracy: 0.8335 - lr: 6.2500e-04 - 9s/epoch - 7ms/step\n",
            "Epoch 36/600\n",
            "1433/1433 - 9s - loss: 0.2619 - accuracy: 0.8318 - val_loss: 0.2597 - val_accuracy: 0.8356 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 37/600\n",
            "1433/1433 - 9s - loss: 0.2609 - accuracy: 0.8342 - val_loss: 0.2593 - val_accuracy: 0.8333 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 38/600\n",
            "1433/1433 - 9s - loss: 0.2610 - accuracy: 0.8334 - val_loss: 0.2592 - val_accuracy: 0.8355 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 39/600\n",
            "1433/1433 - 9s - loss: 0.2609 - accuracy: 0.8342 - val_loss: 0.2631 - val_accuracy: 0.8319 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 40/600\n",
            "1433/1433 - 9s - loss: 0.2607 - accuracy: 0.8331 - val_loss: 0.2589 - val_accuracy: 0.8356 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 41/600\n",
            "1433/1433 - 9s - loss: 0.2616 - accuracy: 0.8327 - val_loss: 0.2588 - val_accuracy: 0.8328 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 42/600\n",
            "1433/1433 - 9s - loss: 0.2603 - accuracy: 0.8343 - val_loss: 0.2589 - val_accuracy: 0.8344 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 43/600\n",
            "1433/1433 - 9s - loss: 0.2605 - accuracy: 0.8336 - val_loss: 0.2666 - val_accuracy: 0.8347 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 44/600\n",
            "1433/1433 - 9s - loss: 0.2607 - accuracy: 0.8331 - val_loss: 0.2582 - val_accuracy: 0.8346 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 45/600\n",
            "1433/1433 - 9s - loss: 0.2626 - accuracy: 0.8318 - val_loss: 0.2586 - val_accuracy: 0.8357 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 46/600\n",
            "1433/1433 - 9s - loss: 0.2597 - accuracy: 0.8330 - val_loss: 0.2579 - val_accuracy: 0.8348 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 47/600\n",
            "1433/1433 - 9s - loss: 0.2599 - accuracy: 0.8334 - val_loss: 0.2586 - val_accuracy: 0.8357 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 48/600\n",
            "1433/1433 - 9s - loss: 0.2601 - accuracy: 0.8334 - val_loss: 0.2586 - val_accuracy: 0.8322 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 49/600\n",
            "1433/1433 - 9s - loss: 0.2601 - accuracy: 0.8335 - val_loss: 0.2578 - val_accuracy: 0.8349 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 50/600\n",
            "1433/1433 - 9s - loss: 0.2613 - accuracy: 0.8330 - val_loss: 0.2590 - val_accuracy: 0.8345 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 51/600\n",
            "1433/1433 - 9s - loss: 0.2595 - accuracy: 0.8328 - val_loss: 0.2581 - val_accuracy: 0.8351 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 52/600\n",
            "1433/1433 - 9s - loss: 0.2606 - accuracy: 0.8325 - val_loss: 0.2592 - val_accuracy: 0.8349 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 53/600\n",
            "1433/1433 - 9s - loss: 0.2583 - accuracy: 0.8344 - val_loss: 0.2566 - val_accuracy: 0.8338 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 54/600\n",
            "1433/1433 - 9s - loss: 0.2579 - accuracy: 0.8343 - val_loss: 0.2566 - val_accuracy: 0.8378 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 55/600\n",
            "1433/1433 - 9s - loss: 0.2579 - accuracy: 0.8343 - val_loss: 0.2561 - val_accuracy: 0.8361 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 56/600\n",
            "1433/1433 - 9s - loss: 0.2580 - accuracy: 0.8343 - val_loss: 0.2567 - val_accuracy: 0.8353 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 57/600\n",
            "1433/1433 - 9s - loss: 0.2577 - accuracy: 0.8340 - val_loss: 0.2562 - val_accuracy: 0.8334 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 58/600\n",
            "1433/1433 - 9s - loss: 0.2577 - accuracy: 0.8345 - val_loss: 0.2565 - val_accuracy: 0.8348 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 59/600\n",
            "1433/1433 - 9s - loss: 0.2568 - accuracy: 0.8352 - val_loss: 0.2557 - val_accuracy: 0.8345 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 60/600\n",
            "1433/1433 - 9s - loss: 0.2567 - accuracy: 0.8346 - val_loss: 0.2553 - val_accuracy: 0.8344 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 61/600\n",
            "1433/1433 - 9s - loss: 0.2565 - accuracy: 0.8361 - val_loss: 0.2551 - val_accuracy: 0.8350 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 62/600\n",
            "1433/1433 - 9s - loss: 0.2566 - accuracy: 0.8341 - val_loss: 0.2558 - val_accuracy: 0.8345 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 63/600\n",
            "1433/1433 - 9s - loss: 0.2566 - accuracy: 0.8344 - val_loss: 0.2553 - val_accuracy: 0.8341 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 64/600\n",
            "1433/1433 - 9s - loss: 0.2566 - accuracy: 0.8348 - val_loss: 0.2552 - val_accuracy: 0.8347 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 65/600\n",
            "1433/1433 - 9s - loss: 0.2560 - accuracy: 0.8345 - val_loss: 0.2550 - val_accuracy: 0.8345 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 66/600\n",
            "1433/1433 - 9s - loss: 0.2560 - accuracy: 0.8348 - val_loss: 0.2546 - val_accuracy: 0.8352 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 67/600\n",
            "1433/1433 - 9s - loss: 0.2559 - accuracy: 0.8350 - val_loss: 0.2550 - val_accuracy: 0.8345 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 68/600\n",
            "1433/1433 - 9s - loss: 0.2560 - accuracy: 0.8344 - val_loss: 0.2546 - val_accuracy: 0.8348 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 69/600\n",
            "1433/1433 - 9s - loss: 0.2559 - accuracy: 0.8350 - val_loss: 0.2548 - val_accuracy: 0.8325 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 70/600\n",
            "1433/1433 - 9s - loss: 0.2557 - accuracy: 0.8346 - val_loss: 0.2545 - val_accuracy: 0.8348 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 71/600\n",
            "1433/1433 - 9s - loss: 0.2556 - accuracy: 0.8351 - val_loss: 0.2545 - val_accuracy: 0.8345 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 72/600\n",
            "1433/1433 - 9s - loss: 0.2556 - accuracy: 0.8356 - val_loss: 0.2544 - val_accuracy: 0.8353 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 73/600\n",
            "1433/1433 - 9s - loss: 0.2556 - accuracy: 0.8357 - val_loss: 0.2544 - val_accuracy: 0.8348 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 74/600\n",
            "1433/1433 - 9s - loss: 0.2557 - accuracy: 0.8354 - val_loss: 0.2545 - val_accuracy: 0.8348 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 75/600\n",
            "1433/1433 - 9s - loss: 0.2556 - accuracy: 0.8353 - val_loss: 0.2544 - val_accuracy: 0.8352 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 76/600\n",
            "1433/1433 - 9s - loss: 0.2556 - accuracy: 0.8357 - val_loss: 0.2543 - val_accuracy: 0.8343 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 77/600\n",
            "1433/1433 - 9s - loss: 0.2555 - accuracy: 0.8356 - val_loss: 0.2542 - val_accuracy: 0.8345 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 78/600\n",
            "1433/1433 - 9s - loss: 0.2555 - accuracy: 0.8354 - val_loss: 0.2542 - val_accuracy: 0.8350 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 79/600\n",
            "1433/1433 - 10s - loss: 0.2555 - accuracy: 0.8349 - val_loss: 0.2542 - val_accuracy: 0.8348 - lr: 9.7656e-06 - 10s/epoch - 7ms/step\n",
            "Epoch 80/600\n",
            "1433/1433 - 10s - loss: 0.2556 - accuracy: 0.8345 - val_loss: 0.2542 - val_accuracy: 0.8344 - lr: 9.7656e-06 - 10s/epoch - 7ms/step\n",
            "Epoch 81/600\n",
            "1433/1433 - 9s - loss: 0.2554 - accuracy: 0.8357 - val_loss: 0.2542 - val_accuracy: 0.8348 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 82/600\n",
            "1433/1433 - 9s - loss: 0.2554 - accuracy: 0.8358 - val_loss: 0.2542 - val_accuracy: 0.8348 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 83/600\n",
            "1433/1433 - 9s - loss: 0.2553 - accuracy: 0.8351 - val_loss: 0.2542 - val_accuracy: 0.8348 - lr: 4.8828e-06 - 9s/epoch - 7ms/step\n",
            "Epoch 84/600\n",
            "1433/1433 - 9s - loss: 0.2553 - accuracy: 0.8348 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 85/600\n",
            "1433/1433 - 9s - loss: 0.2553 - accuracy: 0.8354 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 86/600\n",
            "1433/1433 - 9s - loss: 0.2552 - accuracy: 0.8365 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 87/600\n",
            "1433/1433 - 9s - loss: 0.2554 - accuracy: 0.8362 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 88/600\n",
            "1433/1433 - 9s - loss: 0.2554 - accuracy: 0.8353 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 89/600\n",
            "1433/1433 - 9s - loss: 0.2553 - accuracy: 0.8357 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 90/600\n",
            "1433/1433 - 9s - loss: 0.2552 - accuracy: 0.8345 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 91/600\n",
            "1433/1433 - 9s - loss: 0.2552 - accuracy: 0.8351 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 92/600\n",
            "1433/1433 - 9s - loss: 0.2554 - accuracy: 0.8353 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 93/600\n",
            "1433/1433 - 9s - loss: 0.2552 - accuracy: 0.8351 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 94/600\n",
            "1433/1433 - 9s - loss: 0.2553 - accuracy: 0.8352 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 95/600\n",
            "1433/1433 - 9s - loss: 0.2554 - accuracy: 0.8356 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 96/600\n",
            "1433/1433 - 9s - loss: 0.2553 - accuracy: 0.8356 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 97/600\n",
            "1433/1433 - 9s - loss: 0.2552 - accuracy: 0.8359 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 98/600\n",
            "1433/1433 - 9s - loss: 0.2553 - accuracy: 0.8353 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 99/600\n",
            "1433/1433 - 9s - loss: 0.2553 - accuracy: 0.8354 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 100/600\n",
            "1433/1433 - 9s - loss: 0.2552 - accuracy: 0.8368 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 101/600\n",
            "1433/1433 - 9s - loss: 0.2553 - accuracy: 0.8359 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 102/600\n",
            "1433/1433 - 11s - loss: 0.2553 - accuracy: 0.8355 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 7.6294e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 103/600\n",
            "1433/1433 - 10s - loss: 0.2553 - accuracy: 0.8352 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 7.6294e-08 - 10s/epoch - 7ms/step\n",
            "Epoch 104/600\n",
            "1433/1433 - 11s - loss: 0.2552 - accuracy: 0.8352 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 3.8147e-08 - 11s/epoch - 7ms/step\n",
            "Epoch 105/600\n",
            "1433/1433 - 10s - loss: 0.2553 - accuracy: 0.8351 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 3.8147e-08 - 10s/epoch - 7ms/step\n",
            "Epoch 106/600\n",
            "1433/1433 - 9s - loss: 0.2553 - accuracy: 0.8346 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 3.8147e-08 - 9s/epoch - 7ms/step\n",
            "Epoch 107/600\n",
            "1433/1433 - 9s - loss: 0.2553 - accuracy: 0.8353 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 1.9073e-08 - 9s/epoch - 7ms/step\n",
            "Epoch 108/600\n",
            "1433/1433 - 9s - loss: 0.2554 - accuracy: 0.8346 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 109/600\n",
            "1433/1433 - 11s - loss: 0.2553 - accuracy: 0.8357 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 1.9073e-08 - 11s/epoch - 7ms/step\n",
            "Epoch 110/600\n",
            "1433/1433 - 9s - loss: 0.2551 - accuracy: 0.8364 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 9.5367e-09 - 9s/epoch - 7ms/step\n",
            "Epoch 111/600\n",
            "1433/1433 - 9s - loss: 0.2554 - accuracy: 0.8350 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 9.5367e-09 - 9s/epoch - 7ms/step\n",
            "Epoch 112/600\n",
            "1433/1433 - 11s - loss: 0.2552 - accuracy: 0.8354 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 9.5367e-09 - 11s/epoch - 7ms/step\n",
            "Epoch 113/600\n",
            "1433/1433 - 10s - loss: 0.2552 - accuracy: 0.8357 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 4.7684e-09 - 10s/epoch - 7ms/step\n",
            "Epoch 114/600\n",
            "1433/1433 - 9s - loss: 0.2553 - accuracy: 0.8350 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 4.7684e-09 - 9s/epoch - 7ms/step\n",
            "Epoch 115/600\n",
            "1433/1433 - 11s - loss: 0.2552 - accuracy: 0.8354 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 4.7684e-09 - 11s/epoch - 8ms/step\n",
            "Epoch 116/600\n",
            "1433/1433 - 10s - loss: 0.2553 - accuracy: 0.8355 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 2.3842e-09 - 10s/epoch - 7ms/step\n",
            "Epoch 117/600\n",
            "1433/1433 - 9s - loss: 0.2552 - accuracy: 0.8356 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 2.3842e-09 - 9s/epoch - 7ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " ...\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " ...\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12  2]\n",
            " ...\n",
            " [28 27 10 ...  6 12 14]\n",
            " [28 27 10 ...  6 12 14]\n",
            " [28 27 10 ... 26 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " ...\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ... 14 11 24]\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ...  2 11 20]\n",
            " ...\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ... 14 11 24]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 20 25  7]\n",
            " ...\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 24 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " ...\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ...  7 18 23]\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ...  7 18 13]\n",
            " ...\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 13]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " ...\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  9]\n",
            " ...\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 13 17  1]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21 22]\n",
            " ...\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  1 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  5]\n",
            " ...\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ... 22  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " ...\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " ...\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_11 (Bidirecti  (None, 128)              48128     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1452/1452 - 13s - loss: 0.6727 - accuracy: 0.7913 - val_loss: 0.3722 - val_accuracy: 0.8299 - lr: 0.0050 - 13s/epoch - 9ms/step\n",
            "Epoch 2/600\n",
            "1452/1452 - 9s - loss: 0.4028 - accuracy: 0.8251 - val_loss: 0.3415 - val_accuracy: 0.8302 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 3/600\n",
            "1452/1452 - 9s - loss: 0.4107 - accuracy: 0.8243 - val_loss: 0.3410 - val_accuracy: 0.8306 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 4/600\n",
            "1452/1452 - 9s - loss: 0.3908 - accuracy: 0.8254 - val_loss: 0.3874 - val_accuracy: 0.8235 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 5/600\n",
            "1452/1452 - 9s - loss: 0.3285 - accuracy: 0.8285 - val_loss: 0.3122 - val_accuracy: 0.8296 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 6/600\n",
            "1452/1452 - 9s - loss: 0.3542 - accuracy: 0.8265 - val_loss: 0.3039 - val_accuracy: 0.8270 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 7/600\n",
            "1452/1452 - 9s - loss: 0.4059 - accuracy: 0.8227 - val_loss: 0.3091 - val_accuracy: 0.8305 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 8/600\n",
            "1452/1452 - 9s - loss: 0.3276 - accuracy: 0.8274 - val_loss: 0.3890 - val_accuracy: 0.8327 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 9/600\n",
            "1452/1452 - 9s - loss: 0.3589 - accuracy: 0.8261 - val_loss: 0.5163 - val_accuracy: 0.8312 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 10/600\n",
            "1452/1452 - 9s - loss: 0.3310 - accuracy: 0.8295 - val_loss: 0.2935 - val_accuracy: 0.8331 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 11/600\n",
            "1452/1452 - 9s - loss: 0.3131 - accuracy: 0.8281 - val_loss: 0.2982 - val_accuracy: 0.8288 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 12/600\n",
            "1452/1452 - 9s - loss: 0.2896 - accuracy: 0.8301 - val_loss: 0.2813 - val_accuracy: 0.8293 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 13/600\n",
            "1452/1452 - 9s - loss: 0.3088 - accuracy: 0.8282 - val_loss: 0.2823 - val_accuracy: 0.8264 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 14/600\n",
            "1452/1452 - 9s - loss: 0.2950 - accuracy: 0.8291 - val_loss: 0.2876 - val_accuracy: 0.8303 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 15/600\n",
            "1452/1452 - 9s - loss: 0.2847 - accuracy: 0.8296 - val_loss: 0.2802 - val_accuracy: 0.8311 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 16/600\n",
            "1452/1452 - 9s - loss: 0.3162 - accuracy: 0.8278 - val_loss: 0.2781 - val_accuracy: 0.8323 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 17/600\n",
            "1452/1452 - 10s - loss: 0.3081 - accuracy: 0.8286 - val_loss: 0.3021 - val_accuracy: 0.8330 - lr: 0.0025 - 10s/epoch - 7ms/step\n",
            "Epoch 18/600\n",
            "1452/1452 - 9s - loss: 0.2890 - accuracy: 0.8304 - val_loss: 0.2797 - val_accuracy: 0.8320 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 19/600\n",
            "1452/1452 - 9s - loss: 0.3058 - accuracy: 0.8294 - val_loss: 0.3129 - val_accuracy: 0.8288 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 20/600\n",
            "1452/1452 - 9s - loss: 0.2803 - accuracy: 0.8315 - val_loss: 0.2709 - val_accuracy: 0.8347 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 21/600\n",
            "1452/1452 - 10s - loss: 0.2718 - accuracy: 0.8323 - val_loss: 0.2687 - val_accuracy: 0.8323 - lr: 0.0012 - 10s/epoch - 7ms/step\n",
            "Epoch 22/600\n",
            "1452/1452 - 9s - loss: 0.2721 - accuracy: 0.8313 - val_loss: 0.2665 - val_accuracy: 0.8301 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 23/600\n",
            "1452/1452 - 9s - loss: 0.2820 - accuracy: 0.8299 - val_loss: 0.2686 - val_accuracy: 0.8249 - lr: 0.0012 - 9s/epoch - 7ms/step\n",
            "Epoch 24/600\n",
            "1452/1452 - 9s - loss: 0.2697 - accuracy: 0.8317 - val_loss: 0.2720 - val_accuracy: 0.8314 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 25/600\n",
            "1452/1452 - 9s - loss: 0.2700 - accuracy: 0.8308 - val_loss: 0.2668 - val_accuracy: 0.8318 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 26/600\n",
            "1452/1452 - 9s - loss: 0.2636 - accuracy: 0.8317 - val_loss: 0.2620 - val_accuracy: 0.8330 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 27/600\n",
            "1452/1452 - 9s - loss: 0.2639 - accuracy: 0.8325 - val_loss: 0.2625 - val_accuracy: 0.8331 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 28/600\n",
            "1452/1452 - 9s - loss: 0.2627 - accuracy: 0.8325 - val_loss: 0.2609 - val_accuracy: 0.8330 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 29/600\n",
            "1452/1452 - 9s - loss: 0.2660 - accuracy: 0.8315 - val_loss: 0.2606 - val_accuracy: 0.8327 - lr: 6.2500e-04 - 9s/epoch - 7ms/step\n",
            "Epoch 30/600\n",
            "1452/1452 - 9s - loss: 0.2618 - accuracy: 0.8321 - val_loss: 0.2606 - val_accuracy: 0.8328 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 31/600\n",
            "1452/1452 - 11s - loss: 0.2631 - accuracy: 0.8319 - val_loss: 0.2601 - val_accuracy: 0.8319 - lr: 6.2500e-04 - 11s/epoch - 7ms/step\n",
            "Epoch 32/600\n",
            "1452/1452 - 9s - loss: 0.2622 - accuracy: 0.8325 - val_loss: 0.2602 - val_accuracy: 0.8322 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 33/600\n",
            "1452/1452 - 9s - loss: 0.2651 - accuracy: 0.8300 - val_loss: 0.2926 - val_accuracy: 0.8323 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 34/600\n",
            "1452/1452 - 9s - loss: 0.2638 - accuracy: 0.8322 - val_loss: 0.2599 - val_accuracy: 0.8317 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 35/600\n",
            "1452/1452 - 9s - loss: 0.2614 - accuracy: 0.8327 - val_loss: 0.2598 - val_accuracy: 0.8312 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 36/600\n",
            "1452/1452 - 9s - loss: 0.2646 - accuracy: 0.8312 - val_loss: 0.2628 - val_accuracy: 0.8312 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 37/600\n",
            "1452/1452 - 9s - loss: 0.2615 - accuracy: 0.8322 - val_loss: 0.2593 - val_accuracy: 0.8331 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 38/600\n",
            "1452/1452 - 9s - loss: 0.2608 - accuracy: 0.8333 - val_loss: 0.2591 - val_accuracy: 0.8313 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 39/600\n",
            "1452/1452 - 9s - loss: 0.2623 - accuracy: 0.8321 - val_loss: 0.2592 - val_accuracy: 0.8320 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 40/600\n",
            "1452/1452 - 9s - loss: 0.2649 - accuracy: 0.8317 - val_loss: 0.2600 - val_accuracy: 0.8330 - lr: 6.2500e-04 - 9s/epoch - 7ms/step\n",
            "Epoch 41/600\n",
            "1452/1452 - 9s - loss: 0.2603 - accuracy: 0.8324 - val_loss: 0.2589 - val_accuracy: 0.8349 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 42/600\n",
            "1452/1452 - 9s - loss: 0.2606 - accuracy: 0.8323 - val_loss: 0.2599 - val_accuracy: 0.8306 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 43/600\n",
            "1452/1452 - 9s - loss: 0.2659 - accuracy: 0.8326 - val_loss: 0.2596 - val_accuracy: 0.8310 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 44/600\n",
            "1452/1452 - 9s - loss: 0.2603 - accuracy: 0.8336 - val_loss: 0.2599 - val_accuracy: 0.8319 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 45/600\n",
            "1452/1452 - 9s - loss: 0.2578 - accuracy: 0.8335 - val_loss: 0.2566 - val_accuracy: 0.8308 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 46/600\n",
            "1452/1452 - 9s - loss: 0.2578 - accuracy: 0.8332 - val_loss: 0.2567 - val_accuracy: 0.8315 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 47/600\n",
            "1452/1452 - 9s - loss: 0.2578 - accuracy: 0.8325 - val_loss: 0.2562 - val_accuracy: 0.8339 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 48/600\n",
            "1452/1452 - 9s - loss: 0.2576 - accuracy: 0.8329 - val_loss: 0.2563 - val_accuracy: 0.8337 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 49/600\n",
            "1452/1452 - 9s - loss: 0.2588 - accuracy: 0.8328 - val_loss: 0.2561 - val_accuracy: 0.8337 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 50/600\n",
            "1452/1452 - 9s - loss: 0.2572 - accuracy: 0.8333 - val_loss: 0.2564 - val_accuracy: 0.8335 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 51/600\n",
            "1452/1452 - 9s - loss: 0.2577 - accuracy: 0.8324 - val_loss: 0.2563 - val_accuracy: 0.8334 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 52/600\n",
            "1452/1452 - 9s - loss: 0.2575 - accuracy: 0.8340 - val_loss: 0.2569 - val_accuracy: 0.8330 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 53/600\n",
            "1452/1452 - 9s - loss: 0.2558 - accuracy: 0.8339 - val_loss: 0.2546 - val_accuracy: 0.8332 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 54/600\n",
            "1452/1452 - 9s - loss: 0.2558 - accuracy: 0.8327 - val_loss: 0.2547 - val_accuracy: 0.8339 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 55/600\n",
            "1452/1452 - 9s - loss: 0.2556 - accuracy: 0.8337 - val_loss: 0.2547 - val_accuracy: 0.8327 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 56/600\n",
            "1452/1452 - 9s - loss: 0.2555 - accuracy: 0.8329 - val_loss: 0.2552 - val_accuracy: 0.8304 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 57/600\n",
            "1452/1452 - 9s - loss: 0.2549 - accuracy: 0.8340 - val_loss: 0.2539 - val_accuracy: 0.8337 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 58/600\n",
            "1452/1452 - 9s - loss: 0.2548 - accuracy: 0.8338 - val_loss: 0.2540 - val_accuracy: 0.8333 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 59/600\n",
            "1452/1452 - 9s - loss: 0.2547 - accuracy: 0.8333 - val_loss: 0.2538 - val_accuracy: 0.8319 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 60/600\n",
            "1452/1452 - 9s - loss: 0.2547 - accuracy: 0.8340 - val_loss: 0.2539 - val_accuracy: 0.8324 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 61/600\n",
            "1452/1452 - 9s - loss: 0.2543 - accuracy: 0.8335 - val_loss: 0.2535 - val_accuracy: 0.8319 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 62/600\n",
            "1452/1452 - 9s - loss: 0.2542 - accuracy: 0.8335 - val_loss: 0.2534 - val_accuracy: 0.8319 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 63/600\n",
            "1452/1452 - 9s - loss: 0.2542 - accuracy: 0.8347 - val_loss: 0.2534 - val_accuracy: 0.8333 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 64/600\n",
            "1452/1452 - 9s - loss: 0.2542 - accuracy: 0.8338 - val_loss: 0.2534 - val_accuracy: 0.8316 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 65/600\n",
            "1452/1452 - 9s - loss: 0.2540 - accuracy: 0.8340 - val_loss: 0.2532 - val_accuracy: 0.8319 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 66/600\n",
            "1452/1452 - 9s - loss: 0.2539 - accuracy: 0.8344 - val_loss: 0.2532 - val_accuracy: 0.8337 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 67/600\n",
            "1452/1452 - 9s - loss: 0.2540 - accuracy: 0.8340 - val_loss: 0.2531 - val_accuracy: 0.8337 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 68/600\n",
            "1452/1452 - 9s - loss: 0.2540 - accuracy: 0.8334 - val_loss: 0.2531 - val_accuracy: 0.8336 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 69/600\n",
            "1452/1452 - 9s - loss: 0.2539 - accuracy: 0.8337 - val_loss: 0.2530 - val_accuracy: 0.8337 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 70/600\n",
            "1452/1452 - 9s - loss: 0.2539 - accuracy: 0.8340 - val_loss: 0.2530 - val_accuracy: 0.8337 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 71/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8348 - val_loss: 0.2530 - val_accuracy: 0.8337 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 72/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8344 - val_loss: 0.2530 - val_accuracy: 0.8337 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 73/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8341 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 74/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8343 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 75/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8343 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 76/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8347 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 77/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8339 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 78/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8342 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 79/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8336 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 80/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8343 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 81/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8339 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 82/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8343 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 83/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8350 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 84/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8342 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 85/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8343 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 86/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8347 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 87/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8340 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 88/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8345 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 89/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8343 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 90/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8349 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 91/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8344 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 92/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8345 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 93/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8342 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 94/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8343 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 95/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8340 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 96/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8347 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 97/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8343 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 98/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8348 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 99/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8344 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 100/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8341 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 101/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8344 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 102/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8342 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 103/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8342 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 104/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8353 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 105/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8343 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 106/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8342 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 107/600\n",
            "1452/1452 - 9s - loss: 0.2537 - accuracy: 0.8348 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 108/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8342 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 109/600\n",
            "1452/1452 - 9s - loss: 0.2536 - accuracy: 0.8341 - val_loss: 0.2529 - val_accuracy: 0.8337 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " ...\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " ...\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ...  6 12  2]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ...  6 12  2]\n",
            " ...\n",
            " [28 27 10 ...  6 12 14]\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " ...\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ...  2 11 24]\n",
            " ...\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ... 14 11 20]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 24 25  7]\n",
            " ...\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 20 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ...  7 18 23]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ...  7 18 23]\n",
            " ...\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ... 15 18 13]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 23 17  1]\n",
            " ...\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 13 17  9]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " ...\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  1 21  4]\n",
            " ...\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21  4]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ... 22  3  8]\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ...  4  3  8]\n",
            " ...\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  8]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " ...\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]]\n",
            "[[28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " ...\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_12 (Bidirecti  (None, 128)              48128     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1454/1454 - 13s - loss: 0.6468 - accuracy: 0.7949 - val_loss: 0.3541 - val_accuracy: 0.8331 - lr: 0.0050 - 13s/epoch - 9ms/step\n",
            "Epoch 2/600\n",
            "1454/1454 - 9s - loss: 0.3667 - accuracy: 0.8267 - val_loss: 0.3695 - val_accuracy: 0.8067 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 3/600\n",
            "1454/1454 - 9s - loss: 0.4087 - accuracy: 0.8227 - val_loss: 1.1199 - val_accuracy: 0.7821 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 4/600\n",
            "1454/1454 - 9s - loss: 0.3613 - accuracy: 0.8292 - val_loss: 0.3218 - val_accuracy: 0.8297 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 5/600\n",
            "1454/1454 - 9s - loss: 0.4069 - accuracy: 0.8235 - val_loss: 0.3481 - val_accuracy: 0.8345 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 6/600\n",
            "1454/1454 - 9s - loss: 0.3613 - accuracy: 0.8284 - val_loss: 0.3239 - val_accuracy: 0.8285 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 7/600\n",
            "1454/1454 - 9s - loss: 0.3432 - accuracy: 0.8280 - val_loss: 0.3431 - val_accuracy: 0.8256 - lr: 0.0050 - 9s/epoch - 6ms/step\n",
            "Epoch 8/600\n",
            "1454/1454 - 11s - loss: 0.3011 - accuracy: 0.8316 - val_loss: 0.2890 - val_accuracy: 0.8337 - lr: 0.0025 - 11s/epoch - 7ms/step\n",
            "Epoch 9/600\n",
            "1454/1454 - 9s - loss: 0.3039 - accuracy: 0.8315 - val_loss: 0.2853 - val_accuracy: 0.8358 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 10/600\n",
            "1454/1454 - 9s - loss: 0.3118 - accuracy: 0.8288 - val_loss: 0.2896 - val_accuracy: 0.8324 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 11/600\n",
            "1454/1454 - 9s - loss: 0.2887 - accuracy: 0.8318 - val_loss: 0.2839 - val_accuracy: 0.8336 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 12/600\n",
            "1454/1454 - 9s - loss: 0.3122 - accuracy: 0.8300 - val_loss: 0.2839 - val_accuracy: 0.8340 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 13/600\n",
            "1454/1454 - 9s - loss: 0.2928 - accuracy: 0.8312 - val_loss: 0.8594 - val_accuracy: 0.7787 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 14/600\n",
            "1454/1454 - 9s - loss: 0.3179 - accuracy: 0.8315 - val_loss: 0.2830 - val_accuracy: 0.8354 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 15/600\n",
            "1454/1454 - 9s - loss: 0.2848 - accuracy: 0.8317 - val_loss: 0.2793 - val_accuracy: 0.8286 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 16/600\n",
            "1454/1454 - 9s - loss: 0.3219 - accuracy: 0.8303 - val_loss: 0.2840 - val_accuracy: 0.8353 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 17/600\n",
            "1454/1454 - 9s - loss: 0.3070 - accuracy: 0.8294 - val_loss: 0.2951 - val_accuracy: 0.8331 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 18/600\n",
            "1454/1454 - 9s - loss: 0.2882 - accuracy: 0.8313 - val_loss: 0.2803 - val_accuracy: 0.8289 - lr: 0.0025 - 9s/epoch - 6ms/step\n",
            "Epoch 19/600\n",
            "1454/1454 - 9s - loss: 0.2736 - accuracy: 0.8335 - val_loss: 0.2703 - val_accuracy: 0.8340 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 20/600\n",
            "1454/1454 - 9s - loss: 0.2810 - accuracy: 0.8323 - val_loss: 0.2752 - val_accuracy: 0.8354 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 21/600\n",
            "1454/1454 - 9s - loss: 0.2724 - accuracy: 0.8332 - val_loss: 0.2691 - val_accuracy: 0.8337 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 22/600\n",
            "1454/1454 - 9s - loss: 0.2798 - accuracy: 0.8325 - val_loss: 0.2694 - val_accuracy: 0.8338 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 23/600\n",
            "1454/1454 - 9s - loss: 0.2708 - accuracy: 0.8328 - val_loss: 0.2708 - val_accuracy: 0.8308 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 24/600\n",
            "1454/1454 - 9s - loss: 0.2871 - accuracy: 0.8310 - val_loss: 0.2697 - val_accuracy: 0.8339 - lr: 0.0012 - 9s/epoch - 6ms/step\n",
            "Epoch 25/600\n",
            "1454/1454 - 9s - loss: 0.2668 - accuracy: 0.8334 - val_loss: 0.2636 - val_accuracy: 0.8342 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 26/600\n",
            "1454/1454 - 9s - loss: 0.2651 - accuracy: 0.8332 - val_loss: 0.2624 - val_accuracy: 0.8354 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 27/600\n",
            "1454/1454 - 9s - loss: 0.2661 - accuracy: 0.8338 - val_loss: 0.2630 - val_accuracy: 0.8341 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 28/600\n",
            "1454/1454 - 9s - loss: 0.2640 - accuracy: 0.8345 - val_loss: 0.2613 - val_accuracy: 0.8354 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 29/600\n",
            "1454/1454 - 9s - loss: 0.2680 - accuracy: 0.8334 - val_loss: 0.2614 - val_accuracy: 0.8333 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 30/600\n",
            "1454/1454 - 9s - loss: 0.2637 - accuracy: 0.8340 - val_loss: 0.2634 - val_accuracy: 0.8336 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 31/600\n",
            "1454/1454 - 9s - loss: 0.2640 - accuracy: 0.8345 - val_loss: 0.2621 - val_accuracy: 0.8356 - lr: 6.2500e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 32/600\n",
            "1454/1454 - 9s - loss: 0.2602 - accuracy: 0.8348 - val_loss: 0.2580 - val_accuracy: 0.8340 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 33/600\n",
            "1454/1454 - 9s - loss: 0.2598 - accuracy: 0.8343 - val_loss: 0.2584 - val_accuracy: 0.8340 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 34/600\n",
            "1454/1454 - 9s - loss: 0.2597 - accuracy: 0.8334 - val_loss: 0.2579 - val_accuracy: 0.8354 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 35/600\n",
            "1454/1454 - 9s - loss: 0.2595 - accuracy: 0.8340 - val_loss: 0.2578 - val_accuracy: 0.8345 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 36/600\n",
            "1454/1454 - 9s - loss: 0.2594 - accuracy: 0.8337 - val_loss: 0.2577 - val_accuracy: 0.8347 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 37/600\n",
            "1454/1454 - 9s - loss: 0.2591 - accuracy: 0.8347 - val_loss: 0.2573 - val_accuracy: 0.8336 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 38/600\n",
            "1454/1454 - 9s - loss: 0.2592 - accuracy: 0.8344 - val_loss: 0.2599 - val_accuracy: 0.8326 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 39/600\n",
            "1454/1454 - 9s - loss: 0.2591 - accuracy: 0.8340 - val_loss: 0.2576 - val_accuracy: 0.8346 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 40/600\n",
            "1454/1454 - 9s - loss: 0.2590 - accuracy: 0.8344 - val_loss: 0.2572 - val_accuracy: 0.8343 - lr: 3.1250e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 41/600\n",
            "1454/1454 - 9s - loss: 0.2568 - accuracy: 0.8352 - val_loss: 0.2550 - val_accuracy: 0.8346 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 42/600\n",
            "1454/1454 - 9s - loss: 0.2568 - accuracy: 0.8349 - val_loss: 0.2551 - val_accuracy: 0.8344 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 43/600\n",
            "1454/1454 - 9s - loss: 0.2569 - accuracy: 0.8345 - val_loss: 0.2553 - val_accuracy: 0.8336 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 44/600\n",
            "1454/1454 - 9s - loss: 0.2568 - accuracy: 0.8339 - val_loss: 0.2554 - val_accuracy: 0.8355 - lr: 1.5625e-04 - 9s/epoch - 6ms/step\n",
            "Epoch 45/600\n",
            "1454/1454 - 9s - loss: 0.2558 - accuracy: 0.8348 - val_loss: 0.2541 - val_accuracy: 0.8341 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 46/600\n",
            "1454/1454 - 9s - loss: 0.2557 - accuracy: 0.8354 - val_loss: 0.2540 - val_accuracy: 0.8348 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 47/600\n",
            "1454/1454 - 9s - loss: 0.2557 - accuracy: 0.8340 - val_loss: 0.2541 - val_accuracy: 0.8346 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 48/600\n",
            "1454/1454 - 9s - loss: 0.2556 - accuracy: 0.8344 - val_loss: 0.2540 - val_accuracy: 0.8351 - lr: 7.8125e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 49/600\n",
            "1454/1454 - 9s - loss: 0.2556 - accuracy: 0.8346 - val_loss: 0.2541 - val_accuracy: 0.8357 - lr: 7.8125e-05 - 9s/epoch - 7ms/step\n",
            "Epoch 50/600\n",
            "1454/1454 - 9s - loss: 0.2550 - accuracy: 0.8342 - val_loss: 0.2534 - val_accuracy: 0.8351 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 51/600\n",
            "1454/1454 - 9s - loss: 0.2550 - accuracy: 0.8349 - val_loss: 0.2533 - val_accuracy: 0.8353 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 52/600\n",
            "1454/1454 - 9s - loss: 0.2549 - accuracy: 0.8349 - val_loss: 0.2533 - val_accuracy: 0.8347 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 53/600\n",
            "1454/1454 - 9s - loss: 0.2549 - accuracy: 0.8345 - val_loss: 0.2533 - val_accuracy: 0.8350 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 54/600\n",
            "1454/1454 - 9s - loss: 0.2550 - accuracy: 0.8351 - val_loss: 0.2533 - val_accuracy: 0.8339 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 55/600\n",
            "1454/1454 - 9s - loss: 0.2549 - accuracy: 0.8348 - val_loss: 0.2533 - val_accuracy: 0.8355 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 56/600\n",
            "1454/1454 - 9s - loss: 0.2549 - accuracy: 0.8344 - val_loss: 0.2533 - val_accuracy: 0.8339 - lr: 3.9062e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 57/600\n",
            "1454/1454 - 9s - loss: 0.2546 - accuracy: 0.8354 - val_loss: 0.2530 - val_accuracy: 0.8354 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 58/600\n",
            "1454/1454 - 9s - loss: 0.2545 - accuracy: 0.8342 - val_loss: 0.2531 - val_accuracy: 0.8353 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 59/600\n",
            "1454/1454 - 9s - loss: 0.2545 - accuracy: 0.8356 - val_loss: 0.2530 - val_accuracy: 0.8350 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 60/600\n",
            "1454/1454 - 9s - loss: 0.2546 - accuracy: 0.8340 - val_loss: 0.2530 - val_accuracy: 0.8350 - lr: 1.9531e-05 - 9s/epoch - 6ms/step\n",
            "Epoch 61/600\n",
            "1454/1454 - 9s - loss: 0.2544 - accuracy: 0.8359 - val_loss: 0.2528 - val_accuracy: 0.8350 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 62/600\n",
            "1454/1454 - 9s - loss: 0.2543 - accuracy: 0.8352 - val_loss: 0.2529 - val_accuracy: 0.8350 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 63/600\n",
            "1454/1454 - 9s - loss: 0.2544 - accuracy: 0.8349 - val_loss: 0.2528 - val_accuracy: 0.8350 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 64/600\n",
            "1454/1454 - 9s - loss: 0.2543 - accuracy: 0.8355 - val_loss: 0.2529 - val_accuracy: 0.8354 - lr: 9.7656e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 65/600\n",
            "1454/1454 - 9s - loss: 0.2543 - accuracy: 0.8348 - val_loss: 0.2528 - val_accuracy: 0.8354 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 66/600\n",
            "1454/1454 - 9s - loss: 0.2544 - accuracy: 0.8346 - val_loss: 0.2528 - val_accuracy: 0.8345 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 67/600\n",
            "1454/1454 - 9s - loss: 0.2543 - accuracy: 0.8357 - val_loss: 0.2528 - val_accuracy: 0.8350 - lr: 4.8828e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 68/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8344 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 69/600\n",
            "1454/1454 - 9s - loss: 0.2543 - accuracy: 0.8351 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 70/600\n",
            "1454/1454 - 9s - loss: 0.2543 - accuracy: 0.8345 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 71/600\n",
            "1454/1454 - 9s - loss: 0.2543 - accuracy: 0.8345 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 2.4414e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 72/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8352 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 73/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8355 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 74/600\n",
            "1454/1454 - 9s - loss: 0.2541 - accuracy: 0.8353 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 1.2207e-06 - 9s/epoch - 6ms/step\n",
            "Epoch 75/600\n",
            "1454/1454 - 9s - loss: 0.2541 - accuracy: 0.8351 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 76/600\n",
            "1454/1454 - 9s - loss: 0.2543 - accuracy: 0.8353 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 77/600\n",
            "1454/1454 - 9s - loss: 0.2541 - accuracy: 0.8352 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 6.1035e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 78/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8352 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 79/600\n",
            "1454/1454 - 9s - loss: 0.2541 - accuracy: 0.8360 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 80/600\n",
            "1454/1454 - 9s - loss: 0.2541 - accuracy: 0.8357 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 3.0518e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 81/600\n",
            "1454/1454 - 9s - loss: 0.2541 - accuracy: 0.8360 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 82/600\n",
            "1454/1454 - 9s - loss: 0.2541 - accuracy: 0.8354 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 83/600\n",
            "1454/1454 - 9s - loss: 0.2541 - accuracy: 0.8355 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 1.5259e-07 - 9s/epoch - 6ms/step\n",
            "Epoch 84/600\n",
            "1454/1454 - 9s - loss: 0.2541 - accuracy: 0.8351 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 85/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8355 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 86/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8346 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 7.6294e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 87/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8356 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 88/600\n",
            "1454/1454 - 9s - loss: 0.2541 - accuracy: 0.8350 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 89/600\n",
            "1454/1454 - 9s - loss: 0.2543 - accuracy: 0.8337 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 3.8147e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 90/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8351 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 91/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8345 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 92/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8352 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 1.9073e-08 - 9s/epoch - 6ms/step\n",
            "Epoch 93/600\n",
            "1454/1454 - 9s - loss: 0.2543 - accuracy: 0.8347 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 94/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8350 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 95/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8353 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 9.5367e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 96/600\n",
            "1454/1454 - 9s - loss: 0.2541 - accuracy: 0.8352 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 97/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8349 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 98/600\n",
            "1454/1454 - 9s - loss: 0.2541 - accuracy: 0.8353 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 4.7684e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 99/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8352 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 100/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8348 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 101/600\n",
            "1454/1454 - 9s - loss: 0.2543 - accuracy: 0.8345 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 2.3842e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 102/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8345 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 103/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8347 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "Epoch 104/600\n",
            "1454/1454 - 9s - loss: 0.2542 - accuracy: 0.8345 - val_loss: 0.2527 - val_accuracy: 0.8350 - lr: 1.1921e-09 - 9s/epoch - 6ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " ...\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " ...\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12  2]\n",
            " [28 27 10 ...  6 12 14]\n",
            " [28 27 10 ...  6 12  2]\n",
            " ...\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ...  6 12  2]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 24]\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ...  2 11 24]\n",
            " ...\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 24]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " ...\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 24 25 15]\n",
            " ...\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 24 25  7]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ...  7 18 13]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 13]\n",
            " ...\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ...  7 18 23]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " ...\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 13 17  1]\n",
            " ...\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 23 17  1]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " ...\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  1 21  4]\n",
            " ...\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  1 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ...  4  3  8]\n",
            " ...\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ... 22  3  8]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " ...\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " ...\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]]\n",
            "(12800, 21)\n"
          ]
        }
      ],
      "source": [
        "do_experiment('Model3', 10, True, 0, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "D7Yc82mAYTKE",
        "outputId": "0fa44499-48ea-4335-c199-9f0c7e4a84d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prefix length: 20\n",
            "Already done:  0\n",
            "Already done:  1\n",
            "Already done:  2\n",
            "Already done:  3\n",
            "Already done:  4\n",
            "Already done:  5\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 128)              48128     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1400/1400 - 20s - loss: 0.6536 - accuracy: 0.7984 - val_loss: 0.3586 - val_accuracy: 0.8367 - lr: 0.0050 - 20s/epoch - 14ms/step\n",
            "Epoch 2/600\n",
            "1400/1400 - 12s - loss: 0.4465 - accuracy: 0.8281 - val_loss: 0.3521 - val_accuracy: 0.8364 - lr: 0.0050 - 12s/epoch - 8ms/step\n",
            "Epoch 3/600\n",
            "1400/1400 - 12s - loss: 0.4049 - accuracy: 0.8293 - val_loss: 0.3444 - val_accuracy: 0.8360 - lr: 0.0050 - 12s/epoch - 8ms/step\n",
            "Epoch 4/600\n",
            "1400/1400 - 12s - loss: 0.3594 - accuracy: 0.8299 - val_loss: 0.3148 - val_accuracy: 0.8354 - lr: 0.0050 - 12s/epoch - 8ms/step\n",
            "Epoch 5/600\n",
            "1400/1400 - 12s - loss: 0.4289 - accuracy: 0.8287 - val_loss: 0.4644 - val_accuracy: 0.8357 - lr: 0.0050 - 12s/epoch - 8ms/step\n",
            "Epoch 6/600\n",
            "1400/1400 - 12s - loss: 0.3305 - accuracy: 0.8340 - val_loss: 0.3067 - val_accuracy: 0.8280 - lr: 0.0050 - 12s/epoch - 8ms/step\n",
            "Epoch 7/600\n",
            "1400/1400 - 12s - loss: 0.3809 - accuracy: 0.8294 - val_loss: 0.3128 - val_accuracy: 0.8365 - lr: 0.0050 - 12s/epoch - 8ms/step\n",
            "Epoch 8/600\n",
            "1400/1400 - 12s - loss: 0.3560 - accuracy: 0.8313 - val_loss: 0.3104 - val_accuracy: 0.8357 - lr: 0.0050 - 12s/epoch - 8ms/step\n",
            "Epoch 9/600\n",
            "1400/1400 - 12s - loss: 0.3305 - accuracy: 0.8315 - val_loss: 0.3055 - val_accuracy: 0.8278 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 10/600\n",
            "1400/1400 - 12s - loss: 0.3710 - accuracy: 0.8306 - val_loss: 0.3064 - val_accuracy: 0.8355 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 11/600\n",
            "1400/1400 - 12s - loss: 0.3443 - accuracy: 0.8327 - val_loss: 0.3036 - val_accuracy: 0.8364 - lr: 0.0050 - 12s/epoch - 8ms/step\n",
            "Epoch 12/600\n",
            "1400/1400 - 12s - loss: 0.3315 - accuracy: 0.8313 - val_loss: 0.3009 - val_accuracy: 0.8370 - lr: 0.0050 - 12s/epoch - 8ms/step\n",
            "Epoch 13/600\n",
            "1400/1400 - 12s - loss: 0.3584 - accuracy: 0.8314 - val_loss: 0.3434 - val_accuracy: 0.8308 - lr: 0.0050 - 12s/epoch - 8ms/step\n",
            "Epoch 14/600\n",
            "1400/1400 - 12s - loss: 0.3149 - accuracy: 0.8325 - val_loss: 0.7060 - val_accuracy: 0.7419 - lr: 0.0050 - 12s/epoch - 8ms/step\n",
            "Epoch 15/600\n",
            "1400/1400 - 12s - loss: 0.3480 - accuracy: 0.8311 - val_loss: 0.3454 - val_accuracy: 0.8364 - lr: 0.0050 - 12s/epoch - 8ms/step\n",
            "Epoch 16/600\n",
            "1400/1400 - 12s - loss: 0.2995 - accuracy: 0.8340 - val_loss: 0.2843 - val_accuracy: 0.8358 - lr: 0.0025 - 12s/epoch - 8ms/step\n",
            "Epoch 17/600\n",
            "1400/1400 - 12s - loss: 0.3056 - accuracy: 0.8335 - val_loss: 0.2842 - val_accuracy: 0.8366 - lr: 0.0025 - 12s/epoch - 8ms/step\n",
            "Epoch 18/600\n",
            "1400/1400 - 12s - loss: 0.2956 - accuracy: 0.8347 - val_loss: 0.3953 - val_accuracy: 0.8359 - lr: 0.0025 - 12s/epoch - 8ms/step\n",
            "Epoch 19/600\n",
            "1400/1400 - 12s - loss: 0.2929 - accuracy: 0.8359 - val_loss: 0.2815 - val_accuracy: 0.8357 - lr: 0.0025 - 12s/epoch - 8ms/step\n",
            "Epoch 20/600\n",
            "1400/1400 - 12s - loss: 0.2959 - accuracy: 0.8332 - val_loss: 0.2817 - val_accuracy: 0.8366 - lr: 0.0025 - 12s/epoch - 8ms/step\n",
            "Epoch 21/600\n",
            "1400/1400 - 12s - loss: 0.2872 - accuracy: 0.8353 - val_loss: 0.2789 - val_accuracy: 0.8368 - lr: 0.0025 - 12s/epoch - 8ms/step\n",
            "Epoch 22/600\n",
            "1400/1400 - 12s - loss: 0.2984 - accuracy: 0.8333 - val_loss: 0.5327 - val_accuracy: 0.8358 - lr: 0.0025 - 12s/epoch - 8ms/step\n",
            "Epoch 23/600\n",
            "1400/1400 - 12s - loss: 0.3043 - accuracy: 0.8355 - val_loss: 0.2791 - val_accuracy: 0.8359 - lr: 0.0025 - 12s/epoch - 8ms/step\n",
            "Epoch 24/600\n",
            "1400/1400 - 12s - loss: 0.2821 - accuracy: 0.8353 - val_loss: 0.2790 - val_accuracy: 0.8348 - lr: 0.0025 - 12s/epoch - 8ms/step\n",
            "Epoch 25/600\n",
            "1400/1400 - 12s - loss: 0.2704 - accuracy: 0.8355 - val_loss: 0.2668 - val_accuracy: 0.8359 - lr: 0.0012 - 12s/epoch - 8ms/step\n",
            "Epoch 26/600\n",
            "1400/1400 - 12s - loss: 0.2723 - accuracy: 0.8355 - val_loss: 0.2678 - val_accuracy: 0.8364 - lr: 0.0012 - 12s/epoch - 8ms/step\n",
            "Epoch 27/600\n",
            "1400/1400 - 12s - loss: 0.2740 - accuracy: 0.8351 - val_loss: 0.2666 - val_accuracy: 0.8348 - lr: 0.0012 - 12s/epoch - 8ms/step\n",
            "Epoch 28/600\n",
            "1400/1400 - 12s - loss: 0.2706 - accuracy: 0.8353 - val_loss: 0.2696 - val_accuracy: 0.8350 - lr: 0.0012 - 12s/epoch - 8ms/step\n",
            "Epoch 29/600\n",
            "1400/1400 - 12s - loss: 0.2758 - accuracy: 0.8349 - val_loss: 0.2650 - val_accuracy: 0.8344 - lr: 0.0012 - 12s/epoch - 8ms/step\n",
            "Epoch 30/600\n",
            "1400/1400 - 12s - loss: 0.2677 - accuracy: 0.8345 - val_loss: 0.2636 - val_accuracy: 0.8353 - lr: 0.0012 - 12s/epoch - 8ms/step\n",
            "Epoch 31/600\n",
            "1400/1400 - 12s - loss: 0.2781 - accuracy: 0.8346 - val_loss: 0.2647 - val_accuracy: 0.8378 - lr: 0.0012 - 12s/epoch - 8ms/step\n",
            "Epoch 32/600\n",
            "1400/1400 - 12s - loss: 0.2676 - accuracy: 0.8363 - val_loss: 0.2642 - val_accuracy: 0.8366 - lr: 0.0012 - 12s/epoch - 8ms/step\n",
            "Epoch 33/600\n",
            "1400/1400 - 12s - loss: 0.2718 - accuracy: 0.8351 - val_loss: 0.2648 - val_accuracy: 0.8350 - lr: 0.0012 - 12s/epoch - 8ms/step\n",
            "Epoch 34/600\n",
            "1400/1400 - 12s - loss: 0.2652 - accuracy: 0.8349 - val_loss: 0.2594 - val_accuracy: 0.8353 - lr: 6.2500e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 35/600\n",
            "1400/1400 - 12s - loss: 0.2617 - accuracy: 0.8355 - val_loss: 0.2591 - val_accuracy: 0.8367 - lr: 6.2500e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 36/600\n",
            "1400/1400 - 12s - loss: 0.2617 - accuracy: 0.8367 - val_loss: 0.2603 - val_accuracy: 0.8361 - lr: 6.2500e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 37/600\n",
            "1400/1400 - 12s - loss: 0.2618 - accuracy: 0.8356 - val_loss: 0.2585 - val_accuracy: 0.8367 - lr: 6.2500e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 38/600\n",
            "1400/1400 - 12s - loss: 0.2634 - accuracy: 0.8355 - val_loss: 0.2584 - val_accuracy: 0.8347 - lr: 6.2500e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 39/600\n",
            "1400/1400 - 12s - loss: 0.2618 - accuracy: 0.8355 - val_loss: 0.2591 - val_accuracy: 0.8347 - lr: 6.2500e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 40/600\n",
            "1400/1400 - 12s - loss: 0.2604 - accuracy: 0.8371 - val_loss: 0.2581 - val_accuracy: 0.8359 - lr: 6.2500e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 41/600\n",
            "1400/1400 - 12s - loss: 0.2643 - accuracy: 0.8355 - val_loss: 0.2615 - val_accuracy: 0.8357 - lr: 6.2500e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 42/600\n",
            "1400/1400 - 12s - loss: 0.2605 - accuracy: 0.8353 - val_loss: 0.2589 - val_accuracy: 0.8361 - lr: 6.2500e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 43/600\n",
            "1400/1400 - 12s - loss: 0.2625 - accuracy: 0.8345 - val_loss: 0.2705 - val_accuracy: 0.8363 - lr: 6.2500e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 44/600\n",
            "1400/1400 - 12s - loss: 0.2581 - accuracy: 0.8356 - val_loss: 0.2559 - val_accuracy: 0.8356 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 45/600\n",
            "1400/1400 - 12s - loss: 0.2572 - accuracy: 0.8360 - val_loss: 0.2554 - val_accuracy: 0.8355 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 46/600\n",
            "1400/1400 - 12s - loss: 0.2570 - accuracy: 0.8365 - val_loss: 0.2556 - val_accuracy: 0.8357 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 47/600\n",
            "1400/1400 - 12s - loss: 0.2575 - accuracy: 0.8362 - val_loss: 0.2544 - val_accuracy: 0.8347 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 48/600\n",
            "1400/1400 - 12s - loss: 0.2570 - accuracy: 0.8363 - val_loss: 0.2541 - val_accuracy: 0.8348 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 49/600\n",
            "1400/1400 - 12s - loss: 0.2575 - accuracy: 0.8351 - val_loss: 0.2543 - val_accuracy: 0.8374 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 50/600\n",
            "1400/1400 - 12s - loss: 0.2566 - accuracy: 0.8356 - val_loss: 0.2540 - val_accuracy: 0.8355 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 51/600\n",
            "1400/1400 - 12s - loss: 0.2564 - accuracy: 0.8354 - val_loss: 0.2540 - val_accuracy: 0.8368 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 52/600\n",
            "1400/1400 - 12s - loss: 0.2586 - accuracy: 0.8350 - val_loss: 0.2593 - val_accuracy: 0.8363 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 53/600\n",
            "1400/1400 - 12s - loss: 0.2566 - accuracy: 0.8359 - val_loss: 0.2538 - val_accuracy: 0.8359 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 54/600\n",
            "1400/1400 - 12s - loss: 0.2560 - accuracy: 0.8349 - val_loss: 0.2539 - val_accuracy: 0.8349 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 55/600\n",
            "1400/1400 - 12s - loss: 0.2566 - accuracy: 0.8357 - val_loss: 0.2548 - val_accuracy: 0.8345 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 56/600\n",
            "1400/1400 - 12s - loss: 0.2564 - accuracy: 0.8352 - val_loss: 0.2547 - val_accuracy: 0.8355 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 57/600\n",
            "1400/1400 - 12s - loss: 0.2545 - accuracy: 0.8351 - val_loss: 0.2523 - val_accuracy: 0.8370 - lr: 1.5625e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 58/600\n",
            "1400/1400 - 12s - loss: 0.2543 - accuracy: 0.8370 - val_loss: 0.2526 - val_accuracy: 0.8375 - lr: 1.5625e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 59/600\n",
            "1400/1400 - 12s - loss: 0.2543 - accuracy: 0.8354 - val_loss: 0.2520 - val_accuracy: 0.8353 - lr: 1.5625e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 60/600\n",
            "1400/1400 - 12s - loss: 0.2542 - accuracy: 0.8355 - val_loss: 0.2520 - val_accuracy: 0.8342 - lr: 1.5625e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 61/600\n",
            "1400/1400 - 12s - loss: 0.2542 - accuracy: 0.8359 - val_loss: 0.2520 - val_accuracy: 0.8346 - lr: 1.5625e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 62/600\n",
            "1400/1400 - 12s - loss: 0.2541 - accuracy: 0.8360 - val_loss: 0.2521 - val_accuracy: 0.8361 - lr: 1.5625e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 63/600\n",
            "1400/1400 - 13s - loss: 0.2532 - accuracy: 0.8354 - val_loss: 0.2513 - val_accuracy: 0.8353 - lr: 7.8125e-05 - 13s/epoch - 9ms/step\n",
            "Epoch 64/600\n",
            "1400/1400 - 12s - loss: 0.2530 - accuracy: 0.8359 - val_loss: 0.2515 - val_accuracy: 0.8361 - lr: 7.8125e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 65/600\n",
            "1400/1400 - 12s - loss: 0.2530 - accuracy: 0.8357 - val_loss: 0.2512 - val_accuracy: 0.8358 - lr: 7.8125e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 66/600\n",
            "1400/1400 - 12s - loss: 0.2528 - accuracy: 0.8357 - val_loss: 0.2512 - val_accuracy: 0.8358 - lr: 7.8125e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 67/600\n",
            "1400/1400 - 12s - loss: 0.2529 - accuracy: 0.8355 - val_loss: 0.2512 - val_accuracy: 0.8366 - lr: 7.8125e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 68/600\n",
            "1400/1400 - 12s - loss: 0.2530 - accuracy: 0.8352 - val_loss: 0.2510 - val_accuracy: 0.8369 - lr: 7.8125e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 69/600\n",
            "1400/1400 - 12s - loss: 0.2527 - accuracy: 0.8362 - val_loss: 0.2510 - val_accuracy: 0.8363 - lr: 7.8125e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 70/600\n",
            "1400/1400 - 11s - loss: 0.2528 - accuracy: 0.8361 - val_loss: 0.2512 - val_accuracy: 0.8376 - lr: 7.8125e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 71/600\n",
            "1400/1400 - 12s - loss: 0.2528 - accuracy: 0.8368 - val_loss: 0.2510 - val_accuracy: 0.8370 - lr: 7.8125e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 72/600\n",
            "1400/1400 - 12s - loss: 0.2522 - accuracy: 0.8364 - val_loss: 0.2505 - val_accuracy: 0.8361 - lr: 3.9062e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 73/600\n",
            "1400/1400 - 12s - loss: 0.2522 - accuracy: 0.8364 - val_loss: 0.2505 - val_accuracy: 0.8363 - lr: 3.9062e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 74/600\n",
            "1400/1400 - 12s - loss: 0.2523 - accuracy: 0.8353 - val_loss: 0.2507 - val_accuracy: 0.8354 - lr: 3.9062e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 75/600\n",
            "1400/1400 - 12s - loss: 0.2522 - accuracy: 0.8352 - val_loss: 0.2504 - val_accuracy: 0.8370 - lr: 3.9062e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 76/600\n",
            "1400/1400 - 12s - loss: 0.2518 - accuracy: 0.8363 - val_loss: 0.2502 - val_accuracy: 0.8364 - lr: 1.9531e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 77/600\n",
            "1400/1400 - 12s - loss: 0.2519 - accuracy: 0.8365 - val_loss: 0.2502 - val_accuracy: 0.8364 - lr: 1.9531e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 78/600\n",
            "1400/1400 - 12s - loss: 0.2519 - accuracy: 0.8357 - val_loss: 0.2503 - val_accuracy: 0.8362 - lr: 1.9531e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 79/600\n",
            "1400/1400 - 12s - loss: 0.2520 - accuracy: 0.8361 - val_loss: 0.2502 - val_accuracy: 0.8370 - lr: 1.9531e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 80/600\n",
            "1400/1400 - 12s - loss: 0.2517 - accuracy: 0.8365 - val_loss: 0.2501 - val_accuracy: 0.8370 - lr: 9.7656e-06 - 12s/epoch - 8ms/step\n",
            "Epoch 81/600\n",
            "1400/1400 - 11s - loss: 0.2517 - accuracy: 0.8363 - val_loss: 0.2501 - val_accuracy: 0.8368 - lr: 9.7656e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 82/600\n",
            "1400/1400 - 11s - loss: 0.2518 - accuracy: 0.8364 - val_loss: 0.2501 - val_accuracy: 0.8361 - lr: 9.7656e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 83/600\n",
            "1400/1400 - 12s - loss: 0.2518 - accuracy: 0.8356 - val_loss: 0.2501 - val_accuracy: 0.8368 - lr: 9.7656e-06 - 12s/epoch - 8ms/step\n",
            "Epoch 84/600\n",
            "1400/1400 - 11s - loss: 0.2518 - accuracy: 0.8361 - val_loss: 0.2501 - val_accuracy: 0.8368 - lr: 4.8828e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 85/600\n",
            "1400/1400 - 12s - loss: 0.2517 - accuracy: 0.8365 - val_loss: 0.2501 - val_accuracy: 0.8368 - lr: 4.8828e-06 - 12s/epoch - 8ms/step\n",
            "Epoch 86/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8369 - val_loss: 0.2501 - val_accuracy: 0.8370 - lr: 4.8828e-06 - 12s/epoch - 8ms/step\n",
            "Epoch 87/600\n",
            "1400/1400 - 13s - loss: 0.2516 - accuracy: 0.8364 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 2.4414e-06 - 13s/epoch - 9ms/step\n",
            "Epoch 88/600\n",
            "1400/1400 - 12s - loss: 0.2517 - accuracy: 0.8355 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 2.4414e-06 - 12s/epoch - 8ms/step\n",
            "Epoch 89/600\n",
            "1400/1400 - 12s - loss: 0.2517 - accuracy: 0.8356 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 2.4414e-06 - 12s/epoch - 8ms/step\n",
            "Epoch 90/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8364 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 2.4414e-06 - 12s/epoch - 8ms/step\n",
            "Epoch 91/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8363 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 2.4414e-06 - 12s/epoch - 8ms/step\n",
            "Epoch 92/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8362 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 1.2207e-06 - 12s/epoch - 8ms/step\n",
            "Epoch 93/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8368 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 1.2207e-06 - 12s/epoch - 8ms/step\n",
            "Epoch 94/600\n",
            "1400/1400 - 11s - loss: 0.2516 - accuracy: 0.8362 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 1.2207e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 95/600\n",
            "1400/1400 - 13s - loss: 0.2516 - accuracy: 0.8366 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 6.1035e-07 - 13s/epoch - 9ms/step\n",
            "Epoch 96/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8364 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 6.1035e-07 - 12s/epoch - 8ms/step\n",
            "Epoch 97/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8356 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 6.1035e-07 - 12s/epoch - 8ms/step\n",
            "Epoch 98/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8363 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 3.0518e-07 - 12s/epoch - 8ms/step\n",
            "Epoch 99/600\n",
            "1400/1400 - 11s - loss: 0.2516 - accuracy: 0.8362 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 3.0518e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 100/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8356 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 3.0518e-07 - 12s/epoch - 8ms/step\n",
            "Epoch 101/600\n",
            "1400/1400 - 12s - loss: 0.2515 - accuracy: 0.8367 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 1.5259e-07 - 12s/epoch - 8ms/step\n",
            "Epoch 102/600\n",
            "1400/1400 - 11s - loss: 0.2517 - accuracy: 0.8351 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 1.5259e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 103/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8368 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 1.5259e-07 - 12s/epoch - 8ms/step\n",
            "Epoch 104/600\n",
            "1400/1400 - 11s - loss: 0.2515 - accuracy: 0.8370 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 7.6294e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 105/600\n",
            "1400/1400 - 11s - loss: 0.2515 - accuracy: 0.8370 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 7.6294e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 106/600\n",
            "1400/1400 - 12s - loss: 0.2515 - accuracy: 0.8369 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 7.6294e-08 - 12s/epoch - 8ms/step\n",
            "Epoch 107/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8372 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 3.8147e-08 - 12s/epoch - 8ms/step\n",
            "Epoch 108/600\n",
            "1400/1400 - 12s - loss: 0.2515 - accuracy: 0.8370 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 3.8147e-08 - 12s/epoch - 8ms/step\n",
            "Epoch 109/600\n",
            "1400/1400 - 12s - loss: 0.2515 - accuracy: 0.8370 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 3.8147e-08 - 12s/epoch - 8ms/step\n",
            "Epoch 110/600\n",
            "1400/1400 - 12s - loss: 0.2515 - accuracy: 0.8361 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 1.9073e-08 - 12s/epoch - 8ms/step\n",
            "Epoch 111/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8352 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 1.9073e-08 - 12s/epoch - 8ms/step\n",
            "Epoch 112/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8362 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 1.9073e-08 - 12s/epoch - 8ms/step\n",
            "Epoch 113/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8363 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 9.5367e-09 - 12s/epoch - 8ms/step\n",
            "Epoch 114/600\n",
            "1400/1400 - 12s - loss: 0.2515 - accuracy: 0.8369 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 9.5367e-09 - 12s/epoch - 8ms/step\n",
            "Epoch 115/600\n",
            "1400/1400 - 12s - loss: 0.2515 - accuracy: 0.8364 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 9.5367e-09 - 12s/epoch - 8ms/step\n",
            "Epoch 116/600\n",
            "1400/1400 - 12s - loss: 0.2515 - accuracy: 0.8369 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 4.7684e-09 - 12s/epoch - 8ms/step\n",
            "Epoch 117/600\n",
            "1400/1400 - 12s - loss: 0.2515 - accuracy: 0.8374 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 4.7684e-09 - 12s/epoch - 8ms/step\n",
            "Epoch 118/600\n",
            "1400/1400 - 12s - loss: 0.2515 - accuracy: 0.8368 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 4.7684e-09 - 12s/epoch - 8ms/step\n",
            "Epoch 119/600\n",
            "1400/1400 - 12s - loss: 0.2516 - accuracy: 0.8361 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 2.3842e-09 - 12s/epoch - 8ms/step\n",
            "Epoch 120/600\n",
            "1400/1400 - 12s - loss: 0.2515 - accuracy: 0.8369 - val_loss: 0.2500 - val_accuracy: 0.8370 - lr: 2.3842e-09 - 12s/epoch - 8ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " ...\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " ...\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12 14]\n",
            " ...\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12  2]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 24]\n",
            " ...\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 20]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " ...\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 24 25 15]\n",
            " ...\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 20 25  7]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 23]\n",
            " ...\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ...  7 18 13]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 23 17  9]\n",
            " ...\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 13 17  1]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  9 21 22]\n",
            " ...\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21  4]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ... 22  3  5]\n",
            " ...\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  8]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " ...\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " ...\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_1 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1404/1404 - 17s - loss: 0.6708 - accuracy: 0.7913 - val_loss: 0.3603 - val_accuracy: 0.8355 - lr: 0.0050 - 17s/epoch - 12ms/step\n",
            "Epoch 2/600\n",
            "1404/1404 - 12s - loss: 0.4022 - accuracy: 0.8270 - val_loss: 0.3285 - val_accuracy: 0.8365 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 3/600\n",
            "1404/1404 - 12s - loss: 0.4225 - accuracy: 0.8272 - val_loss: 0.3315 - val_accuracy: 0.8351 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 4/600\n",
            "1404/1404 - 12s - loss: 0.3651 - accuracy: 0.8287 - val_loss: 0.3221 - val_accuracy: 0.8347 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 5/600\n",
            "1404/1404 - 13s - loss: 0.3939 - accuracy: 0.8277 - val_loss: 0.5515 - val_accuracy: 0.8288 - lr: 0.0050 - 13s/epoch - 9ms/step\n",
            "Epoch 6/600\n",
            "1404/1404 - 12s - loss: 0.3769 - accuracy: 0.8305 - val_loss: 0.3276 - val_accuracy: 0.8362 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 7/600\n",
            "1404/1404 - 12s - loss: 0.3281 - accuracy: 0.8309 - val_loss: 0.6452 - val_accuracy: 0.7283 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 8/600\n",
            "1404/1404 - 12s - loss: 0.3020 - accuracy: 0.8342 - val_loss: 0.2917 - val_accuracy: 0.8362 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 9/600\n",
            "1404/1404 - 12s - loss: 0.3149 - accuracy: 0.8324 - val_loss: 0.2871 - val_accuracy: 0.8275 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 10/600\n",
            "1404/1404 - 13s - loss: 0.3011 - accuracy: 0.8330 - val_loss: 0.2808 - val_accuracy: 0.8350 - lr: 0.0025 - 13s/epoch - 9ms/step\n",
            "Epoch 11/600\n",
            "1404/1404 - 12s - loss: 0.2948 - accuracy: 0.8340 - val_loss: 0.2870 - val_accuracy: 0.8364 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 12/600\n",
            "1404/1404 - 12s - loss: 0.3080 - accuracy: 0.8333 - val_loss: 0.2834 - val_accuracy: 0.8361 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 13/600\n",
            "1404/1404 - 12s - loss: 0.3238 - accuracy: 0.8318 - val_loss: 0.2932 - val_accuracy: 0.8360 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 14/600\n",
            "1404/1404 - 12s - loss: 0.2807 - accuracy: 0.8346 - val_loss: 0.2735 - val_accuracy: 0.8348 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 15/600\n",
            "1404/1404 - 12s - loss: 0.2745 - accuracy: 0.8349 - val_loss: 0.2707 - val_accuracy: 0.8361 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 16/600\n",
            "1404/1404 - 12s - loss: 0.2833 - accuracy: 0.8334 - val_loss: 0.2711 - val_accuracy: 0.8346 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 17/600\n",
            "1404/1404 - 12s - loss: 0.2722 - accuracy: 0.8349 - val_loss: 0.2680 - val_accuracy: 0.8339 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 18/600\n",
            "1404/1404 - 12s - loss: 0.2824 - accuracy: 0.8339 - val_loss: 0.2685 - val_accuracy: 0.8360 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 19/600\n",
            "1404/1404 - 12s - loss: 0.2701 - accuracy: 0.8347 - val_loss: 0.2663 - val_accuracy: 0.8352 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 20/600\n",
            "1404/1404 - 12s - loss: 0.2772 - accuracy: 0.8340 - val_loss: 0.2687 - val_accuracy: 0.8351 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 21/600\n",
            "1404/1404 - 12s - loss: 0.2764 - accuracy: 0.8349 - val_loss: 0.2692 - val_accuracy: 0.8360 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 22/600\n",
            "1404/1404 - 12s - loss: 0.2693 - accuracy: 0.8349 - val_loss: 0.2669 - val_accuracy: 0.8358 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 23/600\n",
            "1404/1404 - 12s - loss: 0.2629 - accuracy: 0.8357 - val_loss: 0.2597 - val_accuracy: 0.8357 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 24/600\n",
            "1404/1404 - 12s - loss: 0.2651 - accuracy: 0.8338 - val_loss: 0.2928 - val_accuracy: 0.8347 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 25/600\n",
            "1404/1404 - 12s - loss: 0.2630 - accuracy: 0.8355 - val_loss: 0.2585 - val_accuracy: 0.8348 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 26/600\n",
            "1404/1404 - 12s - loss: 0.2605 - accuracy: 0.8361 - val_loss: 0.2586 - val_accuracy: 0.8359 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 27/600\n",
            "1404/1404 - 12s - loss: 0.2605 - accuracy: 0.8368 - val_loss: 0.2587 - val_accuracy: 0.8354 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 28/600\n",
            "1404/1404 - 12s - loss: 0.2636 - accuracy: 0.8347 - val_loss: 0.2566 - val_accuracy: 0.8346 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 29/600\n",
            "1404/1404 - 12s - loss: 0.2598 - accuracy: 0.8350 - val_loss: 0.2579 - val_accuracy: 0.8363 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 30/600\n",
            "1404/1404 - 12s - loss: 0.2653 - accuracy: 0.8346 - val_loss: 0.2572 - val_accuracy: 0.8359 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 31/600\n",
            "1404/1404 - 12s - loss: 0.2593 - accuracy: 0.8357 - val_loss: 0.2572 - val_accuracy: 0.8347 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 32/600\n",
            "1404/1404 - 13s - loss: 0.2562 - accuracy: 0.8365 - val_loss: 0.2545 - val_accuracy: 0.8354 - lr: 3.1250e-04 - 13s/epoch - 9ms/step\n",
            "Epoch 33/600\n",
            "1404/1404 - 12s - loss: 0.2561 - accuracy: 0.8346 - val_loss: 0.2543 - val_accuracy: 0.8343 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 34/600\n",
            "1404/1404 - 12s - loss: 0.2566 - accuracy: 0.8357 - val_loss: 0.2632 - val_accuracy: 0.8358 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 35/600\n",
            "1404/1404 - 13s - loss: 0.2560 - accuracy: 0.8359 - val_loss: 0.2544 - val_accuracy: 0.8363 - lr: 3.1250e-04 - 13s/epoch - 9ms/step\n",
            "Epoch 36/600\n",
            "1404/1404 - 12s - loss: 0.2555 - accuracy: 0.8356 - val_loss: 0.2536 - val_accuracy: 0.8364 - lr: 3.1250e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 37/600\n",
            "1404/1404 - 12s - loss: 0.2557 - accuracy: 0.8354 - val_loss: 0.2542 - val_accuracy: 0.8356 - lr: 3.1250e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 38/600\n",
            "1404/1404 - 12s - loss: 0.2557 - accuracy: 0.8360 - val_loss: 0.2533 - val_accuracy: 0.8359 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 39/600\n",
            "1404/1404 - 13s - loss: 0.2559 - accuracy: 0.8361 - val_loss: 0.2532 - val_accuracy: 0.8359 - lr: 3.1250e-04 - 13s/epoch - 9ms/step\n",
            "Epoch 40/600\n",
            "1404/1404 - 12s - loss: 0.2553 - accuracy: 0.8350 - val_loss: 0.2541 - val_accuracy: 0.8360 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 41/600\n",
            "1404/1404 - 12s - loss: 0.2554 - accuracy: 0.8354 - val_loss: 0.2543 - val_accuracy: 0.8355 - lr: 3.1250e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 42/600\n",
            "1404/1404 - 13s - loss: 0.2532 - accuracy: 0.8365 - val_loss: 0.2514 - val_accuracy: 0.8335 - lr: 1.5625e-04 - 13s/epoch - 9ms/step\n",
            "Epoch 43/600\n",
            "1404/1404 - 12s - loss: 0.2532 - accuracy: 0.8354 - val_loss: 0.2512 - val_accuracy: 0.8363 - lr: 1.5625e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 44/600\n",
            "1404/1404 - 12s - loss: 0.2532 - accuracy: 0.8359 - val_loss: 0.2511 - val_accuracy: 0.8338 - lr: 1.5625e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 45/600\n",
            "1404/1404 - 12s - loss: 0.2531 - accuracy: 0.8357 - val_loss: 0.2512 - val_accuracy: 0.8351 - lr: 1.5625e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 46/600\n",
            "1404/1404 - 12s - loss: 0.2529 - accuracy: 0.8361 - val_loss: 0.2512 - val_accuracy: 0.8353 - lr: 1.5625e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 47/600\n",
            "1404/1404 - 12s - loss: 0.2528 - accuracy: 0.8369 - val_loss: 0.2510 - val_accuracy: 0.8354 - lr: 1.5625e-04 - 12s/epoch - 8ms/step\n",
            "Epoch 48/600\n",
            "1404/1404 - 12s - loss: 0.2518 - accuracy: 0.8362 - val_loss: 0.2505 - val_accuracy: 0.8348 - lr: 7.8125e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 49/600\n",
            "1404/1404 - 13s - loss: 0.2518 - accuracy: 0.8351 - val_loss: 0.2502 - val_accuracy: 0.8356 - lr: 7.8125e-05 - 13s/epoch - 9ms/step\n",
            "Epoch 50/600\n",
            "1404/1404 - 12s - loss: 0.2518 - accuracy: 0.8355 - val_loss: 0.2501 - val_accuracy: 0.8369 - lr: 7.8125e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 51/600\n",
            "1404/1404 - 12s - loss: 0.2515 - accuracy: 0.8362 - val_loss: 0.2503 - val_accuracy: 0.8357 - lr: 7.8125e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 52/600\n",
            "1404/1404 - 12s - loss: 0.2517 - accuracy: 0.8357 - val_loss: 0.2500 - val_accuracy: 0.8366 - lr: 7.8125e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 53/600\n",
            "1404/1404 - 12s - loss: 0.2515 - accuracy: 0.8360 - val_loss: 0.2500 - val_accuracy: 0.8364 - lr: 7.8125e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 54/600\n",
            "1404/1404 - 12s - loss: 0.2515 - accuracy: 0.8359 - val_loss: 0.2499 - val_accuracy: 0.8351 - lr: 7.8125e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 55/600\n",
            "1404/1404 - 12s - loss: 0.2516 - accuracy: 0.8357 - val_loss: 0.2500 - val_accuracy: 0.8371 - lr: 7.8125e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 56/600\n",
            "1404/1404 - 12s - loss: 0.2510 - accuracy: 0.8361 - val_loss: 0.2495 - val_accuracy: 0.8350 - lr: 3.9062e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 57/600\n",
            "1404/1404 - 12s - loss: 0.2507 - accuracy: 0.8369 - val_loss: 0.2494 - val_accuracy: 0.8347 - lr: 3.9062e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 58/600\n",
            "1404/1404 - 12s - loss: 0.2507 - accuracy: 0.8366 - val_loss: 0.2494 - val_accuracy: 0.8364 - lr: 3.9062e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 59/600\n",
            "1404/1404 - 12s - loss: 0.2510 - accuracy: 0.8349 - val_loss: 0.2494 - val_accuracy: 0.8348 - lr: 3.9062e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 60/600\n",
            "1404/1404 - 12s - loss: 0.2508 - accuracy: 0.8360 - val_loss: 0.2493 - val_accuracy: 0.8349 - lr: 3.9062e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 61/600\n",
            "1404/1404 - 12s - loss: 0.2505 - accuracy: 0.8364 - val_loss: 0.2492 - val_accuracy: 0.8367 - lr: 1.9531e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 62/600\n",
            "1404/1404 - 12s - loss: 0.2505 - accuracy: 0.8353 - val_loss: 0.2492 - val_accuracy: 0.8375 - lr: 1.9531e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 63/600\n",
            "1404/1404 - 12s - loss: 0.2506 - accuracy: 0.8360 - val_loss: 0.2491 - val_accuracy: 0.8363 - lr: 1.9531e-05 - 12s/epoch - 8ms/step\n",
            "Epoch 64/600\n",
            "1404/1404 - 13s - loss: 0.2506 - accuracy: 0.8355 - val_loss: 0.2492 - val_accuracy: 0.8364 - lr: 1.9531e-05 - 13s/epoch - 9ms/step\n",
            "Epoch 65/600\n",
            "1404/1404 - 12s - loss: 0.2504 - accuracy: 0.8362 - val_loss: 0.2493 - val_accuracy: 0.8349 - lr: 9.7656e-06 - 12s/epoch - 8ms/step\n",
            "Epoch 66/600\n",
            "1404/1404 - 12s - loss: 0.2502 - accuracy: 0.8369 - val_loss: 0.2490 - val_accuracy: 0.8353 - lr: 9.7656e-06 - 12s/epoch - 8ms/step\n",
            "Epoch 67/600\n",
            "1404/1404 - 12s - loss: 0.2504 - accuracy: 0.8359 - val_loss: 0.2490 - val_accuracy: 0.8356 - lr: 9.7656e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 68/600\n",
            "1404/1404 - 12s - loss: 0.2504 - accuracy: 0.8359 - val_loss: 0.2490 - val_accuracy: 0.8368 - lr: 9.7656e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 69/600\n",
            "1404/1404 - 12s - loss: 0.2504 - accuracy: 0.8358 - val_loss: 0.2491 - val_accuracy: 0.8363 - lr: 9.7656e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 70/600\n",
            "1404/1404 - 12s - loss: 0.2503 - accuracy: 0.8354 - val_loss: 0.2490 - val_accuracy: 0.8357 - lr: 4.8828e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 71/600\n",
            "1404/1404 - 13s - loss: 0.2503 - accuracy: 0.8352 - val_loss: 0.2490 - val_accuracy: 0.8356 - lr: 4.8828e-06 - 13s/epoch - 9ms/step\n",
            "Epoch 72/600\n",
            "1404/1404 - 12s - loss: 0.2503 - accuracy: 0.8346 - val_loss: 0.2489 - val_accuracy: 0.8360 - lr: 4.8828e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 73/600\n",
            "1404/1404 - 12s - loss: 0.2502 - accuracy: 0.8365 - val_loss: 0.2489 - val_accuracy: 0.8352 - lr: 2.4414e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 74/600\n",
            "1404/1404 - 12s - loss: 0.2502 - accuracy: 0.8350 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 2.4414e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 75/600\n",
            "1404/1404 - 12s - loss: 0.2501 - accuracy: 0.8371 - val_loss: 0.2489 - val_accuracy: 0.8358 - lr: 2.4414e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 76/600\n",
            "1404/1404 - 12s - loss: 0.2501 - accuracy: 0.8369 - val_loss: 0.2489 - val_accuracy: 0.8360 - lr: 2.4414e-06 - 12s/epoch - 8ms/step\n",
            "Epoch 77/600\n",
            "1404/1404 - 12s - loss: 0.2501 - accuracy: 0.8369 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 1.2207e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 78/600\n",
            "1404/1404 - 12s - loss: 0.2501 - accuracy: 0.8360 - val_loss: 0.2489 - val_accuracy: 0.8360 - lr: 1.2207e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 79/600\n",
            "1404/1404 - 12s - loss: 0.2501 - accuracy: 0.8367 - val_loss: 0.2489 - val_accuracy: 0.8352 - lr: 1.2207e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 80/600\n",
            "1404/1404 - 12s - loss: 0.2500 - accuracy: 0.8371 - val_loss: 0.2489 - val_accuracy: 0.8352 - lr: 6.1035e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 81/600\n",
            "1404/1404 - 12s - loss: 0.2501 - accuracy: 0.8364 - val_loss: 0.2489 - val_accuracy: 0.8352 - lr: 6.1035e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 82/600\n",
            "1404/1404 - 12s - loss: 0.2502 - accuracy: 0.8372 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 6.1035e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 83/600\n",
            "1404/1404 - 12s - loss: 0.2501 - accuracy: 0.8359 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 3.0518e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 84/600\n",
            "1404/1404 - 12s - loss: 0.2502 - accuracy: 0.8361 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 3.0518e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 85/600\n",
            "1404/1404 - 12s - loss: 0.2501 - accuracy: 0.8364 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 3.0518e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 86/600\n",
            "1404/1404 - 12s - loss: 0.2501 - accuracy: 0.8367 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 1.5259e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 87/600\n",
            "1404/1404 - 13s - loss: 0.2501 - accuracy: 0.8357 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 1.5259e-07 - 13s/epoch - 9ms/step\n",
            "Epoch 88/600\n",
            "1404/1404 - 12s - loss: 0.2501 - accuracy: 0.8355 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 1.5259e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 89/600\n",
            "1404/1404 - 12s - loss: 0.2500 - accuracy: 0.8370 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 7.6294e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 90/600\n",
            "1404/1404 - 12s - loss: 0.2500 - accuracy: 0.8370 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 7.6294e-08 - 12s/epoch - 8ms/step\n",
            "Epoch 91/600\n",
            "1404/1404 - 12s - loss: 0.2501 - accuracy: 0.8363 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 7.6294e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 92/600\n",
            "1404/1404 - 12s - loss: 0.2501 - accuracy: 0.8372 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 3.8147e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 93/600\n",
            "1404/1404 - 12s - loss: 0.2502 - accuracy: 0.8359 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 3.8147e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 94/600\n",
            "1404/1404 - 12s - loss: 0.2501 - accuracy: 0.8365 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 3.8147e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 95/600\n",
            "1404/1404 - 12s - loss: 0.2501 - accuracy: 0.8374 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 1.9073e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 96/600\n",
            "1404/1404 - 12s - loss: 0.2502 - accuracy: 0.8359 - val_loss: 0.2489 - val_accuracy: 0.8356 - lr: 1.9073e-08 - 12s/epoch - 9ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " ...\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " ...\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12  2]\n",
            " [28 27 10 ...  6 12 14]\n",
            " [28 27 10 ... 26 12 14]\n",
            " ...\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ... 26 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ... 14 11 20]\n",
            " ...\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ... 14 11 20]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " ...\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 20 25 15]\n",
            " ...\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 20 25  7]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ...  7 18 23]\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ... 15 18 13]\n",
            " ...\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ...  7 18 23]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " ...\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 13 17  9]\n",
            " ...\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 23 17  9]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " ...\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21  4]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  5]\n",
            " ...\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " ...\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " ...\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n"
          ]
        }
      ],
      "source": [
        "do_experiment('Model3', 8, True, 0, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ODW53I7KYbSJ",
        "outputId": "1287bf3d-a5db-486c-e744-a5b005395dbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prefix length: 20\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1325/1325 - 16s - loss: 0.6566 - accuracy: 0.7971 - val_loss: 0.3933 - val_accuracy: 0.8341 - lr: 0.0050 - 16s/epoch - 12ms/step\n",
            "Epoch 2/600\n",
            "1325/1325 - 11s - loss: 0.4160 - accuracy: 0.8308 - val_loss: 0.4714 - val_accuracy: 0.8387 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 3/600\n",
            "1325/1325 - 11s - loss: 0.3741 - accuracy: 0.8326 - val_loss: 0.4405 - val_accuracy: 0.8393 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 4/600\n",
            "1325/1325 - 11s - loss: 0.3298 - accuracy: 0.8356 - val_loss: 0.3105 - val_accuracy: 0.8370 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 5/600\n",
            "1325/1325 - 11s - loss: 0.5422 - accuracy: 0.8268 - val_loss: 0.3321 - val_accuracy: 0.8330 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 6/600\n",
            "1325/1325 - 11s - loss: 0.5719 - accuracy: 0.8204 - val_loss: 0.4342 - val_accuracy: 0.8385 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 7/600\n",
            "1325/1325 - 11s - loss: 0.4215 - accuracy: 0.8325 - val_loss: 0.3436 - val_accuracy: 0.8396 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 8/600\n",
            "1325/1325 - 11s - loss: 0.3461 - accuracy: 0.8358 - val_loss: 0.3854 - val_accuracy: 0.8386 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 9/600\n",
            "1325/1325 - 11s - loss: 0.3235 - accuracy: 0.8378 - val_loss: 0.3048 - val_accuracy: 0.8383 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 10/600\n",
            "1325/1325 - 11s - loss: 0.3239 - accuracy: 0.8360 - val_loss: 0.3164 - val_accuracy: 0.8413 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 11/600\n",
            "1325/1325 - 11s - loss: 0.3264 - accuracy: 0.8357 - val_loss: 0.3116 - val_accuracy: 0.8389 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 12/600\n",
            "1325/1325 - 11s - loss: 0.3065 - accuracy: 0.8366 - val_loss: 0.4732 - val_accuracy: 0.8360 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 13/600\n",
            "1325/1325 - 11s - loss: 0.3031 - accuracy: 0.8389 - val_loss: 0.2806 - val_accuracy: 0.8378 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 14/600\n",
            "1325/1325 - 11s - loss: 0.2859 - accuracy: 0.8396 - val_loss: 0.2842 - val_accuracy: 0.8382 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 15/600\n",
            "1325/1325 - 11s - loss: 0.2834 - accuracy: 0.8401 - val_loss: 0.2779 - val_accuracy: 0.8396 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 16/600\n",
            "1325/1325 - 11s - loss: 0.2872 - accuracy: 0.8382 - val_loss: 0.2813 - val_accuracy: 0.8377 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 17/600\n",
            "1325/1325 - 11s - loss: 0.2822 - accuracy: 0.8394 - val_loss: 0.2799 - val_accuracy: 0.8374 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 18/600\n",
            "1325/1325 - 11s - loss: 0.2906 - accuracy: 0.8391 - val_loss: 0.2747 - val_accuracy: 0.8377 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 19/600\n",
            "1325/1325 - 11s - loss: 0.2804 - accuracy: 0.8387 - val_loss: 0.2729 - val_accuracy: 0.8406 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 20/600\n",
            "1325/1325 - 11s - loss: 0.2854 - accuracy: 0.8386 - val_loss: 0.2739 - val_accuracy: 0.8389 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 21/600\n",
            "1325/1325 - 11s - loss: 0.2775 - accuracy: 0.8395 - val_loss: 0.2722 - val_accuracy: 0.8391 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 22/600\n",
            "1325/1325 - 12s - loss: 0.2811 - accuracy: 0.8401 - val_loss: 0.2727 - val_accuracy: 0.8361 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 23/600\n",
            "1325/1325 - 12s - loss: 0.2789 - accuracy: 0.8386 - val_loss: 0.2757 - val_accuracy: 0.8363 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 24/600\n",
            "1325/1325 - 11s - loss: 0.2888 - accuracy: 0.8383 - val_loss: 0.2831 - val_accuracy: 0.8385 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 25/600\n",
            "1325/1325 - 11s - loss: 0.2723 - accuracy: 0.8396 - val_loss: 0.2658 - val_accuracy: 0.8415 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 26/600\n",
            "1325/1325 - 11s - loss: 0.2692 - accuracy: 0.8392 - val_loss: 0.2661 - val_accuracy: 0.8406 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 27/600\n",
            "1325/1325 - 11s - loss: 0.2696 - accuracy: 0.8399 - val_loss: 0.2860 - val_accuracy: 0.8386 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 28/600\n",
            "1325/1325 - 11s - loss: 0.2693 - accuracy: 0.8392 - val_loss: 0.2641 - val_accuracy: 0.8413 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 29/600\n",
            "1325/1325 - 11s - loss: 0.2704 - accuracy: 0.8390 - val_loss: 0.2655 - val_accuracy: 0.8385 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 30/600\n",
            "1325/1325 - 11s - loss: 0.2693 - accuracy: 0.8396 - val_loss: 0.2649 - val_accuracy: 0.8384 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 31/600\n",
            "1325/1325 - 11s - loss: 0.2671 - accuracy: 0.8395 - val_loss: 0.2634 - val_accuracy: 0.8401 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 32/600\n",
            "1325/1325 - 11s - loss: 0.2683 - accuracy: 0.8391 - val_loss: 0.2646 - val_accuracy: 0.8380 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 33/600\n",
            "1325/1325 - 11s - loss: 0.2690 - accuracy: 0.8403 - val_loss: 0.2716 - val_accuracy: 0.8391 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 34/600\n",
            "1325/1325 - 11s - loss: 0.2665 - accuracy: 0.8404 - val_loss: 0.2637 - val_accuracy: 0.8391 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 35/600\n",
            "1325/1325 - 11s - loss: 0.2627 - accuracy: 0.8399 - val_loss: 0.2602 - val_accuracy: 0.8406 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 36/600\n",
            "1325/1325 - 11s - loss: 0.2623 - accuracy: 0.8392 - val_loss: 0.2608 - val_accuracy: 0.8393 - lr: 3.1250e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 37/600\n",
            "1325/1325 - 11s - loss: 0.2627 - accuracy: 0.8403 - val_loss: 0.2605 - val_accuracy: 0.8416 - lr: 3.1250e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 38/600\n",
            "1325/1325 - 11s - loss: 0.2631 - accuracy: 0.8413 - val_loss: 0.2603 - val_accuracy: 0.8386 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 39/600\n",
            "1325/1325 - 11s - loss: 0.2603 - accuracy: 0.8398 - val_loss: 0.2576 - val_accuracy: 0.8402 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 40/600\n",
            "1325/1325 - 11s - loss: 0.2599 - accuracy: 0.8412 - val_loss: 0.2574 - val_accuracy: 0.8405 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 41/600\n",
            "1325/1325 - 11s - loss: 0.2600 - accuracy: 0.8399 - val_loss: 0.2576 - val_accuracy: 0.8427 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 42/600\n",
            "1325/1325 - 11s - loss: 0.2598 - accuracy: 0.8400 - val_loss: 0.2574 - val_accuracy: 0.8398 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 43/600\n",
            "1325/1325 - 11s - loss: 0.2597 - accuracy: 0.8404 - val_loss: 0.2580 - val_accuracy: 0.8390 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 44/600\n",
            "1325/1325 - 11s - loss: 0.2587 - accuracy: 0.8405 - val_loss: 0.2563 - val_accuracy: 0.8405 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 45/600\n",
            "1325/1325 - 11s - loss: 0.2587 - accuracy: 0.8410 - val_loss: 0.2560 - val_accuracy: 0.8398 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 46/600\n",
            "1325/1325 - 11s - loss: 0.2586 - accuracy: 0.8402 - val_loss: 0.2562 - val_accuracy: 0.8397 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 47/600\n",
            "1325/1325 - 11s - loss: 0.2584 - accuracy: 0.8406 - val_loss: 0.2559 - val_accuracy: 0.8400 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 48/600\n",
            "1325/1325 - 11s - loss: 0.2583 - accuracy: 0.8412 - val_loss: 0.2563 - val_accuracy: 0.8400 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 49/600\n",
            "1325/1325 - 11s - loss: 0.2578 - accuracy: 0.8409 - val_loss: 0.2555 - val_accuracy: 0.8417 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 50/600\n",
            "1325/1325 - 11s - loss: 0.2578 - accuracy: 0.8405 - val_loss: 0.2553 - val_accuracy: 0.8405 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 51/600\n",
            "1325/1325 - 11s - loss: 0.2578 - accuracy: 0.8410 - val_loss: 0.2555 - val_accuracy: 0.8400 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 52/600\n",
            "1325/1325 - 11s - loss: 0.2575 - accuracy: 0.8417 - val_loss: 0.2553 - val_accuracy: 0.8410 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 53/600\n",
            "1325/1325 - 11s - loss: 0.2575 - accuracy: 0.8406 - val_loss: 0.2554 - val_accuracy: 0.8405 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 54/600\n",
            "1325/1325 - 11s - loss: 0.2573 - accuracy: 0.8416 - val_loss: 0.2551 - val_accuracy: 0.8400 - lr: 1.9531e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 55/600\n",
            "1325/1325 - 11s - loss: 0.2573 - accuracy: 0.8413 - val_loss: 0.2551 - val_accuracy: 0.8410 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 56/600\n",
            "1325/1325 - 11s - loss: 0.2572 - accuracy: 0.8412 - val_loss: 0.2550 - val_accuracy: 0.8410 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 57/600\n",
            "1325/1325 - 11s - loss: 0.2572 - accuracy: 0.8416 - val_loss: 0.2549 - val_accuracy: 0.8402 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 58/600\n",
            "1325/1325 - 11s - loss: 0.2571 - accuracy: 0.8412 - val_loss: 0.2549 - val_accuracy: 0.8402 - lr: 1.9531e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 59/600\n",
            "1325/1325 - 11s - loss: 0.2572 - accuracy: 0.8408 - val_loss: 0.2552 - val_accuracy: 0.8413 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 60/600\n",
            "1325/1325 - 11s - loss: 0.2573 - accuracy: 0.8406 - val_loss: 0.2548 - val_accuracy: 0.8410 - lr: 1.9531e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 61/600\n",
            "1325/1325 - 11s - loss: 0.2571 - accuracy: 0.8405 - val_loss: 0.2547 - val_accuracy: 0.8410 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 62/600\n",
            "1325/1325 - 12s - loss: 0.2570 - accuracy: 0.8407 - val_loss: 0.2547 - val_accuracy: 0.8402 - lr: 9.7656e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 63/600\n",
            "1325/1325 - 11s - loss: 0.2570 - accuracy: 0.8403 - val_loss: 0.2547 - val_accuracy: 0.8410 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 64/600\n",
            "1325/1325 - 11s - loss: 0.2568 - accuracy: 0.8414 - val_loss: 0.2547 - val_accuracy: 0.8405 - lr: 9.7656e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 65/600\n",
            "1325/1325 - 11s - loss: 0.2568 - accuracy: 0.8410 - val_loss: 0.2546 - val_accuracy: 0.8410 - lr: 4.8828e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 66/600\n",
            "1325/1325 - 11s - loss: 0.2567 - accuracy: 0.8414 - val_loss: 0.2546 - val_accuracy: 0.8410 - lr: 4.8828e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 67/600\n",
            "1325/1325 - 11s - loss: 0.2569 - accuracy: 0.8412 - val_loss: 0.2546 - val_accuracy: 0.8410 - lr: 4.8828e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 68/600\n",
            "1325/1325 - 11s - loss: 0.2566 - accuracy: 0.8408 - val_loss: 0.2546 - val_accuracy: 0.8410 - lr: 2.4414e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 69/600\n",
            "1325/1325 - 11s - loss: 0.2568 - accuracy: 0.8420 - val_loss: 0.2546 - val_accuracy: 0.8410 - lr: 2.4414e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 70/600\n",
            "1325/1325 - 11s - loss: 0.2566 - accuracy: 0.8418 - val_loss: 0.2546 - val_accuracy: 0.8410 - lr: 2.4414e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 71/600\n",
            "1325/1325 - 11s - loss: 0.2568 - accuracy: 0.8412 - val_loss: 0.2546 - val_accuracy: 0.8410 - lr: 2.4414e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 72/600\n",
            "1325/1325 - 11s - loss: 0.2566 - accuracy: 0.8418 - val_loss: 0.2546 - val_accuracy: 0.8410 - lr: 1.2207e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 73/600\n",
            "1325/1325 - 11s - loss: 0.2568 - accuracy: 0.8410 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 74/600\n",
            "1325/1325 - 11s - loss: 0.2567 - accuracy: 0.8401 - val_loss: 0.2546 - val_accuracy: 0.8410 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 75/600\n",
            "1325/1325 - 11s - loss: 0.2567 - accuracy: 0.8414 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 6.1035e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 76/600\n",
            "1325/1325 - 11s - loss: 0.2567 - accuracy: 0.8417 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 6.1035e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 77/600\n",
            "1325/1325 - 11s - loss: 0.2567 - accuracy: 0.8422 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 6.1035e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 78/600\n",
            "1325/1325 - 11s - loss: 0.2568 - accuracy: 0.8407 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 79/600\n",
            "1325/1325 - 11s - loss: 0.2567 - accuracy: 0.8412 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 3.0518e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 80/600\n",
            "1325/1325 - 11s - loss: 0.2567 - accuracy: 0.8410 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 3.0518e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 81/600\n",
            "1325/1325 - 11s - loss: 0.2566 - accuracy: 0.8413 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 1.5259e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 82/600\n",
            "1325/1325 - 11s - loss: 0.2567 - accuracy: 0.8412 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 1.5259e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 83/600\n",
            "1325/1325 - 11s - loss: 0.2566 - accuracy: 0.8415 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 1.5259e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 84/600\n",
            "1325/1325 - 11s - loss: 0.2567 - accuracy: 0.8415 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 7.6294e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 85/600\n",
            "1325/1325 - 11s - loss: 0.2568 - accuracy: 0.8414 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 7.6294e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 86/600\n",
            "1325/1325 - 11s - loss: 0.2566 - accuracy: 0.8414 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 7.6294e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 87/600\n",
            "1325/1325 - 11s - loss: 0.2567 - accuracy: 0.8403 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 3.8147e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 88/600\n",
            "1325/1325 - 11s - loss: 0.2568 - accuracy: 0.8406 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 3.8147e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 89/600\n",
            "1325/1325 - 11s - loss: 0.2568 - accuracy: 0.8409 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 90/600\n",
            "1325/1325 - 12s - loss: 0.2568 - accuracy: 0.8416 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 1.9073e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 91/600\n",
            "1325/1325 - 12s - loss: 0.2568 - accuracy: 0.8404 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 1.9073e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 92/600\n",
            "1325/1325 - 11s - loss: 0.2567 - accuracy: 0.8413 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 1.9073e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 93/600\n",
            "1325/1325 - 11s - loss: 0.2567 - accuracy: 0.8410 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 9.5367e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 94/600\n",
            "1325/1325 - 11s - loss: 0.2566 - accuracy: 0.8421 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 9.5367e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 95/600\n",
            "1325/1325 - 12s - loss: 0.2566 - accuracy: 0.8411 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 9.5367e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 96/600\n",
            "1325/1325 - 11s - loss: 0.2565 - accuracy: 0.8415 - val_loss: 0.2545 - val_accuracy: 0.8410 - lr: 4.7684e-09 - 11s/epoch - 9ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " ...\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " ...\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ...  6 12 14]\n",
            " ...\n",
            " [28 27 10 ...  6 12 14]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12  2]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ... 14 11 20]\n",
            " ...\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 24]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " ...\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 20 25  7]\n",
            " ...\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25  7]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " ...\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ...  7 18 23]\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ...  7 18 23]\n",
            " ...\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ...  7 18 13]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 23 17  9]\n",
            " ...\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 13 17  9]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21 22]\n",
            " ...\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " ...\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  8]\n",
            " ...\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " ...\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " ...\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_3 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1329/1329 - 16s - loss: 0.8853 - accuracy: 0.7622 - val_loss: 0.4904 - val_accuracy: 0.8077 - lr: 0.0050 - 16s/epoch - 12ms/step\n",
            "Epoch 2/600\n",
            "1329/1329 - 11s - loss: 0.5555 - accuracy: 0.8072 - val_loss: 0.4232 - val_accuracy: 0.8305 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 3/600\n",
            "1329/1329 - 11s - loss: 0.5060 - accuracy: 0.8202 - val_loss: 0.4641 - val_accuracy: 0.8324 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 4/600\n",
            "1329/1329 - 11s - loss: 0.4161 - accuracy: 0.8258 - val_loss: 0.3585 - val_accuracy: 0.8220 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 5/600\n",
            "1329/1329 - 11s - loss: 0.4175 - accuracy: 0.8256 - val_loss: 0.4873 - val_accuracy: 0.8320 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 6/600\n",
            "1329/1329 - 11s - loss: 0.4233 - accuracy: 0.8268 - val_loss: 0.3482 - val_accuracy: 0.8295 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 7/600\n",
            "1329/1329 - 13s - loss: 0.3735 - accuracy: 0.8286 - val_loss: 0.4603 - val_accuracy: 0.8187 - lr: 0.0050 - 13s/epoch - 9ms/step\n",
            "Epoch 8/600\n",
            "1329/1329 - 11s - loss: 0.3735 - accuracy: 0.8279 - val_loss: 0.3309 - val_accuracy: 0.8303 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 9/600\n",
            "1329/1329 - 11s - loss: 0.3633 - accuracy: 0.8277 - val_loss: 0.3303 - val_accuracy: 0.8300 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 10/600\n",
            "1329/1329 - 11s - loss: 0.3966 - accuracy: 0.8269 - val_loss: 0.4117 - val_accuracy: 0.8277 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 11/600\n",
            "1329/1329 - 11s - loss: 0.3590 - accuracy: 0.8285 - val_loss: 0.3213 - val_accuracy: 0.8298 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 12/600\n",
            "1329/1329 - 11s - loss: 0.3557 - accuracy: 0.8289 - val_loss: 0.3212 - val_accuracy: 0.8303 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 13/600\n",
            "1329/1329 - 11s - loss: 0.3653 - accuracy: 0.8282 - val_loss: 0.3180 - val_accuracy: 0.8293 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 14/600\n",
            "1329/1329 - 11s - loss: 0.3436 - accuracy: 0.8281 - val_loss: 0.3138 - val_accuracy: 0.8302 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 15/600\n",
            "1329/1329 - 11s - loss: 0.3619 - accuracy: 0.8283 - val_loss: 0.3236 - val_accuracy: 0.8308 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 16/600\n",
            "1329/1329 - 11s - loss: 0.3225 - accuracy: 0.8282 - val_loss: 0.3135 - val_accuracy: 0.8300 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 17/600\n",
            "1329/1329 - 11s - loss: 0.3856 - accuracy: 0.8263 - val_loss: 0.3145 - val_accuracy: 0.8283 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 18/600\n",
            "1329/1329 - 11s - loss: 0.3243 - accuracy: 0.8296 - val_loss: 0.3224 - val_accuracy: 0.8291 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 19/600\n",
            "1329/1329 - 11s - loss: 0.3366 - accuracy: 0.8303 - val_loss: 0.3110 - val_accuracy: 0.8284 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 20/600\n",
            "1329/1329 - 11s - loss: 0.3233 - accuracy: 0.8303 - val_loss: 0.3079 - val_accuracy: 0.8319 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 21/600\n",
            "1329/1329 - 11s - loss: 0.3426 - accuracy: 0.8287 - val_loss: 0.3074 - val_accuracy: 0.8280 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 22/600\n",
            "1329/1329 - 11s - loss: 0.3665 - accuracy: 0.8270 - val_loss: 0.3344 - val_accuracy: 0.8293 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 23/600\n",
            "1329/1329 - 11s - loss: 0.3170 - accuracy: 0.8291 - val_loss: 0.3078 - val_accuracy: 0.8284 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 24/600\n",
            "1329/1329 - 11s - loss: 0.3308 - accuracy: 0.8285 - val_loss: 0.3094 - val_accuracy: 0.8321 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 25/600\n",
            "1329/1329 - 11s - loss: 0.2960 - accuracy: 0.8309 - val_loss: 0.2902 - val_accuracy: 0.8312 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 26/600\n",
            "1329/1329 - 11s - loss: 0.2967 - accuracy: 0.8314 - val_loss: 0.2918 - val_accuracy: 0.8307 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 27/600\n",
            "1329/1329 - 11s - loss: 0.3007 - accuracy: 0.8297 - val_loss: 0.2922 - val_accuracy: 0.8300 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 28/600\n",
            "1329/1329 - 11s - loss: 0.3032 - accuracy: 0.8290 - val_loss: 0.2885 - val_accuracy: 0.8332 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 29/600\n",
            "1329/1329 - 11s - loss: 0.2927 - accuracy: 0.8315 - val_loss: 0.2869 - val_accuracy: 0.8313 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 30/600\n",
            "1329/1329 - 11s - loss: 0.2967 - accuracy: 0.8308 - val_loss: 0.2990 - val_accuracy: 0.8310 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 31/600\n",
            "1329/1329 - 11s - loss: 0.3051 - accuracy: 0.8294 - val_loss: 0.2879 - val_accuracy: 0.8310 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 32/600\n",
            "1329/1329 - 11s - loss: 0.2955 - accuracy: 0.8301 - val_loss: 0.2876 - val_accuracy: 0.8314 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 33/600\n",
            "1329/1329 - 11s - loss: 0.2821 - accuracy: 0.8297 - val_loss: 0.2767 - val_accuracy: 0.8284 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 34/600\n",
            "1329/1329 - 12s - loss: 0.2816 - accuracy: 0.8300 - val_loss: 0.2769 - val_accuracy: 0.8304 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 35/600\n",
            "1329/1329 - 12s - loss: 0.2838 - accuracy: 0.8300 - val_loss: 0.2761 - val_accuracy: 0.8315 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 36/600\n",
            "1329/1329 - 12s - loss: 0.2807 - accuracy: 0.8303 - val_loss: 0.2771 - val_accuracy: 0.8319 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 37/600\n",
            "1329/1329 - 13s - loss: 0.2809 - accuracy: 0.8295 - val_loss: 0.2763 - val_accuracy: 0.8318 - lr: 0.0012 - 13s/epoch - 9ms/step\n",
            "Epoch 38/600\n",
            "1329/1329 - 12s - loss: 0.2867 - accuracy: 0.8302 - val_loss: 0.2783 - val_accuracy: 0.8324 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 39/600\n",
            "1329/1329 - 11s - loss: 0.2758 - accuracy: 0.8304 - val_loss: 0.2714 - val_accuracy: 0.8321 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 40/600\n",
            "1329/1329 - 11s - loss: 0.2747 - accuracy: 0.8303 - val_loss: 0.2709 - val_accuracy: 0.8294 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 41/600\n",
            "1329/1329 - 11s - loss: 0.2747 - accuracy: 0.8300 - val_loss: 0.2708 - val_accuracy: 0.8297 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 42/600\n",
            "1329/1329 - 11s - loss: 0.2746 - accuracy: 0.8319 - val_loss: 0.2713 - val_accuracy: 0.8315 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 43/600\n",
            "1329/1329 - 11s - loss: 0.2747 - accuracy: 0.8312 - val_loss: 0.2707 - val_accuracy: 0.8300 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 44/600\n",
            "1329/1329 - 11s - loss: 0.2744 - accuracy: 0.8300 - val_loss: 0.2710 - val_accuracy: 0.8315 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 45/600\n",
            "1329/1329 - 11s - loss: 0.2716 - accuracy: 0.8290 - val_loss: 0.2678 - val_accuracy: 0.8319 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 46/600\n",
            "1329/1329 - 11s - loss: 0.2714 - accuracy: 0.8308 - val_loss: 0.2680 - val_accuracy: 0.8332 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 47/600\n",
            "1329/1329 - 12s - loss: 0.2713 - accuracy: 0.8309 - val_loss: 0.2678 - val_accuracy: 0.8322 - lr: 3.1250e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 48/600\n",
            "1329/1329 - 11s - loss: 0.2712 - accuracy: 0.8302 - val_loss: 0.2682 - val_accuracy: 0.8284 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 49/600\n",
            "1329/1329 - 11s - loss: 0.2699 - accuracy: 0.8303 - val_loss: 0.2668 - val_accuracy: 0.8315 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 50/600\n",
            "1329/1329 - 11s - loss: 0.2698 - accuracy: 0.8312 - val_loss: 0.2668 - val_accuracy: 0.8328 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 51/600\n",
            "1329/1329 - 11s - loss: 0.2697 - accuracy: 0.8312 - val_loss: 0.2666 - val_accuracy: 0.8304 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 52/600\n",
            "1329/1329 - 12s - loss: 0.2695 - accuracy: 0.8305 - val_loss: 0.2666 - val_accuracy: 0.8324 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 53/600\n",
            "1329/1329 - 11s - loss: 0.2695 - accuracy: 0.8307 - val_loss: 0.2666 - val_accuracy: 0.8324 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 54/600\n",
            "1329/1329 - 11s - loss: 0.2695 - accuracy: 0.8317 - val_loss: 0.2666 - val_accuracy: 0.8304 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 55/600\n",
            "1329/1329 - 11s - loss: 0.2688 - accuracy: 0.8313 - val_loss: 0.2662 - val_accuracy: 0.8319 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 56/600\n",
            "1329/1329 - 11s - loss: 0.2688 - accuracy: 0.8315 - val_loss: 0.2659 - val_accuracy: 0.8321 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 57/600\n",
            "1329/1329 - 11s - loss: 0.2688 - accuracy: 0.8305 - val_loss: 0.2658 - val_accuracy: 0.8302 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 58/600\n",
            "1329/1329 - 11s - loss: 0.2688 - accuracy: 0.8306 - val_loss: 0.2659 - val_accuracy: 0.8321 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 59/600\n",
            "1329/1329 - 11s - loss: 0.2687 - accuracy: 0.8316 - val_loss: 0.2658 - val_accuracy: 0.8321 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 60/600\n",
            "1329/1329 - 11s - loss: 0.2687 - accuracy: 0.8308 - val_loss: 0.2657 - val_accuracy: 0.8329 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 61/600\n",
            "1329/1329 - 11s - loss: 0.2686 - accuracy: 0.8309 - val_loss: 0.2657 - val_accuracy: 0.8321 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 62/600\n",
            "1329/1329 - 11s - loss: 0.2686 - accuracy: 0.8320 - val_loss: 0.2657 - val_accuracy: 0.8327 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 63/600\n",
            "1329/1329 - 11s - loss: 0.2684 - accuracy: 0.8314 - val_loss: 0.2655 - val_accuracy: 0.8329 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 64/600\n",
            "1329/1329 - 12s - loss: 0.2683 - accuracy: 0.8318 - val_loss: 0.2655 - val_accuracy: 0.8321 - lr: 3.9062e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 65/600\n",
            "1329/1329 - 11s - loss: 0.2682 - accuracy: 0.8310 - val_loss: 0.2655 - val_accuracy: 0.8321 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 66/600\n",
            "1329/1329 - 11s - loss: 0.2684 - accuracy: 0.8317 - val_loss: 0.2654 - val_accuracy: 0.8321 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 67/600\n",
            "1329/1329 - 11s - loss: 0.2683 - accuracy: 0.8311 - val_loss: 0.2654 - val_accuracy: 0.8321 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 68/600\n",
            "1329/1329 - 11s - loss: 0.2680 - accuracy: 0.8320 - val_loss: 0.2653 - val_accuracy: 0.8321 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 69/600\n",
            "1329/1329 - 11s - loss: 0.2681 - accuracy: 0.8315 - val_loss: 0.2653 - val_accuracy: 0.8321 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 70/600\n",
            "1329/1329 - 12s - loss: 0.2681 - accuracy: 0.8318 - val_loss: 0.2653 - val_accuracy: 0.8321 - lr: 1.9531e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 71/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8328 - val_loss: 0.2652 - val_accuracy: 0.8321 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 72/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8319 - val_loss: 0.2652 - val_accuracy: 0.8321 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 73/600\n",
            "1329/1329 - 11s - loss: 0.2680 - accuracy: 0.8325 - val_loss: 0.2652 - val_accuracy: 0.8321 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 74/600\n",
            "1329/1329 - 11s - loss: 0.2680 - accuracy: 0.8323 - val_loss: 0.2652 - val_accuracy: 0.8321 - lr: 9.7656e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 75/600\n",
            "1329/1329 - 12s - loss: 0.2680 - accuracy: 0.8319 - val_loss: 0.2652 - val_accuracy: 0.8321 - lr: 4.8828e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 76/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8326 - val_loss: 0.2652 - val_accuracy: 0.8321 - lr: 4.8828e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 77/600\n",
            "1329/1329 - 11s - loss: 0.2680 - accuracy: 0.8319 - val_loss: 0.2652 - val_accuracy: 0.8321 - lr: 4.8828e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 78/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8326 - val_loss: 0.2652 - val_accuracy: 0.8321 - lr: 2.4414e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 79/600\n",
            "1329/1329 - 11s - loss: 0.2680 - accuracy: 0.8318 - val_loss: 0.2652 - val_accuracy: 0.8321 - lr: 2.4414e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 80/600\n",
            "1329/1329 - 11s - loss: 0.2680 - accuracy: 0.8318 - val_loss: 0.2652 - val_accuracy: 0.8321 - lr: 2.4414e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 81/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8317 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 82/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8314 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 83/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8321 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 1.2207e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 84/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8319 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 6.1035e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 85/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8317 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 6.1035e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 86/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8325 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 6.1035e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 87/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8323 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 88/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8322 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 3.0518e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 89/600\n",
            "1329/1329 - 11s - loss: 0.2678 - accuracy: 0.8317 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 90/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8322 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 91/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8315 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 92/600\n",
            "1329/1329 - 11s - loss: 0.2678 - accuracy: 0.8316 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 1.5259e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 93/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8320 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 7.6294e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 94/600\n",
            "1329/1329 - 11s - loss: 0.2678 - accuracy: 0.8320 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 7.6294e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 95/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8318 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 7.6294e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 96/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8323 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 97/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8313 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 3.8147e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 98/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8312 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 99/600\n",
            "1329/1329 - 11s - loss: 0.2678 - accuracy: 0.8316 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 1.9073e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 100/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8325 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 1.9073e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 101/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8316 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 1.9073e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 102/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8322 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 9.5367e-09 - 11s/epoch - 8ms/step\n",
            "Epoch 103/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8317 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 9.5367e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 104/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8315 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 9.5367e-09 - 11s/epoch - 8ms/step\n",
            "Epoch 105/600\n",
            "1329/1329 - 11s - loss: 0.2679 - accuracy: 0.8320 - val_loss: 0.2651 - val_accuracy: 0.8321 - lr: 4.7684e-09 - 11s/epoch - 8ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " ...\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " ...\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12 14]\n",
            " ...\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12  2]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ... 14 11 24]\n",
            " ...\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 20]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " ...\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 24 25  7]\n",
            " ...\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 20 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ... 15 18 23]\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ...  7 18 13]\n",
            " ...\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 13]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " ...\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 13 17  9]\n",
            " ...\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  1]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21 22]\n",
            " ...\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " ...\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ... 22  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  5]\n",
            " ...\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " ...\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " ...\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_4 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1333/1333 - 16s - loss: 0.7478 - accuracy: 0.7908 - val_loss: 0.4607 - val_accuracy: 0.8394 - lr: 0.0050 - 16s/epoch - 12ms/step\n",
            "Epoch 2/600\n",
            "1333/1333 - 11s - loss: 0.4111 - accuracy: 0.8320 - val_loss: 0.3321 - val_accuracy: 0.8374 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 3/600\n",
            "1333/1333 - 11s - loss: 0.3906 - accuracy: 0.8312 - val_loss: 0.3354 - val_accuracy: 0.8243 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 4/600\n",
            "1333/1333 - 11s - loss: 0.3315 - accuracy: 0.8333 - val_loss: 0.3133 - val_accuracy: 0.8388 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 5/600\n",
            "1333/1333 - 11s - loss: 0.4989 - accuracy: 0.8237 - val_loss: 0.3552 - val_accuracy: 0.8362 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 6/600\n",
            "1333/1333 - 11s - loss: 0.3216 - accuracy: 0.8351 - val_loss: 0.3072 - val_accuracy: 0.8375 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 7/600\n",
            "1333/1333 - 11s - loss: 0.3576 - accuracy: 0.8339 - val_loss: 0.3097 - val_accuracy: 0.8364 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 8/600\n",
            "1333/1333 - 11s - loss: 0.3237 - accuracy: 0.8354 - val_loss: 0.3038 - val_accuracy: 0.8388 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 9/600\n",
            "1333/1333 - 11s - loss: 0.4696 - accuracy: 0.8270 - val_loss: 0.4693 - val_accuracy: 0.8404 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 10/600\n",
            "1333/1333 - 11s - loss: 0.3418 - accuracy: 0.8357 - val_loss: 0.3109 - val_accuracy: 0.8397 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 11/600\n",
            "1333/1333 - 11s - loss: 0.3771 - accuracy: 0.8317 - val_loss: 0.3158 - val_accuracy: 0.8390 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 12/600\n",
            "1333/1333 - 11s - loss: 0.2989 - accuracy: 0.8364 - val_loss: 0.2914 - val_accuracy: 0.8377 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 13/600\n",
            "1333/1333 - 11s - loss: 0.3238 - accuracy: 0.8335 - val_loss: 0.2885 - val_accuracy: 0.8375 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 14/600\n",
            "1333/1333 - 11s - loss: 0.2910 - accuracy: 0.8369 - val_loss: 0.2827 - val_accuracy: 0.8370 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 15/600\n",
            "1333/1333 - 11s - loss: 0.3112 - accuracy: 0.8348 - val_loss: 0.2821 - val_accuracy: 0.8395 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 16/600\n",
            "1333/1333 - 11s - loss: 0.3025 - accuracy: 0.8362 - val_loss: 0.3615 - val_accuracy: 0.8381 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 17/600\n",
            "1333/1333 - 11s - loss: 0.2969 - accuracy: 0.8369 - val_loss: 0.2857 - val_accuracy: 0.8382 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 18/600\n",
            "1333/1333 - 11s - loss: 0.3068 - accuracy: 0.8358 - val_loss: 0.3755 - val_accuracy: 0.8382 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 19/600\n",
            "1333/1333 - 11s - loss: 0.2947 - accuracy: 0.8381 - val_loss: 0.2726 - val_accuracy: 0.8374 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 20/600\n",
            "1333/1333 - 12s - loss: 0.2740 - accuracy: 0.8381 - val_loss: 0.2722 - val_accuracy: 0.8383 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 21/600\n",
            "1333/1333 - 11s - loss: 0.2724 - accuracy: 0.8384 - val_loss: 0.2679 - val_accuracy: 0.8397 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 22/600\n",
            "1333/1333 - 11s - loss: 0.2780 - accuracy: 0.8379 - val_loss: 0.2661 - val_accuracy: 0.8415 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 23/600\n",
            "1333/1333 - 11s - loss: 0.2704 - accuracy: 0.8389 - val_loss: 0.2667 - val_accuracy: 0.8363 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 24/600\n",
            "1333/1333 - 12s - loss: 0.2816 - accuracy: 0.8374 - val_loss: 0.2667 - val_accuracy: 0.8370 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 25/600\n",
            "1333/1333 - 11s - loss: 0.2688 - accuracy: 0.8372 - val_loss: 0.2687 - val_accuracy: 0.8414 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 26/600\n",
            "1333/1333 - 11s - loss: 0.2636 - accuracy: 0.8399 - val_loss: 0.2616 - val_accuracy: 0.8401 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 27/600\n",
            "1333/1333 - 11s - loss: 0.2627 - accuracy: 0.8396 - val_loss: 0.2605 - val_accuracy: 0.8417 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 28/600\n",
            "1333/1333 - 11s - loss: 0.2626 - accuracy: 0.8389 - val_loss: 0.2592 - val_accuracy: 0.8394 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 29/600\n",
            "1333/1333 - 11s - loss: 0.2636 - accuracy: 0.8388 - val_loss: 0.2587 - val_accuracy: 0.8400 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 30/600\n",
            "1333/1333 - 11s - loss: 0.2639 - accuracy: 0.8377 - val_loss: 0.2581 - val_accuracy: 0.8407 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 31/600\n",
            "1333/1333 - 11s - loss: 0.2612 - accuracy: 0.8387 - val_loss: 0.2586 - val_accuracy: 0.8405 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 32/600\n",
            "1333/1333 - 11s - loss: 0.2610 - accuracy: 0.8395 - val_loss: 0.2602 - val_accuracy: 0.8412 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 33/600\n",
            "1333/1333 - 11s - loss: 0.2617 - accuracy: 0.8393 - val_loss: 0.2595 - val_accuracy: 0.8423 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 34/600\n",
            "1333/1333 - 11s - loss: 0.2573 - accuracy: 0.8395 - val_loss: 0.2548 - val_accuracy: 0.8417 - lr: 3.1250e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 35/600\n",
            "1333/1333 - 11s - loss: 0.2571 - accuracy: 0.8395 - val_loss: 0.2543 - val_accuracy: 0.8422 - lr: 3.1250e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 36/600\n",
            "1333/1333 - 11s - loss: 0.2569 - accuracy: 0.8397 - val_loss: 0.2542 - val_accuracy: 0.8427 - lr: 3.1250e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 37/600\n",
            "1333/1333 - 11s - loss: 0.2568 - accuracy: 0.8398 - val_loss: 0.2547 - val_accuracy: 0.8399 - lr: 3.1250e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 38/600\n",
            "1333/1333 - 11s - loss: 0.2567 - accuracy: 0.8390 - val_loss: 0.2541 - val_accuracy: 0.8411 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 39/600\n",
            "1333/1333 - 11s - loss: 0.2562 - accuracy: 0.8389 - val_loss: 0.2544 - val_accuracy: 0.8401 - lr: 3.1250e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 40/600\n",
            "1333/1333 - 11s - loss: 0.2565 - accuracy: 0.8394 - val_loss: 0.2541 - val_accuracy: 0.8408 - lr: 3.1250e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 41/600\n",
            "1333/1333 - 11s - loss: 0.2561 - accuracy: 0.8389 - val_loss: 0.2541 - val_accuracy: 0.8380 - lr: 3.1250e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 42/600\n",
            "1333/1333 - 11s - loss: 0.2542 - accuracy: 0.8393 - val_loss: 0.2532 - val_accuracy: 0.8396 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 43/600\n",
            "1333/1333 - 11s - loss: 0.2542 - accuracy: 0.8389 - val_loss: 0.2521 - val_accuracy: 0.8400 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 44/600\n",
            "1333/1333 - 11s - loss: 0.2539 - accuracy: 0.8389 - val_loss: 0.2525 - val_accuracy: 0.8418 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 45/600\n",
            "1333/1333 - 11s - loss: 0.2540 - accuracy: 0.8397 - val_loss: 0.2517 - val_accuracy: 0.8395 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 46/600\n",
            "1333/1333 - 11s - loss: 0.2538 - accuracy: 0.8398 - val_loss: 0.2516 - val_accuracy: 0.8395 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 47/600\n",
            "1333/1333 - 11s - loss: 0.2539 - accuracy: 0.8388 - val_loss: 0.2517 - val_accuracy: 0.8410 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 48/600\n",
            "1333/1333 - 11s - loss: 0.2537 - accuracy: 0.8394 - val_loss: 0.2527 - val_accuracy: 0.8399 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 49/600\n",
            "1333/1333 - 11s - loss: 0.2527 - accuracy: 0.8400 - val_loss: 0.2509 - val_accuracy: 0.8410 - lr: 7.8125e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 50/600\n",
            "1333/1333 - 11s - loss: 0.2526 - accuracy: 0.8397 - val_loss: 0.2509 - val_accuracy: 0.8417 - lr: 7.8125e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 51/600\n",
            "1333/1333 - 11s - loss: 0.2525 - accuracy: 0.8400 - val_loss: 0.2507 - val_accuracy: 0.8409 - lr: 7.8125e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 52/600\n",
            "1333/1333 - 12s - loss: 0.2525 - accuracy: 0.8395 - val_loss: 0.2505 - val_accuracy: 0.8422 - lr: 7.8125e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 53/600\n",
            "1333/1333 - 11s - loss: 0.2525 - accuracy: 0.8395 - val_loss: 0.2508 - val_accuracy: 0.8406 - lr: 7.8125e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 54/600\n",
            "1333/1333 - 11s - loss: 0.2523 - accuracy: 0.8390 - val_loss: 0.2504 - val_accuracy: 0.8404 - lr: 7.8125e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 55/600\n",
            "1333/1333 - 11s - loss: 0.2521 - accuracy: 0.8409 - val_loss: 0.2508 - val_accuracy: 0.8409 - lr: 7.8125e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 56/600\n",
            "1333/1333 - 11s - loss: 0.2517 - accuracy: 0.8401 - val_loss: 0.2499 - val_accuracy: 0.8413 - lr: 3.9062e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 57/600\n",
            "1333/1333 - 11s - loss: 0.2516 - accuracy: 0.8400 - val_loss: 0.2500 - val_accuracy: 0.8419 - lr: 3.9062e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 58/600\n",
            "1333/1333 - 11s - loss: 0.2516 - accuracy: 0.8409 - val_loss: 0.2498 - val_accuracy: 0.8424 - lr: 3.9062e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 59/600\n",
            "1333/1333 - 11s - loss: 0.2516 - accuracy: 0.8401 - val_loss: 0.2498 - val_accuracy: 0.8416 - lr: 3.9062e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 60/600\n",
            "1333/1333 - 11s - loss: 0.2517 - accuracy: 0.8402 - val_loss: 0.2499 - val_accuracy: 0.8420 - lr: 3.9062e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 61/600\n",
            "1333/1333 - 11s - loss: 0.2515 - accuracy: 0.8400 - val_loss: 0.2497 - val_accuracy: 0.8411 - lr: 3.9062e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 62/600\n",
            "1333/1333 - 11s - loss: 0.2512 - accuracy: 0.8394 - val_loss: 0.2496 - val_accuracy: 0.8417 - lr: 1.9531e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 63/600\n",
            "1333/1333 - 11s - loss: 0.2512 - accuracy: 0.8405 - val_loss: 0.2496 - val_accuracy: 0.8407 - lr: 1.9531e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 64/600\n",
            "1333/1333 - 11s - loss: 0.2511 - accuracy: 0.8412 - val_loss: 0.2497 - val_accuracy: 0.8417 - lr: 1.9531e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 65/600\n",
            "1333/1333 - 11s - loss: 0.2511 - accuracy: 0.8405 - val_loss: 0.2495 - val_accuracy: 0.8417 - lr: 1.9531e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 66/600\n",
            "1333/1333 - 11s - loss: 0.2510 - accuracy: 0.8403 - val_loss: 0.2494 - val_accuracy: 0.8413 - lr: 9.7656e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 67/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8412 - val_loss: 0.2494 - val_accuracy: 0.8404 - lr: 9.7656e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 68/600\n",
            "1333/1333 - 11s - loss: 0.2509 - accuracy: 0.8405 - val_loss: 0.2494 - val_accuracy: 0.8418 - lr: 9.7656e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 69/600\n",
            "1333/1333 - 11s - loss: 0.2510 - accuracy: 0.8401 - val_loss: 0.2494 - val_accuracy: 0.8411 - lr: 9.7656e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 70/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8408 - val_loss: 0.2493 - val_accuracy: 0.8419 - lr: 4.8828e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 71/600\n",
            "1333/1333 - 11s - loss: 0.2510 - accuracy: 0.8408 - val_loss: 0.2493 - val_accuracy: 0.8408 - lr: 4.8828e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 72/600\n",
            "1333/1333 - 11s - loss: 0.2509 - accuracy: 0.8405 - val_loss: 0.2493 - val_accuracy: 0.8408 - lr: 4.8828e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 73/600\n",
            "1333/1333 - 11s - loss: 0.2509 - accuracy: 0.8395 - val_loss: 0.2493 - val_accuracy: 0.8405 - lr: 4.8828e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 74/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8408 - val_loss: 0.2493 - val_accuracy: 0.8406 - lr: 2.4414e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 75/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8398 - val_loss: 0.2493 - val_accuracy: 0.8404 - lr: 2.4414e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 76/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8413 - val_loss: 0.2493 - val_accuracy: 0.8406 - lr: 2.4414e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 77/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8406 - val_loss: 0.2493 - val_accuracy: 0.8407 - lr: 1.2207e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 78/600\n",
            "1333/1333 - 11s - loss: 0.2507 - accuracy: 0.8414 - val_loss: 0.2493 - val_accuracy: 0.8407 - lr: 1.2207e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 79/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8406 - val_loss: 0.2493 - val_accuracy: 0.8407 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 80/600\n",
            "1333/1333 - 11s - loss: 0.2507 - accuracy: 0.8412 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 6.1035e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 81/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8404 - val_loss: 0.2492 - val_accuracy: 0.8406 - lr: 6.1035e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 82/600\n",
            "1333/1333 - 11s - loss: 0.2509 - accuracy: 0.8401 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 6.1035e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 83/600\n",
            "1333/1333 - 11s - loss: 0.2509 - accuracy: 0.8397 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 3.0518e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 84/600\n",
            "1333/1333 - 11s - loss: 0.2507 - accuracy: 0.8400 - val_loss: 0.2492 - val_accuracy: 0.8406 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 85/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8403 - val_loss: 0.2492 - val_accuracy: 0.8406 - lr: 3.0518e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 86/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8409 - val_loss: 0.2492 - val_accuracy: 0.8406 - lr: 1.5259e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 87/600\n",
            "1333/1333 - 11s - loss: 0.2507 - accuracy: 0.8405 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 1.5259e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 88/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8396 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 1.5259e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 89/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8397 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 7.6294e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 90/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8403 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 7.6294e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 91/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8410 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 7.6294e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 92/600\n",
            "1333/1333 - 11s - loss: 0.2509 - accuracy: 0.8406 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 93/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8400 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 94/600\n",
            "1333/1333 - 11s - loss: 0.2506 - accuracy: 0.8405 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 3.8147e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 95/600\n",
            "1333/1333 - 11s - loss: 0.2508 - accuracy: 0.8414 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 1.9073e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 96/600\n",
            "1333/1333 - 12s - loss: 0.2509 - accuracy: 0.8398 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 1.9073e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 97/600\n",
            "1333/1333 - 11s - loss: 0.2507 - accuracy: 0.8408 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 1.9073e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 98/600\n",
            "1333/1333 - 12s - loss: 0.2508 - accuracy: 0.8406 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 9.5367e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 99/600\n",
            "1333/1333 - 11s - loss: 0.2507 - accuracy: 0.8406 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 9.5367e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 100/600\n",
            "1333/1333 - 11s - loss: 0.2507 - accuracy: 0.8411 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 9.5367e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 101/600\n",
            "1333/1333 - 12s - loss: 0.2508 - accuracy: 0.8405 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 4.7684e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 102/600\n",
            "1333/1333 - 12s - loss: 0.2506 - accuracy: 0.8415 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 4.7684e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 103/600\n",
            "1333/1333 - 12s - loss: 0.2508 - accuracy: 0.8398 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 4.7684e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 104/600\n",
            "1333/1333 - 11s - loss: 0.2507 - accuracy: 0.8416 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 2.3842e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 105/600\n",
            "1333/1333 - 11s - loss: 0.2507 - accuracy: 0.8409 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 2.3842e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 106/600\n",
            "1333/1333 - 11s - loss: 0.2507 - accuracy: 0.8411 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 2.3842e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 107/600\n",
            "1333/1333 - 12s - loss: 0.2509 - accuracy: 0.8399 - val_loss: 0.2492 - val_accuracy: 0.8407 - lr: 1.1921e-09 - 12s/epoch - 9ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " ...\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " ...\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12 14]\n",
            " ...\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ... 14 11 24]\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ... 14 11 20]\n",
            " ...\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ... 14 11 24]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 20 25 15]\n",
            " ...\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 24 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 23]\n",
            " ...\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ... 15 18 23]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 23 17  9]\n",
            " ...\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 23 17  9]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " ...\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ... 22  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " ...\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " ...\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " ...\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_5 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1342/1342 - 16s - loss: 0.8037 - accuracy: 0.7798 - val_loss: 0.4005 - val_accuracy: 0.8284 - lr: 0.0050 - 16s/epoch - 12ms/step\n",
            "Epoch 2/600\n",
            "1342/1342 - 12s - loss: 0.4333 - accuracy: 0.8272 - val_loss: 0.3812 - val_accuracy: 0.8331 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 3/600\n",
            "1342/1342 - 12s - loss: 0.5343 - accuracy: 0.8187 - val_loss: 0.3883 - val_accuracy: 0.8362 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 4/600\n",
            "1342/1342 - 13s - loss: 0.4053 - accuracy: 0.8307 - val_loss: 0.3344 - val_accuracy: 0.8356 - lr: 0.0050 - 13s/epoch - 9ms/step\n",
            "Epoch 5/600\n",
            "1342/1342 - 12s - loss: 0.7108 - accuracy: 0.8182 - val_loss: 0.4991 - val_accuracy: 0.8339 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 6/600\n",
            "1342/1342 - 11s - loss: 0.4070 - accuracy: 0.8326 - val_loss: 0.3560 - val_accuracy: 0.8375 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 7/600\n",
            "1342/1342 - 13s - loss: 0.3696 - accuracy: 0.8303 - val_loss: 0.3572 - val_accuracy: 0.8363 - lr: 0.0050 - 13s/epoch - 9ms/step\n",
            "Epoch 8/600\n",
            "1342/1342 - 12s - loss: 0.3139 - accuracy: 0.8357 - val_loss: 0.3005 - val_accuracy: 0.8383 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 9/600\n",
            "1342/1342 - 12s - loss: 0.3264 - accuracy: 0.8343 - val_loss: 0.2989 - val_accuracy: 0.8360 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 10/600\n",
            "1342/1342 - 13s - loss: 0.3222 - accuracy: 0.8346 - val_loss: 0.3007 - val_accuracy: 0.8388 - lr: 0.0025 - 13s/epoch - 9ms/step\n",
            "Epoch 11/600\n",
            "1342/1342 - 11s - loss: 0.3066 - accuracy: 0.8345 - val_loss: 0.2968 - val_accuracy: 0.8331 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 12/600\n",
            "1342/1342 - 11s - loss: 0.3538 - accuracy: 0.8319 - val_loss: 0.3666 - val_accuracy: 0.8358 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 13/600\n",
            "1342/1342 - 12s - loss: 0.3460 - accuracy: 0.8344 - val_loss: 0.3101 - val_accuracy: 0.8367 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 14/600\n",
            "1342/1342 - 12s - loss: 0.3339 - accuracy: 0.8350 - val_loss: 0.3002 - val_accuracy: 0.8378 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 15/600\n",
            "1342/1342 - 12s - loss: 0.2969 - accuracy: 0.8369 - val_loss: 0.2893 - val_accuracy: 0.8380 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 16/600\n",
            "1342/1342 - 12s - loss: 0.2935 - accuracy: 0.8364 - val_loss: 0.2875 - val_accuracy: 0.8364 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 17/600\n",
            "1342/1342 - 12s - loss: 0.2930 - accuracy: 0.8362 - val_loss: 0.3050 - val_accuracy: 0.8369 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 18/600\n",
            "1342/1342 - 12s - loss: 0.2878 - accuracy: 0.8370 - val_loss: 0.2815 - val_accuracy: 0.8369 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 19/600\n",
            "1342/1342 - 12s - loss: 0.2854 - accuracy: 0.8365 - val_loss: 0.2789 - val_accuracy: 0.8372 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 20/600\n",
            "1342/1342 - 12s - loss: 0.2851 - accuracy: 0.8364 - val_loss: 0.2773 - val_accuracy: 0.8378 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 21/600\n",
            "1342/1342 - 12s - loss: 0.2824 - accuracy: 0.8369 - val_loss: 0.2756 - val_accuracy: 0.8387 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 22/600\n",
            "1342/1342 - 12s - loss: 0.2888 - accuracy: 0.8370 - val_loss: 0.2779 - val_accuracy: 0.8386 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 23/600\n",
            "1342/1342 - 12s - loss: 0.2796 - accuracy: 0.8369 - val_loss: 0.2756 - val_accuracy: 0.8378 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 24/600\n",
            "1342/1342 - 11s - loss: 0.2836 - accuracy: 0.8365 - val_loss: 0.2747 - val_accuracy: 0.8371 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 25/600\n",
            "1342/1342 - 12s - loss: 0.2776 - accuracy: 0.8377 - val_loss: 0.2730 - val_accuracy: 0.8378 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 26/600\n",
            "1342/1342 - 11s - loss: 0.2969 - accuracy: 0.8367 - val_loss: 0.2716 - val_accuracy: 0.8381 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 27/600\n",
            "1342/1342 - 12s - loss: 0.2755 - accuracy: 0.8384 - val_loss: 0.2702 - val_accuracy: 0.8386 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 28/600\n",
            "1342/1342 - 12s - loss: 0.2928 - accuracy: 0.8369 - val_loss: 0.2790 - val_accuracy: 0.8380 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 29/600\n",
            "1342/1342 - 12s - loss: 0.2751 - accuracy: 0.8369 - val_loss: 0.2702 - val_accuracy: 0.8383 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 30/600\n",
            "1342/1342 - 12s - loss: 0.2736 - accuracy: 0.8380 - val_loss: 0.2708 - val_accuracy: 0.8371 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 31/600\n",
            "1342/1342 - 12s - loss: 0.2701 - accuracy: 0.8386 - val_loss: 0.2647 - val_accuracy: 0.8410 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 32/600\n",
            "1342/1342 - 12s - loss: 0.2685 - accuracy: 0.8384 - val_loss: 0.2652 - val_accuracy: 0.8395 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 33/600\n",
            "1342/1342 - 12s - loss: 0.2733 - accuracy: 0.8384 - val_loss: 0.2796 - val_accuracy: 0.8380 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 34/600\n",
            "1342/1342 - 12s - loss: 0.2688 - accuracy: 0.8377 - val_loss: 0.2641 - val_accuracy: 0.8395 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 35/600\n",
            "1342/1342 - 12s - loss: 0.2674 - accuracy: 0.8387 - val_loss: 0.2647 - val_accuracy: 0.8397 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 36/600\n",
            "1342/1342 - 12s - loss: 0.2676 - accuracy: 0.8387 - val_loss: 0.2646 - val_accuracy: 0.8380 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 37/600\n",
            "1342/1342 - 11s - loss: 0.2749 - accuracy: 0.8379 - val_loss: 0.2702 - val_accuracy: 0.8379 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 38/600\n",
            "1342/1342 - 12s - loss: 0.2660 - accuracy: 0.8394 - val_loss: 0.2615 - val_accuracy: 0.8377 - lr: 3.1250e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 39/600\n",
            "1342/1342 - 12s - loss: 0.2645 - accuracy: 0.8379 - val_loss: 0.2618 - val_accuracy: 0.8383 - lr: 3.1250e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 40/600\n",
            "1342/1342 - 11s - loss: 0.2640 - accuracy: 0.8383 - val_loss: 0.2606 - val_accuracy: 0.8391 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 41/600\n",
            "1342/1342 - 12s - loss: 0.2640 - accuracy: 0.8386 - val_loss: 0.2605 - val_accuracy: 0.8380 - lr: 3.1250e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 42/600\n",
            "1342/1342 - 11s - loss: 0.2641 - accuracy: 0.8389 - val_loss: 0.2609 - val_accuracy: 0.8405 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 43/600\n",
            "1342/1342 - 12s - loss: 0.2638 - accuracy: 0.8383 - val_loss: 0.2607 - val_accuracy: 0.8378 - lr: 3.1250e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 44/600\n",
            "1342/1342 - 11s - loss: 0.2618 - accuracy: 0.8391 - val_loss: 0.2590 - val_accuracy: 0.8392 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 45/600\n",
            "1342/1342 - 12s - loss: 0.2619 - accuracy: 0.8392 - val_loss: 0.2590 - val_accuracy: 0.8387 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 46/600\n",
            "1342/1342 - 12s - loss: 0.2616 - accuracy: 0.8400 - val_loss: 0.2586 - val_accuracy: 0.8394 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 47/600\n",
            "1342/1342 - 12s - loss: 0.2617 - accuracy: 0.8385 - val_loss: 0.2585 - val_accuracy: 0.8396 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 48/600\n",
            "1342/1342 - 12s - loss: 0.2615 - accuracy: 0.8387 - val_loss: 0.2585 - val_accuracy: 0.8376 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 49/600\n",
            "1342/1342 - 11s - loss: 0.2615 - accuracy: 0.8393 - val_loss: 0.2585 - val_accuracy: 0.8393 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 50/600\n",
            "1342/1342 - 12s - loss: 0.2613 - accuracy: 0.8388 - val_loss: 0.2585 - val_accuracy: 0.8401 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 51/600\n",
            "1342/1342 - 12s - loss: 0.2606 - accuracy: 0.8381 - val_loss: 0.2576 - val_accuracy: 0.8377 - lr: 7.8125e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 52/600\n",
            "1342/1342 - 12s - loss: 0.2604 - accuracy: 0.8398 - val_loss: 0.2578 - val_accuracy: 0.8385 - lr: 7.8125e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 53/600\n",
            "1342/1342 - 12s - loss: 0.2604 - accuracy: 0.8397 - val_loss: 0.2577 - val_accuracy: 0.8378 - lr: 7.8125e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 54/600\n",
            "1342/1342 - 12s - loss: 0.2603 - accuracy: 0.8384 - val_loss: 0.2575 - val_accuracy: 0.8383 - lr: 7.8125e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 55/600\n",
            "1342/1342 - 11s - loss: 0.2599 - accuracy: 0.8390 - val_loss: 0.2572 - val_accuracy: 0.8376 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 56/600\n",
            "1342/1342 - 12s - loss: 0.2599 - accuracy: 0.8393 - val_loss: 0.2572 - val_accuracy: 0.8370 - lr: 3.9062e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 57/600\n",
            "1342/1342 - 11s - loss: 0.2598 - accuracy: 0.8389 - val_loss: 0.2573 - val_accuracy: 0.8386 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 58/600\n",
            "1342/1342 - 12s - loss: 0.2597 - accuracy: 0.8393 - val_loss: 0.2571 - val_accuracy: 0.8389 - lr: 3.9062e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 59/600\n",
            "1342/1342 - 12s - loss: 0.2596 - accuracy: 0.8388 - val_loss: 0.2569 - val_accuracy: 0.8377 - lr: 1.9531e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 60/600\n",
            "1342/1342 - 12s - loss: 0.2595 - accuracy: 0.8387 - val_loss: 0.2570 - val_accuracy: 0.8379 - lr: 1.9531e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 61/600\n",
            "1342/1342 - 11s - loss: 0.2595 - accuracy: 0.8395 - val_loss: 0.2569 - val_accuracy: 0.8368 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 62/600\n",
            "1342/1342 - 12s - loss: 0.2596 - accuracy: 0.8391 - val_loss: 0.2569 - val_accuracy: 0.8377 - lr: 1.9531e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 63/600\n",
            "1342/1342 - 12s - loss: 0.2594 - accuracy: 0.8400 - val_loss: 0.2568 - val_accuracy: 0.8376 - lr: 9.7656e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 64/600\n",
            "1342/1342 - 12s - loss: 0.2593 - accuracy: 0.8398 - val_loss: 0.2568 - val_accuracy: 0.8374 - lr: 9.7656e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 65/600\n",
            "1342/1342 - 12s - loss: 0.2595 - accuracy: 0.8396 - val_loss: 0.2568 - val_accuracy: 0.8369 - lr: 9.7656e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 66/600\n",
            "1342/1342 - 12s - loss: 0.2593 - accuracy: 0.8393 - val_loss: 0.2568 - val_accuracy: 0.8372 - lr: 9.7656e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 67/600\n",
            "1342/1342 - 13s - loss: 0.2594 - accuracy: 0.8391 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 4.8828e-06 - 13s/epoch - 9ms/step\n",
            "Epoch 68/600\n",
            "1342/1342 - 13s - loss: 0.2592 - accuracy: 0.8389 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 4.8828e-06 - 13s/epoch - 9ms/step\n",
            "Epoch 69/600\n",
            "1342/1342 - 11s - loss: 0.2593 - accuracy: 0.8392 - val_loss: 0.2567 - val_accuracy: 0.8371 - lr: 4.8828e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 70/600\n",
            "1342/1342 - 11s - loss: 0.2593 - accuracy: 0.8395 - val_loss: 0.2567 - val_accuracy: 0.8371 - lr: 2.4414e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 71/600\n",
            "1342/1342 - 13s - loss: 0.2593 - accuracy: 0.8399 - val_loss: 0.2567 - val_accuracy: 0.8369 - lr: 2.4414e-06 - 13s/epoch - 9ms/step\n",
            "Epoch 72/600\n",
            "1342/1342 - 12s - loss: 0.2593 - accuracy: 0.8398 - val_loss: 0.2567 - val_accuracy: 0.8370 - lr: 2.4414e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 73/600\n",
            "1342/1342 - 11s - loss: 0.2592 - accuracy: 0.8403 - val_loss: 0.2567 - val_accuracy: 0.8373 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 74/600\n",
            "1342/1342 - 12s - loss: 0.2593 - accuracy: 0.8394 - val_loss: 0.2567 - val_accuracy: 0.8371 - lr: 1.2207e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 75/600\n",
            "1342/1342 - 12s - loss: 0.2592 - accuracy: 0.8394 - val_loss: 0.2567 - val_accuracy: 0.8371 - lr: 1.2207e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 76/600\n",
            "1342/1342 - 12s - loss: 0.2593 - accuracy: 0.8392 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 1.2207e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 77/600\n",
            "1342/1342 - 13s - loss: 0.2593 - accuracy: 0.8387 - val_loss: 0.2567 - val_accuracy: 0.8371 - lr: 6.1035e-07 - 13s/epoch - 9ms/step\n",
            "Epoch 78/600\n",
            "1342/1342 - 12s - loss: 0.2593 - accuracy: 0.8391 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 6.1035e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 79/600\n",
            "1342/1342 - 12s - loss: 0.2592 - accuracy: 0.8401 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 6.1035e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 80/600\n",
            "1342/1342 - 11s - loss: 0.2593 - accuracy: 0.8403 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 3.0518e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 81/600\n",
            "1342/1342 - 11s - loss: 0.2593 - accuracy: 0.8394 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 82/600\n",
            "1342/1342 - 11s - loss: 0.2593 - accuracy: 0.8397 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 83/600\n",
            "1342/1342 - 11s - loss: 0.2594 - accuracy: 0.8389 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 84/600\n",
            "1342/1342 - 11s - loss: 0.2594 - accuracy: 0.8391 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 85/600\n",
            "1342/1342 - 11s - loss: 0.2592 - accuracy: 0.8406 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 86/600\n",
            "1342/1342 - 11s - loss: 0.2591 - accuracy: 0.8403 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 7.6294e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 87/600\n",
            "1342/1342 - 12s - loss: 0.2593 - accuracy: 0.8389 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 7.6294e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 88/600\n",
            "1342/1342 - 12s - loss: 0.2591 - accuracy: 0.8397 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 7.6294e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 89/600\n",
            "1342/1342 - 11s - loss: 0.2591 - accuracy: 0.8396 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 90/600\n",
            "1342/1342 - 12s - loss: 0.2592 - accuracy: 0.8394 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 3.8147e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 91/600\n",
            "1342/1342 - 11s - loss: 0.2592 - accuracy: 0.8398 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 92/600\n",
            "1342/1342 - 12s - loss: 0.2592 - accuracy: 0.8391 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 1.9073e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 93/600\n",
            "1342/1342 - 12s - loss: 0.2591 - accuracy: 0.8394 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 1.9073e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 94/600\n",
            "1342/1342 - 11s - loss: 0.2591 - accuracy: 0.8407 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 1.9073e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 95/600\n",
            "1342/1342 - 12s - loss: 0.2591 - accuracy: 0.8387 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 9.5367e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 96/600\n",
            "1342/1342 - 11s - loss: 0.2593 - accuracy: 0.8385 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 9.5367e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 97/600\n",
            "1342/1342 - 12s - loss: 0.2592 - accuracy: 0.8399 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 9.5367e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 98/600\n",
            "1342/1342 - 12s - loss: 0.2593 - accuracy: 0.8393 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 4.7684e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 99/600\n",
            "1342/1342 - 12s - loss: 0.2593 - accuracy: 0.8386 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 4.7684e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 100/600\n",
            "1342/1342 - 12s - loss: 0.2594 - accuracy: 0.8396 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 4.7684e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 101/600\n",
            "1342/1342 - 12s - loss: 0.2591 - accuracy: 0.8401 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 2.3842e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 102/600\n",
            "1342/1342 - 12s - loss: 0.2593 - accuracy: 0.8394 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 2.3842e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 103/600\n",
            "1342/1342 - 12s - loss: 0.2592 - accuracy: 0.8398 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 2.3842e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 104/600\n",
            "1342/1342 - 13s - loss: 0.2592 - accuracy: 0.8392 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 1.1921e-09 - 13s/epoch - 9ms/step\n",
            "Epoch 105/600\n",
            "1342/1342 - 12s - loss: 0.2592 - accuracy: 0.8398 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 1.1921e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 106/600\n",
            "1342/1342 - 12s - loss: 0.2593 - accuracy: 0.8388 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 1.1921e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 107/600\n",
            "1342/1342 - 12s - loss: 0.2593 - accuracy: 0.8397 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 5.9605e-10 - 12s/epoch - 9ms/step\n",
            "Epoch 108/600\n",
            "1342/1342 - 11s - loss: 0.2593 - accuracy: 0.8399 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 5.9605e-10 - 11s/epoch - 9ms/step\n",
            "Epoch 109/600\n",
            "1342/1342 - 12s - loss: 0.2591 - accuracy: 0.8410 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 5.9605e-10 - 12s/epoch - 9ms/step\n",
            "Epoch 110/600\n",
            "1342/1342 - 11s - loss: 0.2593 - accuracy: 0.8398 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 2.9802e-10 - 11s/epoch - 9ms/step\n",
            "Epoch 111/600\n",
            "1342/1342 - 11s - loss: 0.2592 - accuracy: 0.8397 - val_loss: 0.2567 - val_accuracy: 0.8372 - lr: 2.9802e-10 - 11s/epoch - 9ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " ...\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " ...\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ... 26 12  2]\n",
            " ...\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ... 26 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 24]\n",
            " ...\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ... 14 11 24]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25 15]\n",
            " ...\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 23]\n",
            " ...\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 23]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 23 17  9]\n",
            " ...\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 23 17  9]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " ...\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  9 21  4]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  5]\n",
            " ...\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ...  4  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " ...\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " ...\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_6 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1329/1329 - 16s - loss: 0.6568 - accuracy: 0.7910 - val_loss: 0.3477 - val_accuracy: 0.8202 - lr: 0.0050 - 16s/epoch - 12ms/step\n",
            "Epoch 2/600\n",
            "1329/1329 - 11s - loss: 0.5283 - accuracy: 0.8185 - val_loss: 0.3447 - val_accuracy: 0.8348 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 3/600\n",
            "1329/1329 - 11s - loss: 0.4534 - accuracy: 0.8216 - val_loss: 0.9524 - val_accuracy: 0.8297 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 4/600\n",
            "1329/1329 - 11s - loss: 0.4778 - accuracy: 0.8239 - val_loss: 0.3535 - val_accuracy: 0.8297 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 5/600\n",
            "1329/1329 - 12s - loss: 0.3446 - accuracy: 0.8312 - val_loss: 0.3194 - val_accuracy: 0.8346 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 6/600\n",
            "1329/1329 - 12s - loss: 0.5529 - accuracy: 0.8186 - val_loss: 0.3707 - val_accuracy: 0.8300 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 7/600\n",
            "1329/1329 - 11s - loss: 0.5390 - accuracy: 0.8179 - val_loss: 0.4321 - val_accuracy: 0.8306 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 8/600\n",
            "1329/1329 - 11s - loss: 0.3835 - accuracy: 0.8285 - val_loss: 0.3358 - val_accuracy: 0.8298 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 9/600\n",
            "1329/1329 - 11s - loss: 0.3200 - accuracy: 0.8296 - val_loss: 0.3103 - val_accuracy: 0.8283 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 10/600\n",
            "1329/1329 - 11s - loss: 0.3245 - accuracy: 0.8288 - val_loss: 0.3173 - val_accuracy: 0.8306 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 11/600\n",
            "1329/1329 - 12s - loss: 0.2998 - accuracy: 0.8293 - val_loss: 0.2922 - val_accuracy: 0.8298 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 12/600\n",
            "1329/1329 - 11s - loss: 0.3343 - accuracy: 0.8296 - val_loss: 0.2919 - val_accuracy: 0.8350 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 13/600\n",
            "1329/1329 - 11s - loss: 0.3275 - accuracy: 0.8302 - val_loss: 0.2994 - val_accuracy: 0.8319 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 14/600\n",
            "1329/1329 - 11s - loss: 0.3105 - accuracy: 0.8308 - val_loss: 0.3591 - val_accuracy: 0.8293 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 15/600\n",
            "1329/1329 - 11s - loss: 0.2969 - accuracy: 0.8300 - val_loss: 0.2840 - val_accuracy: 0.8300 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 16/600\n",
            "1329/1329 - 11s - loss: 0.3104 - accuracy: 0.8278 - val_loss: 0.2852 - val_accuracy: 0.8313 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 17/600\n",
            "1329/1329 - 11s - loss: 0.3056 - accuracy: 0.8280 - val_loss: 0.2870 - val_accuracy: 0.8289 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 18/600\n",
            "1329/1329 - 12s - loss: 0.2870 - accuracy: 0.8296 - val_loss: 0.2818 - val_accuracy: 0.8306 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 19/600\n",
            "1329/1329 - 12s - loss: 0.3605 - accuracy: 0.8257 - val_loss: 0.3564 - val_accuracy: 0.8315 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 20/600\n",
            "1329/1329 - 12s - loss: 0.3211 - accuracy: 0.8296 - val_loss: 0.2921 - val_accuracy: 0.8344 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 21/600\n",
            "1329/1329 - 11s - loss: 0.2896 - accuracy: 0.8319 - val_loss: 0.2828 - val_accuracy: 0.8353 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 22/600\n",
            "1329/1329 - 11s - loss: 0.2807 - accuracy: 0.8338 - val_loss: 0.2741 - val_accuracy: 0.8295 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 23/600\n",
            "1329/1329 - 12s - loss: 0.2746 - accuracy: 0.8305 - val_loss: 0.2713 - val_accuracy: 0.8306 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 24/600\n",
            "1329/1329 - 11s - loss: 0.2733 - accuracy: 0.8304 - val_loss: 0.2702 - val_accuracy: 0.8350 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 25/600\n",
            "1329/1329 - 12s - loss: 0.2877 - accuracy: 0.8288 - val_loss: 0.2702 - val_accuracy: 0.8295 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 26/600\n",
            "1329/1329 - 12s - loss: 0.2718 - accuracy: 0.8306 - val_loss: 0.2686 - val_accuracy: 0.8296 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 27/600\n",
            "1329/1329 - 11s - loss: 0.2714 - accuracy: 0.8297 - val_loss: 0.2689 - val_accuracy: 0.8305 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 28/600\n",
            "1329/1329 - 11s - loss: 0.2983 - accuracy: 0.8279 - val_loss: 0.2703 - val_accuracy: 0.8304 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 29/600\n",
            "1329/1329 - 12s - loss: 0.2709 - accuracy: 0.8324 - val_loss: 0.2681 - val_accuracy: 0.8340 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 30/600\n",
            "1329/1329 - 12s - loss: 0.2886 - accuracy: 0.8315 - val_loss: 0.2734 - val_accuracy: 0.8291 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 31/600\n",
            "1329/1329 - 11s - loss: 0.2709 - accuracy: 0.8349 - val_loss: 0.2684 - val_accuracy: 0.8316 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 32/600\n",
            "1329/1329 - 12s - loss: 0.2733 - accuracy: 0.8347 - val_loss: 0.2674 - val_accuracy: 0.8356 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 33/600\n",
            "1329/1329 - 12s - loss: 0.2995 - accuracy: 0.8310 - val_loss: 0.2685 - val_accuracy: 0.8318 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 34/600\n",
            "1329/1329 - 12s - loss: 0.2709 - accuracy: 0.8351 - val_loss: 0.2692 - val_accuracy: 0.8346 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 35/600\n",
            "1329/1329 - 12s - loss: 0.2740 - accuracy: 0.8342 - val_loss: 0.2675 - val_accuracy: 0.8325 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 36/600\n",
            "1329/1329 - 11s - loss: 0.2652 - accuracy: 0.8358 - val_loss: 0.2625 - val_accuracy: 0.8397 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 37/600\n",
            "1329/1329 - 12s - loss: 0.2651 - accuracy: 0.8352 - val_loss: 0.2624 - val_accuracy: 0.8355 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 38/600\n",
            "1329/1329 - 11s - loss: 0.2726 - accuracy: 0.8335 - val_loss: 0.2632 - val_accuracy: 0.8391 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 39/600\n",
            "1329/1329 - 12s - loss: 0.2642 - accuracy: 0.8356 - val_loss: 0.2613 - val_accuracy: 0.8409 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 40/600\n",
            "1329/1329 - 13s - loss: 0.2640 - accuracy: 0.8369 - val_loss: 0.2614 - val_accuracy: 0.8386 - lr: 6.2500e-04 - 13s/epoch - 9ms/step\n",
            "Epoch 41/600\n",
            "1329/1329 - 11s - loss: 0.2684 - accuracy: 0.8352 - val_loss: 0.2615 - val_accuracy: 0.8398 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 42/600\n",
            "1329/1329 - 12s - loss: 0.2638 - accuracy: 0.8367 - val_loss: 0.2616 - val_accuracy: 0.8374 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 43/600\n",
            "1329/1329 - 11s - loss: 0.2609 - accuracy: 0.8378 - val_loss: 0.2586 - val_accuracy: 0.8385 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 44/600\n",
            "1329/1329 - 11s - loss: 0.2606 - accuracy: 0.8378 - val_loss: 0.2586 - val_accuracy: 0.8398 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 45/600\n",
            "1329/1329 - 12s - loss: 0.2613 - accuracy: 0.8372 - val_loss: 0.2630 - val_accuracy: 0.8321 - lr: 3.1250e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 46/600\n",
            "1329/1329 - 11s - loss: 0.2605 - accuracy: 0.8376 - val_loss: 0.2584 - val_accuracy: 0.8397 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 47/600\n",
            "1329/1329 - 12s - loss: 0.2602 - accuracy: 0.8377 - val_loss: 0.2585 - val_accuracy: 0.8388 - lr: 3.1250e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 48/600\n",
            "1329/1329 - 12s - loss: 0.2597 - accuracy: 0.8378 - val_loss: 0.2581 - val_accuracy: 0.8388 - lr: 3.1250e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 49/600\n",
            "1329/1329 - 12s - loss: 0.2601 - accuracy: 0.8371 - val_loss: 0.2597 - val_accuracy: 0.8337 - lr: 3.1250e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 50/600\n",
            "1329/1329 - 11s - loss: 0.2598 - accuracy: 0.8359 - val_loss: 0.2582 - val_accuracy: 0.8393 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 51/600\n",
            "1329/1329 - 11s - loss: 0.2629 - accuracy: 0.8366 - val_loss: 0.2581 - val_accuracy: 0.8387 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 52/600\n",
            "1329/1329 - 12s - loss: 0.2579 - accuracy: 0.8392 - val_loss: 0.2562 - val_accuracy: 0.8388 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 53/600\n",
            "1329/1329 - 11s - loss: 0.2580 - accuracy: 0.8374 - val_loss: 0.2563 - val_accuracy: 0.8396 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 54/600\n",
            "1329/1329 - 12s - loss: 0.2581 - accuracy: 0.8367 - val_loss: 0.2559 - val_accuracy: 0.8398 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 55/600\n",
            "1329/1329 - 11s - loss: 0.2579 - accuracy: 0.8383 - val_loss: 0.2561 - val_accuracy: 0.8395 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 56/600\n",
            "1329/1329 - 12s - loss: 0.2577 - accuracy: 0.8379 - val_loss: 0.2557 - val_accuracy: 0.8395 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 57/600\n",
            "1329/1329 - 11s - loss: 0.2576 - accuracy: 0.8386 - val_loss: 0.2560 - val_accuracy: 0.8387 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 58/600\n",
            "1329/1329 - 11s - loss: 0.2577 - accuracy: 0.8368 - val_loss: 0.2557 - val_accuracy: 0.8397 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 59/600\n",
            "1329/1329 - 12s - loss: 0.2575 - accuracy: 0.8380 - val_loss: 0.2560 - val_accuracy: 0.8396 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 60/600\n",
            "1329/1329 - 12s - loss: 0.2566 - accuracy: 0.8387 - val_loss: 0.2548 - val_accuracy: 0.8393 - lr: 7.8125e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 61/600\n",
            "1329/1329 - 11s - loss: 0.2566 - accuracy: 0.8389 - val_loss: 0.2549 - val_accuracy: 0.8392 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 62/600\n",
            "1329/1329 - 12s - loss: 0.2565 - accuracy: 0.8392 - val_loss: 0.2548 - val_accuracy: 0.8403 - lr: 7.8125e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 63/600\n",
            "1329/1329 - 11s - loss: 0.2564 - accuracy: 0.8388 - val_loss: 0.2546 - val_accuracy: 0.8387 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 64/600\n",
            "1329/1329 - 12s - loss: 0.2563 - accuracy: 0.8394 - val_loss: 0.2547 - val_accuracy: 0.8405 - lr: 7.8125e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 65/600\n",
            "1329/1329 - 11s - loss: 0.2564 - accuracy: 0.8391 - val_loss: 0.2547 - val_accuracy: 0.8405 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 66/600\n",
            "1329/1329 - 12s - loss: 0.2563 - accuracy: 0.8391 - val_loss: 0.2546 - val_accuracy: 0.8390 - lr: 7.8125e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 67/600\n",
            "1329/1329 - 12s - loss: 0.2557 - accuracy: 0.8383 - val_loss: 0.2542 - val_accuracy: 0.8390 - lr: 3.9062e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 68/600\n",
            "1329/1329 - 12s - loss: 0.2558 - accuracy: 0.8394 - val_loss: 0.2540 - val_accuracy: 0.8396 - lr: 3.9062e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 69/600\n",
            "1329/1329 - 12s - loss: 0.2555 - accuracy: 0.8394 - val_loss: 0.2541 - val_accuracy: 0.8393 - lr: 3.9062e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 70/600\n",
            "1329/1329 - 12s - loss: 0.2557 - accuracy: 0.8401 - val_loss: 0.2539 - val_accuracy: 0.8400 - lr: 3.9062e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 71/600\n",
            "1329/1329 - 12s - loss: 0.2557 - accuracy: 0.8397 - val_loss: 0.2539 - val_accuracy: 0.8389 - lr: 3.9062e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 72/600\n",
            "1329/1329 - 12s - loss: 0.2556 - accuracy: 0.8398 - val_loss: 0.2541 - val_accuracy: 0.8384 - lr: 3.9062e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 73/600\n",
            "1329/1329 - 12s - loss: 0.2555 - accuracy: 0.8393 - val_loss: 0.2540 - val_accuracy: 0.8403 - lr: 3.9062e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 74/600\n",
            "1329/1329 - 12s - loss: 0.2556 - accuracy: 0.8384 - val_loss: 0.2539 - val_accuracy: 0.8393 - lr: 3.9062e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 75/600\n",
            "1329/1329 - 12s - loss: 0.2552 - accuracy: 0.8402 - val_loss: 0.2537 - val_accuracy: 0.8390 - lr: 1.9531e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 76/600\n",
            "1329/1329 - 12s - loss: 0.2552 - accuracy: 0.8398 - val_loss: 0.2537 - val_accuracy: 0.8387 - lr: 1.9531e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 77/600\n",
            "1329/1329 - 12s - loss: 0.2551 - accuracy: 0.8398 - val_loss: 0.2536 - val_accuracy: 0.8388 - lr: 1.9531e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 78/600\n",
            "1329/1329 - 12s - loss: 0.2552 - accuracy: 0.8390 - val_loss: 0.2535 - val_accuracy: 0.8398 - lr: 1.9531e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 79/600\n",
            "1329/1329 - 12s - loss: 0.2553 - accuracy: 0.8401 - val_loss: 0.2535 - val_accuracy: 0.8400 - lr: 1.9531e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 80/600\n",
            "1329/1329 - 12s - loss: 0.2551 - accuracy: 0.8397 - val_loss: 0.2535 - val_accuracy: 0.8404 - lr: 1.9531e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 81/600\n",
            "1329/1329 - 12s - loss: 0.2551 - accuracy: 0.8398 - val_loss: 0.2535 - val_accuracy: 0.8395 - lr: 1.9531e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 82/600\n",
            "1329/1329 - 12s - loss: 0.2549 - accuracy: 0.8393 - val_loss: 0.2533 - val_accuracy: 0.8404 - lr: 9.7656e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 83/600\n",
            "1329/1329 - 11s - loss: 0.2549 - accuracy: 0.8391 - val_loss: 0.2534 - val_accuracy: 0.8389 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 84/600\n",
            "1329/1329 - 11s - loss: 0.2550 - accuracy: 0.8394 - val_loss: 0.2534 - val_accuracy: 0.8402 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 85/600\n",
            "1329/1329 - 12s - loss: 0.2549 - accuracy: 0.8392 - val_loss: 0.2533 - val_accuracy: 0.8392 - lr: 9.7656e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 86/600\n",
            "1329/1329 - 12s - loss: 0.2548 - accuracy: 0.8402 - val_loss: 0.2532 - val_accuracy: 0.8400 - lr: 4.8828e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 87/600\n",
            "1329/1329 - 12s - loss: 0.2549 - accuracy: 0.8395 - val_loss: 0.2533 - val_accuracy: 0.8400 - lr: 4.8828e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 88/600\n",
            "1329/1329 - 11s - loss: 0.2549 - accuracy: 0.8402 - val_loss: 0.2533 - val_accuracy: 0.8402 - lr: 4.8828e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 89/600\n",
            "1329/1329 - 12s - loss: 0.2547 - accuracy: 0.8391 - val_loss: 0.2532 - val_accuracy: 0.8403 - lr: 2.4414e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 90/600\n",
            "1329/1329 - 11s - loss: 0.2548 - accuracy: 0.8404 - val_loss: 0.2533 - val_accuracy: 0.8404 - lr: 2.4414e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 91/600\n",
            "1329/1329 - 13s - loss: 0.2547 - accuracy: 0.8399 - val_loss: 0.2532 - val_accuracy: 0.8400 - lr: 2.4414e-06 - 13s/epoch - 9ms/step\n",
            "Epoch 92/600\n",
            "1329/1329 - 11s - loss: 0.2548 - accuracy: 0.8395 - val_loss: 0.2532 - val_accuracy: 0.8400 - lr: 2.4414e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 93/600\n",
            "1329/1329 - 11s - loss: 0.2547 - accuracy: 0.8396 - val_loss: 0.2532 - val_accuracy: 0.8403 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 94/600\n",
            "1329/1329 - 11s - loss: 0.2548 - accuracy: 0.8404 - val_loss: 0.2532 - val_accuracy: 0.8402 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 95/600\n",
            "1329/1329 - 11s - loss: 0.2548 - accuracy: 0.8390 - val_loss: 0.2532 - val_accuracy: 0.8400 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 96/600\n",
            "1329/1329 - 11s - loss: 0.2547 - accuracy: 0.8411 - val_loss: 0.2532 - val_accuracy: 0.8402 - lr: 6.1035e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 97/600\n",
            "1329/1329 - 11s - loss: 0.2547 - accuracy: 0.8404 - val_loss: 0.2532 - val_accuracy: 0.8402 - lr: 6.1035e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 98/600\n",
            "1329/1329 - 11s - loss: 0.2547 - accuracy: 0.8400 - val_loss: 0.2532 - val_accuracy: 0.8402 - lr: 6.1035e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 99/600\n",
            "1329/1329 - 11s - loss: 0.2548 - accuracy: 0.8397 - val_loss: 0.2532 - val_accuracy: 0.8402 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 100/600\n",
            "1329/1329 - 12s - loss: 0.2547 - accuracy: 0.8399 - val_loss: 0.2532 - val_accuracy: 0.8403 - lr: 3.0518e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 101/600\n",
            "1329/1329 - 11s - loss: 0.2547 - accuracy: 0.8404 - val_loss: 0.2532 - val_accuracy: 0.8402 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 102/600\n",
            "1329/1329 - 11s - loss: 0.2548 - accuracy: 0.8397 - val_loss: 0.2532 - val_accuracy: 0.8402 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 103/600\n",
            "1329/1329 - 11s - loss: 0.2546 - accuracy: 0.8402 - val_loss: 0.2532 - val_accuracy: 0.8402 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 104/600\n",
            "1329/1329 - 11s - loss: 0.2546 - accuracy: 0.8402 - val_loss: 0.2532 - val_accuracy: 0.8402 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 105/600\n",
            "1329/1329 - 11s - loss: 0.2547 - accuracy: 0.8393 - val_loss: 0.2532 - val_accuracy: 0.8402 - lr: 7.6294e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 106/600\n",
            "1329/1329 - 11s - loss: 0.2548 - accuracy: 0.8402 - val_loss: 0.2532 - val_accuracy: 0.8402 - lr: 7.6294e-08 - 11s/epoch - 9ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " ...\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " ...\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ...  6 12 14]\n",
            " ...\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ...  6 12 14]\n",
            " [28 27 10 ...  6 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ... 14 11 24]\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 20]\n",
            " ...\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ... 14 11 24]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25  7]\n",
            " ...\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ...  7 18 13]\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ...  7 18 13]\n",
            " ...\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 23]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " ...\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 13 17  9]\n",
            " ...\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  9]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  9 21 22]\n",
            " ...\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " ...\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ... 22  3  8]\n",
            " ...\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ... 22  3  8]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " ...\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " ...\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_7 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1344/1344 - 16s - loss: 0.6467 - accuracy: 0.7944 - val_loss: 1.0123 - val_accuracy: 0.6489 - lr: 0.0050 - 16s/epoch - 12ms/step\n",
            "Epoch 2/600\n",
            "1344/1344 - 11s - loss: 0.3698 - accuracy: 0.8332 - val_loss: 0.3232 - val_accuracy: 0.8374 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 3/600\n",
            "1344/1344 - 11s - loss: 0.4599 - accuracy: 0.8285 - val_loss: 0.3188 - val_accuracy: 0.8372 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 4/600\n",
            "1344/1344 - 11s - loss: 0.3632 - accuracy: 0.8335 - val_loss: 0.3118 - val_accuracy: 0.8373 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 5/600\n",
            "1344/1344 - 11s - loss: 0.4466 - accuracy: 0.8285 - val_loss: 0.3727 - val_accuracy: 0.8372 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 6/600\n",
            "1344/1344 - 11s - loss: 0.3342 - accuracy: 0.8332 - val_loss: 0.3597 - val_accuracy: 0.8353 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 7/600\n",
            "1344/1344 - 11s - loss: 0.3476 - accuracy: 0.8326 - val_loss: 0.3095 - val_accuracy: 0.8376 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 8/600\n",
            "1344/1344 - 11s - loss: 0.3708 - accuracy: 0.8320 - val_loss: 0.5897 - val_accuracy: 0.8348 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 9/600\n",
            "1344/1344 - 11s - loss: 0.3514 - accuracy: 0.8357 - val_loss: 0.3058 - val_accuracy: 0.8365 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 10/600\n",
            "1344/1344 - 11s - loss: 0.3443 - accuracy: 0.8346 - val_loss: 0.3035 - val_accuracy: 0.8329 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 11/600\n",
            "1344/1344 - 11s - loss: 0.3397 - accuracy: 0.8337 - val_loss: 0.3056 - val_accuracy: 0.8358 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 12/600\n",
            "1344/1344 - 11s - loss: 0.3325 - accuracy: 0.8346 - val_loss: 0.3017 - val_accuracy: 0.8355 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 13/600\n",
            "1344/1344 - 11s - loss: 0.3086 - accuracy: 0.8353 - val_loss: 0.2930 - val_accuracy: 0.8383 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 14/600\n",
            "1344/1344 - 11s - loss: 0.3502 - accuracy: 0.8334 - val_loss: 0.2977 - val_accuracy: 0.8370 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 15/600\n",
            "1344/1344 - 11s - loss: 0.3238 - accuracy: 0.8348 - val_loss: 0.2950 - val_accuracy: 0.8380 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 16/600\n",
            "1344/1344 - 11s - loss: 0.3688 - accuracy: 0.8319 - val_loss: 0.3287 - val_accuracy: 0.8391 - lr: 0.0050 - 11s/epoch - 8ms/step\n",
            "Epoch 17/600\n",
            "1344/1344 - 11s - loss: 0.3017 - accuracy: 0.8379 - val_loss: 0.2864 - val_accuracy: 0.8347 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 18/600\n",
            "1344/1344 - 11s - loss: 0.2904 - accuracy: 0.8378 - val_loss: 0.2821 - val_accuracy: 0.8393 - lr: 0.0025 - 11s/epoch - 8ms/step\n",
            "Epoch 19/600\n",
            "1344/1344 - 12s - loss: 0.2964 - accuracy: 0.8371 - val_loss: 0.2798 - val_accuracy: 0.8373 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 20/600\n",
            "1344/1344 - 11s - loss: 0.2827 - accuracy: 0.8374 - val_loss: 0.2761 - val_accuracy: 0.8394 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 21/600\n",
            "1344/1344 - 12s - loss: 0.3127 - accuracy: 0.8352 - val_loss: 0.2778 - val_accuracy: 0.8396 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 22/600\n",
            "1344/1344 - 11s - loss: 0.2955 - accuracy: 0.8369 - val_loss: 0.2799 - val_accuracy: 0.8400 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 23/600\n",
            "1344/1344 - 12s - loss: 0.2832 - accuracy: 0.8380 - val_loss: 0.3964 - val_accuracy: 0.8264 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 24/600\n",
            "1344/1344 - 12s - loss: 0.2796 - accuracy: 0.8384 - val_loss: 0.2693 - val_accuracy: 0.8380 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 25/600\n",
            "1344/1344 - 12s - loss: 0.2710 - accuracy: 0.8391 - val_loss: 0.2667 - val_accuracy: 0.8375 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 26/600\n",
            "1344/1344 - 11s - loss: 0.2757 - accuracy: 0.8381 - val_loss: 0.2654 - val_accuracy: 0.8384 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 27/600\n",
            "1344/1344 - 11s - loss: 0.2692 - accuracy: 0.8391 - val_loss: 0.2661 - val_accuracy: 0.8388 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 28/600\n",
            "1344/1344 - 11s - loss: 0.2702 - accuracy: 0.8382 - val_loss: 0.2668 - val_accuracy: 0.8384 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 29/600\n",
            "1344/1344 - 12s - loss: 0.2877 - accuracy: 0.8367 - val_loss: 0.2664 - val_accuracy: 0.8361 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 30/600\n",
            "1344/1344 - 11s - loss: 0.2631 - accuracy: 0.8390 - val_loss: 0.2596 - val_accuracy: 0.8386 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 31/600\n",
            "1344/1344 - 12s - loss: 0.2620 - accuracy: 0.8391 - val_loss: 0.2586 - val_accuracy: 0.8399 - lr: 6.2500e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 32/600\n",
            "1344/1344 - 11s - loss: 0.2618 - accuracy: 0.8382 - val_loss: 0.2586 - val_accuracy: 0.8385 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 33/600\n",
            "1344/1344 - 11s - loss: 0.2619 - accuracy: 0.8386 - val_loss: 0.2582 - val_accuracy: 0.8402 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 34/600\n",
            "1344/1344 - 11s - loss: 0.2619 - accuracy: 0.8386 - val_loss: 0.2597 - val_accuracy: 0.8390 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 35/600\n",
            "1344/1344 - 11s - loss: 0.2626 - accuracy: 0.8392 - val_loss: 0.2595 - val_accuracy: 0.8387 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 36/600\n",
            "1344/1344 - 11s - loss: 0.2607 - accuracy: 0.8392 - val_loss: 0.2581 - val_accuracy: 0.8392 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 37/600\n",
            "1344/1344 - 12s - loss: 0.2571 - accuracy: 0.8403 - val_loss: 0.2546 - val_accuracy: 0.8376 - lr: 3.1250e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 38/600\n",
            "1344/1344 - 12s - loss: 0.2570 - accuracy: 0.8397 - val_loss: 0.2566 - val_accuracy: 0.8387 - lr: 3.1250e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 39/600\n",
            "1344/1344 - 11s - loss: 0.2571 - accuracy: 0.8391 - val_loss: 0.2556 - val_accuracy: 0.8395 - lr: 3.1250e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 40/600\n",
            "1344/1344 - 11s - loss: 0.2566 - accuracy: 0.8395 - val_loss: 0.2550 - val_accuracy: 0.8388 - lr: 3.1250e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 41/600\n",
            "1344/1344 - 11s - loss: 0.2547 - accuracy: 0.8395 - val_loss: 0.2529 - val_accuracy: 0.8389 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 42/600\n",
            "1344/1344 - 11s - loss: 0.2548 - accuracy: 0.8392 - val_loss: 0.2524 - val_accuracy: 0.8387 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 43/600\n",
            "1344/1344 - 11s - loss: 0.2544 - accuracy: 0.8393 - val_loss: 0.2529 - val_accuracy: 0.8401 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 44/600\n",
            "1344/1344 - 11s - loss: 0.2545 - accuracy: 0.8381 - val_loss: 0.2522 - val_accuracy: 0.8398 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 45/600\n",
            "1344/1344 - 11s - loss: 0.2545 - accuracy: 0.8386 - val_loss: 0.2522 - val_accuracy: 0.8395 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 46/600\n",
            "1344/1344 - 11s - loss: 0.2542 - accuracy: 0.8396 - val_loss: 0.2524 - val_accuracy: 0.8373 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 47/600\n",
            "1344/1344 - 11s - loss: 0.2542 - accuracy: 0.8392 - val_loss: 0.2520 - val_accuracy: 0.8377 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 48/600\n",
            "1344/1344 - 11s - loss: 0.2542 - accuracy: 0.8395 - val_loss: 0.2518 - val_accuracy: 0.8393 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 49/600\n",
            "1344/1344 - 11s - loss: 0.2541 - accuracy: 0.8387 - val_loss: 0.2519 - val_accuracy: 0.8386 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 50/600\n",
            "1344/1344 - 12s - loss: 0.2541 - accuracy: 0.8399 - val_loss: 0.2519 - val_accuracy: 0.8385 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 51/600\n",
            "1344/1344 - 12s - loss: 0.2540 - accuracy: 0.8392 - val_loss: 0.2520 - val_accuracy: 0.8387 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 52/600\n",
            "1344/1344 - 11s - loss: 0.2529 - accuracy: 0.8391 - val_loss: 0.2510 - val_accuracy: 0.8383 - lr: 7.8125e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 53/600\n",
            "1344/1344 - 11s - loss: 0.2529 - accuracy: 0.8398 - val_loss: 0.2509 - val_accuracy: 0.8393 - lr: 7.8125e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 54/600\n",
            "1344/1344 - 11s - loss: 0.2528 - accuracy: 0.8389 - val_loss: 0.2510 - val_accuracy: 0.8390 - lr: 7.8125e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 55/600\n",
            "1344/1344 - 11s - loss: 0.2529 - accuracy: 0.8388 - val_loss: 0.2509 - val_accuracy: 0.8405 - lr: 7.8125e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 56/600\n",
            "1344/1344 - 11s - loss: 0.2522 - accuracy: 0.8390 - val_loss: 0.2503 - val_accuracy: 0.8389 - lr: 3.9062e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 57/600\n",
            "1344/1344 - 11s - loss: 0.2522 - accuracy: 0.8389 - val_loss: 0.2502 - val_accuracy: 0.8393 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 58/600\n",
            "1344/1344 - 11s - loss: 0.2521 - accuracy: 0.8399 - val_loss: 0.2505 - val_accuracy: 0.8385 - lr: 3.9062e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 59/600\n",
            "1344/1344 - 11s - loss: 0.2521 - accuracy: 0.8397 - val_loss: 0.2502 - val_accuracy: 0.8393 - lr: 3.9062e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 60/600\n",
            "1344/1344 - 11s - loss: 0.2518 - accuracy: 0.8406 - val_loss: 0.2501 - val_accuracy: 0.8389 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 61/600\n",
            "1344/1344 - 11s - loss: 0.2518 - accuracy: 0.8399 - val_loss: 0.2500 - val_accuracy: 0.8385 - lr: 1.9531e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 62/600\n",
            "1344/1344 - 11s - loss: 0.2518 - accuracy: 0.8399 - val_loss: 0.2500 - val_accuracy: 0.8385 - lr: 1.9531e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 63/600\n",
            "1344/1344 - 11s - loss: 0.2518 - accuracy: 0.8398 - val_loss: 0.2500 - val_accuracy: 0.8388 - lr: 1.9531e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 64/600\n",
            "1344/1344 - 11s - loss: 0.2518 - accuracy: 0.8401 - val_loss: 0.2501 - val_accuracy: 0.8389 - lr: 1.9531e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 65/600\n",
            "1344/1344 - 11s - loss: 0.2518 - accuracy: 0.8389 - val_loss: 0.2498 - val_accuracy: 0.8391 - lr: 9.7656e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 66/600\n",
            "1344/1344 - 11s - loss: 0.2516 - accuracy: 0.8405 - val_loss: 0.2498 - val_accuracy: 0.8382 - lr: 9.7656e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 67/600\n",
            "1344/1344 - 11s - loss: 0.2517 - accuracy: 0.8400 - val_loss: 0.2499 - val_accuracy: 0.8388 - lr: 9.7656e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 68/600\n",
            "1344/1344 - 11s - loss: 0.2516 - accuracy: 0.8397 - val_loss: 0.2498 - val_accuracy: 0.8389 - lr: 9.7656e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 69/600\n",
            "1344/1344 - 11s - loss: 0.2517 - accuracy: 0.8401 - val_loss: 0.2498 - val_accuracy: 0.8383 - lr: 4.8828e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 70/600\n",
            "1344/1344 - 12s - loss: 0.2515 - accuracy: 0.8397 - val_loss: 0.2498 - val_accuracy: 0.8388 - lr: 4.8828e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 71/600\n",
            "1344/1344 - 12s - loss: 0.2515 - accuracy: 0.8406 - val_loss: 0.2498 - val_accuracy: 0.8391 - lr: 4.8828e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 72/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8400 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 2.4414e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 73/600\n",
            "1344/1344 - 12s - loss: 0.2515 - accuracy: 0.8394 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 2.4414e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 74/600\n",
            "1344/1344 - 12s - loss: 0.2516 - accuracy: 0.8391 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 2.4414e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 75/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8402 - val_loss: 0.2497 - val_accuracy: 0.8388 - lr: 2.4414e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 76/600\n",
            "1344/1344 - 12s - loss: 0.2515 - accuracy: 0.8395 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 1.2207e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 77/600\n",
            "1344/1344 - 12s - loss: 0.2515 - accuracy: 0.8393 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 1.2207e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 78/600\n",
            "1344/1344 - 12s - loss: 0.2515 - accuracy: 0.8397 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 1.2207e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 79/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8400 - val_loss: 0.2497 - val_accuracy: 0.8388 - lr: 6.1035e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 80/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8409 - val_loss: 0.2497 - val_accuracy: 0.8388 - lr: 6.1035e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 81/600\n",
            "1344/1344 - 12s - loss: 0.2515 - accuracy: 0.8401 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 6.1035e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 82/600\n",
            "1344/1344 - 12s - loss: 0.2515 - accuracy: 0.8394 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 3.0518e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 83/600\n",
            "1344/1344 - 12s - loss: 0.2517 - accuracy: 0.8387 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 3.0518e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 84/600\n",
            "1344/1344 - 12s - loss: 0.2515 - accuracy: 0.8398 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 3.0518e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 85/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8412 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 1.5259e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 86/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8400 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 1.5259e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 87/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8404 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 1.5259e-07 - 12s/epoch - 9ms/step\n",
            "Epoch 88/600\n",
            "1344/1344 - 12s - loss: 0.2515 - accuracy: 0.8395 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 7.6294e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 89/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8408 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 7.6294e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 90/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8401 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 7.6294e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 91/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8404 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 3.8147e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 92/600\n",
            "1344/1344 - 11s - loss: 0.2514 - accuracy: 0.8392 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 93/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8397 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 3.8147e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 94/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8397 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 1.9073e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 95/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8391 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 1.9073e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 96/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8396 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 1.9073e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 97/600\n",
            "1344/1344 - 12s - loss: 0.2515 - accuracy: 0.8391 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 9.5367e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 98/600\n",
            "1344/1344 - 12s - loss: 0.2516 - accuracy: 0.8395 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 9.5367e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 99/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8397 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 9.5367e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 100/600\n",
            "1344/1344 - 12s - loss: 0.2515 - accuracy: 0.8398 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 4.7684e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 101/600\n",
            "1344/1344 - 12s - loss: 0.2513 - accuracy: 0.8394 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 4.7684e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 102/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8401 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 4.7684e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 103/600\n",
            "1344/1344 - 12s - loss: 0.2515 - accuracy: 0.8391 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 2.3842e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 104/600\n",
            "1344/1344 - 12s - loss: 0.2515 - accuracy: 0.8397 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 2.3842e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 105/600\n",
            "1344/1344 - 13s - loss: 0.2514 - accuracy: 0.8401 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 2.3842e-09 - 13s/epoch - 9ms/step\n",
            "Epoch 106/600\n",
            "1344/1344 - 12s - loss: 0.2514 - accuracy: 0.8406 - val_loss: 0.2497 - val_accuracy: 0.8389 - lr: 1.1921e-09 - 12s/epoch - 9ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  1]\n",
            " ...\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  1 26]\n",
            " ...\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12 14]\n",
            " [28 27 10 ...  1 26 12]\n",
            " ...\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 26 12  2]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 24]\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ... 12  2 11]\n",
            " ...\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 20]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ...  2 11 20]\n",
            " ...\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 11 20 25]\n",
            " ...\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25  7]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 20 25 15]\n",
            " ...\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ... 15 18 23]\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ...  7 18 13]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 15 18 23]\n",
            " ...\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  1]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 23 17  9]\n",
            " ...\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ...  9 21  4]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  4  3  5]\n",
            " ...\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  3  5 19]\n",
            " ...\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n"
          ]
        }
      ],
      "source": [
        "do_experiment('Model3', 6, True, 0, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G3aXMvMlYbVO",
        "outputId": "6361ed6b-083a-40fb-cfb2-be3faa8fa2bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prefix length: 20\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_8 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1277/1277 - 15s - loss: 0.9368 - accuracy: 0.7759 - val_loss: 0.7249 - val_accuracy: 0.7878 - lr: 0.0050 - 15s/epoch - 12ms/step\n",
            "Epoch 2/600\n",
            "1277/1277 - 10s - loss: 0.4708 - accuracy: 0.8309 - val_loss: 0.3660 - val_accuracy: 0.8423 - lr: 0.0050 - 10s/epoch - 8ms/step\n",
            "Epoch 3/600\n",
            "1277/1277 - 11s - loss: 0.4521 - accuracy: 0.8321 - val_loss: 0.3507 - val_accuracy: 0.8365 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 4/600\n",
            "1277/1277 - 10s - loss: 0.4258 - accuracy: 0.8331 - val_loss: 0.3459 - val_accuracy: 0.8408 - lr: 0.0050 - 10s/epoch - 8ms/step\n",
            "Epoch 5/600\n",
            "1277/1277 - 10s - loss: 0.3737 - accuracy: 0.8366 - val_loss: 0.3318 - val_accuracy: 0.8402 - lr: 0.0050 - 10s/epoch - 8ms/step\n",
            "Epoch 6/600\n",
            "1277/1277 - 10s - loss: 0.3516 - accuracy: 0.8361 - val_loss: 0.3209 - val_accuracy: 0.8377 - lr: 0.0050 - 10s/epoch - 8ms/step\n",
            "Epoch 7/600\n",
            "1277/1277 - 10s - loss: 0.4751 - accuracy: 0.8316 - val_loss: 0.3612 - val_accuracy: 0.8401 - lr: 0.0050 - 10s/epoch - 8ms/step\n",
            "Epoch 8/600\n",
            "1277/1277 - 10s - loss: 0.3566 - accuracy: 0.8368 - val_loss: 0.3209 - val_accuracy: 0.8425 - lr: 0.0050 - 10s/epoch - 8ms/step\n",
            "Epoch 9/600\n",
            "1277/1277 - 10s - loss: 0.4231 - accuracy: 0.8315 - val_loss: 0.5739 - val_accuracy: 0.8189 - lr: 0.0050 - 10s/epoch - 8ms/step\n",
            "Epoch 10/600\n",
            "1277/1277 - 10s - loss: 0.3815 - accuracy: 0.8354 - val_loss: 0.3099 - val_accuracy: 0.8393 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 11/600\n",
            "1277/1277 - 10s - loss: 0.3087 - accuracy: 0.8386 - val_loss: 0.2965 - val_accuracy: 0.8393 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 12/600\n",
            "1277/1277 - 10s - loss: 0.3215 - accuracy: 0.8384 - val_loss: 0.2978 - val_accuracy: 0.8401 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 13/600\n",
            "1277/1277 - 10s - loss: 0.3077 - accuracy: 0.8390 - val_loss: 0.2921 - val_accuracy: 0.8399 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 14/600\n",
            "1277/1277 - 10s - loss: 0.3158 - accuracy: 0.8382 - val_loss: 0.3127 - val_accuracy: 0.8421 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 15/600\n",
            "1277/1277 - 10s - loss: 0.3038 - accuracy: 0.8399 - val_loss: 0.4607 - val_accuracy: 0.8215 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 16/600\n",
            "1277/1277 - 10s - loss: 0.3040 - accuracy: 0.8401 - val_loss: 0.2881 - val_accuracy: 0.8409 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 17/600\n",
            "1277/1277 - 10s - loss: 0.3094 - accuracy: 0.8389 - val_loss: 0.2888 - val_accuracy: 0.8409 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 18/600\n",
            "1277/1277 - 10s - loss: 0.3151 - accuracy: 0.8383 - val_loss: 0.3021 - val_accuracy: 0.8423 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 19/600\n",
            "1277/1277 - 10s - loss: 0.2928 - accuracy: 0.8405 - val_loss: 0.2884 - val_accuracy: 0.8369 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 20/600\n",
            "1277/1277 - 10s - loss: 0.2805 - accuracy: 0.8413 - val_loss: 0.2797 - val_accuracy: 0.8405 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 21/600\n",
            "1277/1277 - 10s - loss: 0.2935 - accuracy: 0.8389 - val_loss: 0.3219 - val_accuracy: 0.8401 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 22/600\n",
            "1277/1277 - 10s - loss: 0.2824 - accuracy: 0.8411 - val_loss: 0.2733 - val_accuracy: 0.8409 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 23/600\n",
            "1277/1277 - 11s - loss: 0.2775 - accuracy: 0.8405 - val_loss: 0.2727 - val_accuracy: 0.8420 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 24/600\n",
            "1277/1277 - 10s - loss: 0.2850 - accuracy: 0.8408 - val_loss: 0.2730 - val_accuracy: 0.8427 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 25/600\n",
            "1277/1277 - 10s - loss: 0.2759 - accuracy: 0.8410 - val_loss: 0.2727 - val_accuracy: 0.8418 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 26/600\n",
            "1277/1277 - 10s - loss: 0.2843 - accuracy: 0.8402 - val_loss: 0.2714 - val_accuracy: 0.8403 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 27/600\n",
            "1277/1277 - 10s - loss: 0.2757 - accuracy: 0.8407 - val_loss: 0.2718 - val_accuracy: 0.8397 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 28/600\n",
            "1277/1277 - 10s - loss: 0.2774 - accuracy: 0.8414 - val_loss: 0.2718 - val_accuracy: 0.8407 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 29/600\n",
            "1277/1277 - 10s - loss: 0.2825 - accuracy: 0.8410 - val_loss: 0.2716 - val_accuracy: 0.8402 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 30/600\n",
            "1277/1277 - 10s - loss: 0.2689 - accuracy: 0.8408 - val_loss: 0.2648 - val_accuracy: 0.8419 - lr: 6.2500e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 31/600\n",
            "1277/1277 - 10s - loss: 0.2692 - accuracy: 0.8403 - val_loss: 0.2664 - val_accuracy: 0.8417 - lr: 6.2500e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 32/600\n",
            "1277/1277 - 10s - loss: 0.2691 - accuracy: 0.8397 - val_loss: 0.2653 - val_accuracy: 0.8409 - lr: 6.2500e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 33/600\n",
            "1277/1277 - 10s - loss: 0.2705 - accuracy: 0.8420 - val_loss: 0.2654 - val_accuracy: 0.8418 - lr: 6.2500e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 34/600\n",
            "1277/1277 - 10s - loss: 0.2650 - accuracy: 0.8429 - val_loss: 0.2619 - val_accuracy: 0.8414 - lr: 3.1250e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 35/600\n",
            "1277/1277 - 10s - loss: 0.2649 - accuracy: 0.8410 - val_loss: 0.2616 - val_accuracy: 0.8410 - lr: 3.1250e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 36/600\n",
            "1277/1277 - 10s - loss: 0.2653 - accuracy: 0.8414 - val_loss: 0.2620 - val_accuracy: 0.8418 - lr: 3.1250e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 37/600\n",
            "1277/1277 - 10s - loss: 0.2646 - accuracy: 0.8413 - val_loss: 0.2619 - val_accuracy: 0.8429 - lr: 3.1250e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 38/600\n",
            "1277/1277 - 10s - loss: 0.2652 - accuracy: 0.8421 - val_loss: 0.2617 - val_accuracy: 0.8424 - lr: 3.1250e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 39/600\n",
            "1277/1277 - 10s - loss: 0.2630 - accuracy: 0.8410 - val_loss: 0.2605 - val_accuracy: 0.8411 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 40/600\n",
            "1277/1277 - 10s - loss: 0.2626 - accuracy: 0.8419 - val_loss: 0.2598 - val_accuracy: 0.8437 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 41/600\n",
            "1277/1277 - 11s - loss: 0.2627 - accuracy: 0.8420 - val_loss: 0.2602 - val_accuracy: 0.8424 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 42/600\n",
            "1277/1277 - 10s - loss: 0.2627 - accuracy: 0.8406 - val_loss: 0.2600 - val_accuracy: 0.8413 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 43/600\n",
            "1277/1277 - 10s - loss: 0.2624 - accuracy: 0.8424 - val_loss: 0.2598 - val_accuracy: 0.8411 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 44/600\n",
            "1277/1277 - 10s - loss: 0.2615 - accuracy: 0.8417 - val_loss: 0.2589 - val_accuracy: 0.8423 - lr: 7.8125e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 45/600\n",
            "1277/1277 - 10s - loss: 0.2613 - accuracy: 0.8432 - val_loss: 0.2589 - val_accuracy: 0.8420 - lr: 7.8125e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 46/600\n",
            "1277/1277 - 10s - loss: 0.2614 - accuracy: 0.8421 - val_loss: 0.2587 - val_accuracy: 0.8416 - lr: 7.8125e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 47/600\n",
            "1277/1277 - 10s - loss: 0.2613 - accuracy: 0.8413 - val_loss: 0.2586 - val_accuracy: 0.8411 - lr: 7.8125e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 48/600\n",
            "1277/1277 - 10s - loss: 0.2612 - accuracy: 0.8424 - val_loss: 0.2586 - val_accuracy: 0.8433 - lr: 7.8125e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 49/600\n",
            "1277/1277 - 10s - loss: 0.2612 - accuracy: 0.8431 - val_loss: 0.2592 - val_accuracy: 0.8422 - lr: 7.8125e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 50/600\n",
            "1277/1277 - 10s - loss: 0.2611 - accuracy: 0.8419 - val_loss: 0.2584 - val_accuracy: 0.8401 - lr: 7.8125e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 51/600\n",
            "1277/1277 - 10s - loss: 0.2610 - accuracy: 0.8428 - val_loss: 0.2586 - val_accuracy: 0.8409 - lr: 7.8125e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 52/600\n",
            "1277/1277 - 10s - loss: 0.2610 - accuracy: 0.8427 - val_loss: 0.2585 - val_accuracy: 0.8432 - lr: 7.8125e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 53/600\n",
            "1277/1277 - 10s - loss: 0.2610 - accuracy: 0.8428 - val_loss: 0.2588 - val_accuracy: 0.8416 - lr: 7.8125e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 54/600\n",
            "1277/1277 - 10s - loss: 0.2604 - accuracy: 0.8426 - val_loss: 0.2580 - val_accuracy: 0.8408 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 55/600\n",
            "1277/1277 - 10s - loss: 0.2603 - accuracy: 0.8436 - val_loss: 0.2579 - val_accuracy: 0.8404 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 56/600\n",
            "1277/1277 - 10s - loss: 0.2602 - accuracy: 0.8427 - val_loss: 0.2578 - val_accuracy: 0.8437 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 57/600\n",
            "1277/1277 - 10s - loss: 0.2603 - accuracy: 0.8426 - val_loss: 0.2579 - val_accuracy: 0.8416 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 58/600\n",
            "1277/1277 - 10s - loss: 0.2602 - accuracy: 0.8422 - val_loss: 0.2579 - val_accuracy: 0.8406 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 59/600\n",
            "1277/1277 - 10s - loss: 0.2604 - accuracy: 0.8415 - val_loss: 0.2577 - val_accuracy: 0.8422 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 60/600\n",
            "1277/1277 - 10s - loss: 0.2604 - accuracy: 0.8418 - val_loss: 0.2578 - val_accuracy: 0.8414 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 61/600\n",
            "1277/1277 - 11s - loss: 0.2601 - accuracy: 0.8434 - val_loss: 0.2579 - val_accuracy: 0.8414 - lr: 3.9062e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 62/600\n",
            "1277/1277 - 10s - loss: 0.2602 - accuracy: 0.8425 - val_loss: 0.2578 - val_accuracy: 0.8412 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 63/600\n",
            "1277/1277 - 10s - loss: 0.2599 - accuracy: 0.8421 - val_loss: 0.2576 - val_accuracy: 0.8409 - lr: 1.9531e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 64/600\n",
            "1277/1277 - 10s - loss: 0.2600 - accuracy: 0.8426 - val_loss: 0.2574 - val_accuracy: 0.8406 - lr: 1.9531e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 65/600\n",
            "1277/1277 - 10s - loss: 0.2599 - accuracy: 0.8424 - val_loss: 0.2575 - val_accuracy: 0.8405 - lr: 1.9531e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 66/600\n",
            "1277/1277 - 11s - loss: 0.2598 - accuracy: 0.8426 - val_loss: 0.2574 - val_accuracy: 0.8409 - lr: 1.9531e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 67/600\n",
            "1277/1277 - 10s - loss: 0.2599 - accuracy: 0.8425 - val_loss: 0.2574 - val_accuracy: 0.8416 - lr: 1.9531e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 68/600\n",
            "1277/1277 - 10s - loss: 0.2594 - accuracy: 0.8440 - val_loss: 0.2573 - val_accuracy: 0.8405 - lr: 9.7656e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 69/600\n",
            "1277/1277 - 10s - loss: 0.2596 - accuracy: 0.8434 - val_loss: 0.2572 - val_accuracy: 0.8404 - lr: 9.7656e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 70/600\n",
            "1277/1277 - 10s - loss: 0.2597 - accuracy: 0.8429 - val_loss: 0.2572 - val_accuracy: 0.8405 - lr: 9.7656e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 71/600\n",
            "1277/1277 - 10s - loss: 0.2596 - accuracy: 0.8430 - val_loss: 0.2572 - val_accuracy: 0.8409 - lr: 9.7656e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 72/600\n",
            "1277/1277 - 10s - loss: 0.2595 - accuracy: 0.8437 - val_loss: 0.2572 - val_accuracy: 0.8409 - lr: 4.8828e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 73/600\n",
            "1277/1277 - 10s - loss: 0.2594 - accuracy: 0.8433 - val_loss: 0.2572 - val_accuracy: 0.8408 - lr: 4.8828e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 74/600\n",
            "1277/1277 - 10s - loss: 0.2595 - accuracy: 0.8434 - val_loss: 0.2571 - val_accuracy: 0.8407 - lr: 4.8828e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 75/600\n",
            "1277/1277 - 10s - loss: 0.2596 - accuracy: 0.8426 - val_loss: 0.2571 - val_accuracy: 0.8404 - lr: 4.8828e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 76/600\n",
            "1277/1277 - 10s - loss: 0.2595 - accuracy: 0.8433 - val_loss: 0.2571 - val_accuracy: 0.8407 - lr: 4.8828e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 77/600\n",
            "1277/1277 - 10s - loss: 0.2595 - accuracy: 0.8425 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 2.4414e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 78/600\n",
            "1277/1277 - 11s - loss: 0.2595 - accuracy: 0.8426 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 2.4414e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 79/600\n",
            "1277/1277 - 10s - loss: 0.2595 - accuracy: 0.8427 - val_loss: 0.2571 - val_accuracy: 0.8404 - lr: 2.4414e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 80/600\n",
            "1277/1277 - 10s - loss: 0.2595 - accuracy: 0.8426 - val_loss: 0.2571 - val_accuracy: 0.8404 - lr: 1.2207e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 81/600\n",
            "1277/1277 - 11s - loss: 0.2593 - accuracy: 0.8427 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 1.2207e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 82/600\n",
            "1277/1277 - 10s - loss: 0.2596 - accuracy: 0.8423 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 1.2207e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 83/600\n",
            "1277/1277 - 10s - loss: 0.2595 - accuracy: 0.8427 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 6.1035e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 84/600\n",
            "1277/1277 - 10s - loss: 0.2595 - accuracy: 0.8432 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 6.1035e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 85/600\n",
            "1277/1277 - 10s - loss: 0.2594 - accuracy: 0.8430 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 6.1035e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 86/600\n",
            "1277/1277 - 10s - loss: 0.2594 - accuracy: 0.8434 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 3.0518e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 87/600\n",
            "1277/1277 - 10s - loss: 0.2594 - accuracy: 0.8432 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 3.0518e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 88/600\n",
            "1277/1277 - 10s - loss: 0.2595 - accuracy: 0.8423 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 3.0518e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 89/600\n",
            "1277/1277 - 10s - loss: 0.2593 - accuracy: 0.8430 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 1.5259e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 90/600\n",
            "1277/1277 - 10s - loss: 0.2594 - accuracy: 0.8431 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 1.5259e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 91/600\n",
            "1277/1277 - 10s - loss: 0.2595 - accuracy: 0.8430 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 1.5259e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 92/600\n",
            "1277/1277 - 10s - loss: 0.2595 - accuracy: 0.8425 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 7.6294e-08 - 10s/epoch - 8ms/step\n",
            "Epoch 93/600\n",
            "1277/1277 - 10s - loss: 0.2594 - accuracy: 0.8440 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 7.6294e-08 - 10s/epoch - 8ms/step\n",
            "Epoch 94/600\n",
            "1277/1277 - 10s - loss: 0.2594 - accuracy: 0.8437 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 7.6294e-08 - 10s/epoch - 8ms/step\n",
            "Epoch 95/600\n",
            "1277/1277 - 10s - loss: 0.2594 - accuracy: 0.8425 - val_loss: 0.2571 - val_accuracy: 0.8405 - lr: 3.8147e-08 - 10s/epoch - 8ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " ...\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " ...\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12  2]\n",
            " [28 27 10 ...  6 12 14]\n",
            " [28 27 10 ...  6 12 14]\n",
            " ...\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ... 14 11 20]\n",
            " ...\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ... 14 11 20]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 20 25 15]\n",
            " ...\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25  7]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25  7 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ...  7 18 13]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 23]\n",
            " ...\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ...  7 18 23]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  1]\n",
            " ...\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 23 17  1]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " ...\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21 22]\n",
            " ...\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  1 21  4]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ... 22  3  8]\n",
            " ...\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " ...\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " ...\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_9 (Bidirectio  (None, 128)              48128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1276/1276 - 16s - loss: 0.6965 - accuracy: 0.7860 - val_loss: 0.3787 - val_accuracy: 0.8405 - lr: 0.0050 - 16s/epoch - 12ms/step\n",
            "Epoch 2/600\n",
            "1276/1276 - 11s - loss: 0.4317 - accuracy: 0.8298 - val_loss: 0.3297 - val_accuracy: 0.8389 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 3/600\n",
            "1276/1276 - 11s - loss: 0.7129 - accuracy: 0.8155 - val_loss: 0.5513 - val_accuracy: 0.8348 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 4/600\n",
            "1276/1276 - 11s - loss: 0.4301 - accuracy: 0.8320 - val_loss: 0.3618 - val_accuracy: 0.8379 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 5/600\n",
            "1276/1276 - 11s - loss: 0.4602 - accuracy: 0.8292 - val_loss: 0.3460 - val_accuracy: 0.8377 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 6/600\n",
            "1276/1276 - 12s - loss: 0.3226 - accuracy: 0.8366 - val_loss: 0.3033 - val_accuracy: 0.8436 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 7/600\n",
            "1276/1276 - 11s - loss: 0.3204 - accuracy: 0.8352 - val_loss: 0.2966 - val_accuracy: 0.8383 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 8/600\n",
            "1276/1276 - 11s - loss: 0.3063 - accuracy: 0.8354 - val_loss: 0.2941 - val_accuracy: 0.8384 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 9/600\n",
            "1276/1276 - 11s - loss: 0.3248 - accuracy: 0.8358 - val_loss: 0.2921 - val_accuracy: 0.8400 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 10/600\n",
            "1276/1276 - 11s - loss: 0.2955 - accuracy: 0.8380 - val_loss: 0.2870 - val_accuracy: 0.8368 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 11/600\n",
            "1276/1276 - 12s - loss: 0.2973 - accuracy: 0.8373 - val_loss: 0.2830 - val_accuracy: 0.8402 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 12/600\n",
            "1276/1276 - 12s - loss: 0.3093 - accuracy: 0.8362 - val_loss: 0.2843 - val_accuracy: 0.8385 - lr: 0.0025 - 12s/epoch - 9ms/step\n",
            "Epoch 13/600\n",
            "1276/1276 - 11s - loss: 0.3237 - accuracy: 0.8360 - val_loss: 0.2996 - val_accuracy: 0.8349 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 14/600\n",
            "1276/1276 - 11s - loss: 0.2880 - accuracy: 0.8390 - val_loss: 0.2848 - val_accuracy: 0.8354 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 15/600\n",
            "1276/1276 - 11s - loss: 0.2751 - accuracy: 0.8395 - val_loss: 0.2701 - val_accuracy: 0.8411 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 16/600\n",
            "1276/1276 - 11s - loss: 0.2746 - accuracy: 0.8401 - val_loss: 0.2714 - val_accuracy: 0.8391 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 17/600\n",
            "1276/1276 - 11s - loss: 0.2812 - accuracy: 0.8385 - val_loss: 0.2697 - val_accuracy: 0.8419 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 18/600\n",
            "1276/1276 - 11s - loss: 0.2729 - accuracy: 0.8389 - val_loss: 0.2698 - val_accuracy: 0.8376 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 19/600\n",
            "1276/1276 - 12s - loss: 0.2738 - accuracy: 0.8380 - val_loss: 0.2691 - val_accuracy: 0.8414 - lr: 0.0012 - 12s/epoch - 9ms/step\n",
            "Epoch 20/600\n",
            "1276/1276 - 11s - loss: 0.2905 - accuracy: 0.8375 - val_loss: 0.2854 - val_accuracy: 0.8392 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 21/600\n",
            "1276/1276 - 11s - loss: 0.2723 - accuracy: 0.8396 - val_loss: 0.2691 - val_accuracy: 0.8360 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 22/600\n",
            "1276/1276 - 11s - loss: 0.2704 - accuracy: 0.8397 - val_loss: 0.2659 - val_accuracy: 0.8407 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 23/600\n",
            "1276/1276 - 11s - loss: 0.2707 - accuracy: 0.8398 - val_loss: 0.2696 - val_accuracy: 0.8406 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 24/600\n",
            "1276/1276 - 11s - loss: 0.2958 - accuracy: 0.8371 - val_loss: 0.2754 - val_accuracy: 0.8367 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 25/600\n",
            "1276/1276 - 11s - loss: 0.2701 - accuracy: 0.8385 - val_loss: 0.2656 - val_accuracy: 0.8415 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 26/600\n",
            "1276/1276 - 11s - loss: 0.2696 - accuracy: 0.8382 - val_loss: 0.2651 - val_accuracy: 0.8392 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 27/600\n",
            "1276/1276 - 11s - loss: 0.2771 - accuracy: 0.8371 - val_loss: 0.2766 - val_accuracy: 0.8384 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 28/600\n",
            "1276/1276 - 11s - loss: 0.2695 - accuracy: 0.8397 - val_loss: 0.2666 - val_accuracy: 0.8391 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 29/600\n",
            "1276/1276 - 11s - loss: 0.2788 - accuracy: 0.8368 - val_loss: 0.2697 - val_accuracy: 0.8377 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 30/600\n",
            "1276/1276 - 11s - loss: 0.2658 - accuracy: 0.8375 - val_loss: 0.2663 - val_accuracy: 0.8381 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 31/600\n",
            "1276/1276 - 11s - loss: 0.2651 - accuracy: 0.8383 - val_loss: 0.2607 - val_accuracy: 0.8420 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 32/600\n",
            "1276/1276 - 11s - loss: 0.2646 - accuracy: 0.8400 - val_loss: 0.2621 - val_accuracy: 0.8414 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 33/600\n",
            "1276/1276 - 11s - loss: 0.2700 - accuracy: 0.8391 - val_loss: 0.2605 - val_accuracy: 0.8402 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 34/600\n",
            "1276/1276 - 11s - loss: 0.2628 - accuracy: 0.8411 - val_loss: 0.2613 - val_accuracy: 0.8394 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 35/600\n",
            "1276/1276 - 11s - loss: 0.2631 - accuracy: 0.8393 - val_loss: 0.2616 - val_accuracy: 0.8402 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 36/600\n",
            "1276/1276 - 11s - loss: 0.2635 - accuracy: 0.8402 - val_loss: 0.2627 - val_accuracy: 0.8379 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 37/600\n",
            "1276/1276 - 11s - loss: 0.2592 - accuracy: 0.8415 - val_loss: 0.2568 - val_accuracy: 0.8422 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 38/600\n",
            "1276/1276 - 11s - loss: 0.2591 - accuracy: 0.8411 - val_loss: 0.2569 - val_accuracy: 0.8406 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 39/600\n",
            "1276/1276 - 11s - loss: 0.2588 - accuracy: 0.8412 - val_loss: 0.2558 - val_accuracy: 0.8422 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 40/600\n",
            "1276/1276 - 11s - loss: 0.2588 - accuracy: 0.8413 - val_loss: 0.2563 - val_accuracy: 0.8433 - lr: 3.1250e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 41/600\n",
            "1276/1276 - 11s - loss: 0.2586 - accuracy: 0.8407 - val_loss: 0.2568 - val_accuracy: 0.8435 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 42/600\n",
            "1276/1276 - 11s - loss: 0.2584 - accuracy: 0.8412 - val_loss: 0.2581 - val_accuracy: 0.8435 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 43/600\n",
            "1276/1276 - 11s - loss: 0.2563 - accuracy: 0.8413 - val_loss: 0.2541 - val_accuracy: 0.8435 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 44/600\n",
            "1276/1276 - 11s - loss: 0.2558 - accuracy: 0.8418 - val_loss: 0.2538 - val_accuracy: 0.8435 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 45/600\n",
            "1276/1276 - 11s - loss: 0.2559 - accuracy: 0.8424 - val_loss: 0.2538 - val_accuracy: 0.8433 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 46/600\n",
            "1276/1276 - 11s - loss: 0.2560 - accuracy: 0.8426 - val_loss: 0.2540 - val_accuracy: 0.8403 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 47/600\n",
            "1276/1276 - 11s - loss: 0.2558 - accuracy: 0.8421 - val_loss: 0.2532 - val_accuracy: 0.8438 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 48/600\n",
            "1276/1276 - 11s - loss: 0.2559 - accuracy: 0.8419 - val_loss: 0.2545 - val_accuracy: 0.8430 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 49/600\n",
            "1276/1276 - 12s - loss: 0.2555 - accuracy: 0.8418 - val_loss: 0.2540 - val_accuracy: 0.8417 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 50/600\n",
            "1276/1276 - 12s - loss: 0.2556 - accuracy: 0.8420 - val_loss: 0.2535 - val_accuracy: 0.8421 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 51/600\n",
            "1276/1276 - 11s - loss: 0.2542 - accuracy: 0.8425 - val_loss: 0.2522 - val_accuracy: 0.8430 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 52/600\n",
            "1276/1276 - 12s - loss: 0.2541 - accuracy: 0.8430 - val_loss: 0.2521 - val_accuracy: 0.8439 - lr: 7.8125e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 53/600\n",
            "1276/1276 - 11s - loss: 0.2543 - accuracy: 0.8423 - val_loss: 0.2523 - val_accuracy: 0.8422 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 54/600\n",
            "1276/1276 - 11s - loss: 0.2541 - accuracy: 0.8429 - val_loss: 0.2521 - val_accuracy: 0.8425 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 55/600\n",
            "1276/1276 - 11s - loss: 0.2535 - accuracy: 0.8433 - val_loss: 0.2516 - val_accuracy: 0.8439 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 56/600\n",
            "1276/1276 - 13s - loss: 0.2534 - accuracy: 0.8436 - val_loss: 0.2513 - val_accuracy: 0.8432 - lr: 3.9062e-05 - 13s/epoch - 10ms/step\n",
            "Epoch 57/600\n",
            "1276/1276 - 11s - loss: 0.2534 - accuracy: 0.8416 - val_loss: 0.2514 - val_accuracy: 0.8429 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 58/600\n",
            "1276/1276 - 13s - loss: 0.2533 - accuracy: 0.8429 - val_loss: 0.2515 - val_accuracy: 0.8441 - lr: 3.9062e-05 - 13s/epoch - 10ms/step\n",
            "Epoch 59/600\n",
            "1276/1276 - 11s - loss: 0.2532 - accuracy: 0.8434 - val_loss: 0.2513 - val_accuracy: 0.8435 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 60/600\n",
            "1276/1276 - 11s - loss: 0.2529 - accuracy: 0.8423 - val_loss: 0.2510 - val_accuracy: 0.8408 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 61/600\n",
            "1276/1276 - 12s - loss: 0.2531 - accuracy: 0.8423 - val_loss: 0.2509 - val_accuracy: 0.8434 - lr: 1.9531e-05 - 12s/epoch - 10ms/step\n",
            "Epoch 62/600\n",
            "1276/1276 - 11s - loss: 0.2529 - accuracy: 0.8427 - val_loss: 0.2509 - val_accuracy: 0.8429 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 63/600\n",
            "1276/1276 - 12s - loss: 0.2528 - accuracy: 0.8425 - val_loss: 0.2509 - val_accuracy: 0.8433 - lr: 1.9531e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 64/600\n",
            "1276/1276 - 11s - loss: 0.2527 - accuracy: 0.8430 - val_loss: 0.2507 - val_accuracy: 0.8455 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 65/600\n",
            "1276/1276 - 11s - loss: 0.2527 - accuracy: 0.8432 - val_loss: 0.2507 - val_accuracy: 0.8445 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 66/600\n",
            "1276/1276 - 11s - loss: 0.2528 - accuracy: 0.8427 - val_loss: 0.2507 - val_accuracy: 0.8425 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 67/600\n",
            "1276/1276 - 11s - loss: 0.2527 - accuracy: 0.8432 - val_loss: 0.2506 - val_accuracy: 0.8410 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 68/600\n",
            "1276/1276 - 11s - loss: 0.2526 - accuracy: 0.8434 - val_loss: 0.2506 - val_accuracy: 0.8434 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 69/600\n",
            "1276/1276 - 11s - loss: 0.2526 - accuracy: 0.8435 - val_loss: 0.2505 - val_accuracy: 0.8442 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 70/600\n",
            "1276/1276 - 11s - loss: 0.2527 - accuracy: 0.8427 - val_loss: 0.2506 - val_accuracy: 0.8421 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 71/600\n",
            "1276/1276 - 11s - loss: 0.2524 - accuracy: 0.8431 - val_loss: 0.2503 - val_accuracy: 0.8441 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 72/600\n",
            "1276/1276 - 11s - loss: 0.2523 - accuracy: 0.8431 - val_loss: 0.2503 - val_accuracy: 0.8445 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 73/600\n",
            "1276/1276 - 12s - loss: 0.2523 - accuracy: 0.8436 - val_loss: 0.2502 - val_accuracy: 0.8428 - lr: 9.7656e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 74/600\n",
            "1276/1276 - 11s - loss: 0.2523 - accuracy: 0.8429 - val_loss: 0.2501 - val_accuracy: 0.8431 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 75/600\n",
            "1276/1276 - 12s - loss: 0.2523 - accuracy: 0.8429 - val_loss: 0.2501 - val_accuracy: 0.8419 - lr: 9.7656e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 76/600\n",
            "1276/1276 - 11s - loss: 0.2522 - accuracy: 0.8422 - val_loss: 0.2500 - val_accuracy: 0.8445 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 77/600\n",
            "1276/1276 - 13s - loss: 0.2522 - accuracy: 0.8430 - val_loss: 0.2501 - val_accuracy: 0.8422 - lr: 9.7656e-06 - 13s/epoch - 10ms/step\n",
            "Epoch 78/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8437 - val_loss: 0.2499 - val_accuracy: 0.8431 - lr: 4.8828e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 79/600\n",
            "1276/1276 - 12s - loss: 0.2520 - accuracy: 0.8436 - val_loss: 0.2499 - val_accuracy: 0.8429 - lr: 4.8828e-06 - 12s/epoch - 10ms/step\n",
            "Epoch 80/600\n",
            "1276/1276 - 11s - loss: 0.2518 - accuracy: 0.8435 - val_loss: 0.2499 - val_accuracy: 0.8431 - lr: 4.8828e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 81/600\n",
            "1276/1276 - 11s - loss: 0.2519 - accuracy: 0.8426 - val_loss: 0.2498 - val_accuracy: 0.8431 - lr: 4.8828e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 82/600\n",
            "1276/1276 - 12s - loss: 0.2518 - accuracy: 0.8438 - val_loss: 0.2498 - val_accuracy: 0.8437 - lr: 4.8828e-06 - 12s/epoch - 10ms/step\n",
            "Epoch 83/600\n",
            "1276/1276 - 12s - loss: 0.2518 - accuracy: 0.8444 - val_loss: 0.2498 - val_accuracy: 0.8436 - lr: 4.8828e-06 - 12s/epoch - 10ms/step\n",
            "Epoch 84/600\n",
            "1276/1276 - 12s - loss: 0.2518 - accuracy: 0.8434 - val_loss: 0.2497 - val_accuracy: 0.8431 - lr: 4.8828e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 85/600\n",
            "1276/1276 - 11s - loss: 0.2519 - accuracy: 0.8429 - val_loss: 0.2497 - val_accuracy: 0.8434 - lr: 2.4414e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 86/600\n",
            "1276/1276 - 11s - loss: 0.2518 - accuracy: 0.8434 - val_loss: 0.2497 - val_accuracy: 0.8425 - lr: 2.4414e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 87/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8440 - val_loss: 0.2497 - val_accuracy: 0.8427 - lr: 2.4414e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 88/600\n",
            "1276/1276 - 12s - loss: 0.2518 - accuracy: 0.8436 - val_loss: 0.2497 - val_accuracy: 0.8429 - lr: 2.4414e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 89/600\n",
            "1276/1276 - 11s - loss: 0.2516 - accuracy: 0.8432 - val_loss: 0.2497 - val_accuracy: 0.8426 - lr: 2.4414e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 90/600\n",
            "1276/1276 - 11s - loss: 0.2516 - accuracy: 0.8436 - val_loss: 0.2497 - val_accuracy: 0.8444 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 91/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8427 - val_loss: 0.2497 - val_accuracy: 0.8429 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 92/600\n",
            "1276/1276 - 11s - loss: 0.2518 - accuracy: 0.8422 - val_loss: 0.2497 - val_accuracy: 0.8434 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 93/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8437 - val_loss: 0.2496 - val_accuracy: 0.8431 - lr: 6.1035e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 94/600\n",
            "1276/1276 - 13s - loss: 0.2517 - accuracy: 0.8429 - val_loss: 0.2496 - val_accuracy: 0.8437 - lr: 6.1035e-07 - 13s/epoch - 10ms/step\n",
            "Epoch 95/600\n",
            "1276/1276 - 11s - loss: 0.2516 - accuracy: 0.8435 - val_loss: 0.2497 - val_accuracy: 0.8438 - lr: 6.1035e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 96/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8435 - val_loss: 0.2496 - val_accuracy: 0.8436 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 97/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8439 - val_loss: 0.2496 - val_accuracy: 0.8436 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 98/600\n",
            "1276/1276 - 12s - loss: 0.2515 - accuracy: 0.8439 - val_loss: 0.2496 - val_accuracy: 0.8441 - lr: 3.0518e-07 - 12s/epoch - 10ms/step\n",
            "Epoch 99/600\n",
            "1276/1276 - 11s - loss: 0.2518 - accuracy: 0.8419 - val_loss: 0.2496 - val_accuracy: 0.8441 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 100/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8430 - val_loss: 0.2496 - val_accuracy: 0.8441 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 101/600\n",
            "1276/1276 - 12s - loss: 0.2517 - accuracy: 0.8438 - val_loss: 0.2496 - val_accuracy: 0.8441 - lr: 1.5259e-07 - 12s/epoch - 10ms/step\n",
            "Epoch 102/600\n",
            "1276/1276 - 11s - loss: 0.2516 - accuracy: 0.8436 - val_loss: 0.2496 - val_accuracy: 0.8441 - lr: 7.6294e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 103/600\n",
            "1276/1276 - 11s - loss: 0.2516 - accuracy: 0.8436 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 7.6294e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 104/600\n",
            "1276/1276 - 12s - loss: 0.2518 - accuracy: 0.8431 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 7.6294e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 105/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8431 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 106/600\n",
            "1276/1276 - 11s - loss: 0.2518 - accuracy: 0.8436 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 107/600\n",
            "1276/1276 - 11s - loss: 0.2516 - accuracy: 0.8431 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 108/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8434 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 1.9073e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 109/600\n",
            "1276/1276 - 13s - loss: 0.2516 - accuracy: 0.8438 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 1.9073e-08 - 13s/epoch - 10ms/step\n",
            "Epoch 110/600\n",
            "1276/1276 - 11s - loss: 0.2515 - accuracy: 0.8433 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 1.9073e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 111/600\n",
            "1276/1276 - 11s - loss: 0.2516 - accuracy: 0.8436 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 9.5367e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 112/600\n",
            "1276/1276 - 11s - loss: 0.2516 - accuracy: 0.8435 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 9.5367e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 113/600\n",
            "1276/1276 - 11s - loss: 0.2515 - accuracy: 0.8435 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 9.5367e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 114/600\n",
            "1276/1276 - 12s - loss: 0.2518 - accuracy: 0.8433 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 4.7684e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 115/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8427 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 4.7684e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 116/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8432 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 4.7684e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 117/600\n",
            "1276/1276 - 11s - loss: 0.2516 - accuracy: 0.8430 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 2.3842e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 118/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8431 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 2.3842e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 119/600\n",
            "1276/1276 - 11s - loss: 0.2518 - accuracy: 0.8432 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 2.3842e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 120/600\n",
            "1276/1276 - 12s - loss: 0.2517 - accuracy: 0.8433 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 1.1921e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 121/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8428 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 1.1921e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 122/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8433 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 1.1921e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 123/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8433 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 5.9605e-10 - 11s/epoch - 9ms/step\n",
            "Epoch 124/600\n",
            "1276/1276 - 11s - loss: 0.2516 - accuracy: 0.8433 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 5.9605e-10 - 11s/epoch - 9ms/step\n",
            "Epoch 125/600\n",
            "1276/1276 - 11s - loss: 0.2516 - accuracy: 0.8442 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 5.9605e-10 - 11s/epoch - 9ms/step\n",
            "Epoch 126/600\n",
            "1276/1276 - 11s - loss: 0.2516 - accuracy: 0.8433 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 2.9802e-10 - 11s/epoch - 9ms/step\n",
            "Epoch 127/600\n",
            "1276/1276 - 11s - loss: 0.2516 - accuracy: 0.8435 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 2.9802e-10 - 11s/epoch - 9ms/step\n",
            "Epoch 128/600\n",
            "1276/1276 - 11s - loss: 0.2517 - accuracy: 0.8429 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 2.9802e-10 - 11s/epoch - 9ms/step\n",
            "Epoch 129/600\n",
            "1276/1276 - 11s - loss: 0.2515 - accuracy: 0.8440 - val_loss: 0.2496 - val_accuracy: 0.8438 - lr: 1.4901e-10 - 11s/epoch - 9ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " ...\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " ...\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12  2]\n",
            " ...\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ... 26 12  2]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 24]\n",
            " ...\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ...  2 11 20]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25 15]\n",
            " ...\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 20 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 23]\n",
            " ...\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 23]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 23 17  9]\n",
            " ...\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 23 17  1]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " ...\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  1 21 22]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " ...\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ... 22  3  8]\n",
            " [28 27 10 ... 22  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " ...\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " ...\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_10 (Bidirecti  (None, 128)              48128     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1274/1274 - 15s - loss: 0.6931 - accuracy: 0.7773 - val_loss: 0.3465 - val_accuracy: 0.8389 - lr: 0.0050 - 15s/epoch - 11ms/step\n",
            "Epoch 2/600\n",
            "1274/1274 - 10s - loss: 0.3768 - accuracy: 0.8309 - val_loss: 0.3209 - val_accuracy: 0.8382 - lr: 0.0050 - 10s/epoch - 8ms/step\n",
            "Epoch 3/600\n",
            "1274/1274 - 10s - loss: 0.4246 - accuracy: 0.8250 - val_loss: 0.3238 - val_accuracy: 0.8405 - lr: 0.0050 - 10s/epoch - 8ms/step\n",
            "Epoch 4/600\n",
            "1274/1274 - 10s - loss: 0.4590 - accuracy: 0.8275 - val_loss: 0.3539 - val_accuracy: 0.8389 - lr: 0.0050 - 10s/epoch - 8ms/step\n",
            "Epoch 5/600\n",
            "1274/1274 - 12s - loss: 0.3736 - accuracy: 0.8323 - val_loss: 0.3285 - val_accuracy: 0.8320 - lr: 0.0050 - 12s/epoch - 9ms/step\n",
            "Epoch 6/600\n",
            "1274/1274 - 10s - loss: 0.3091 - accuracy: 0.8355 - val_loss: 0.2961 - val_accuracy: 0.8413 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 7/600\n",
            "1274/1274 - 10s - loss: 0.3088 - accuracy: 0.8338 - val_loss: 0.2951 - val_accuracy: 0.8372 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 8/600\n",
            "1274/1274 - 10s - loss: 0.3340 - accuracy: 0.8321 - val_loss: 0.2937 - val_accuracy: 0.8392 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 9/600\n",
            "1274/1274 - 10s - loss: 0.3248 - accuracy: 0.8335 - val_loss: 0.3415 - val_accuracy: 0.8405 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 10/600\n",
            "1274/1274 - 10s - loss: 0.3009 - accuracy: 0.8359 - val_loss: 0.2902 - val_accuracy: 0.8390 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 11/600\n",
            "1274/1274 - 10s - loss: 0.3172 - accuracy: 0.8338 - val_loss: 0.2931 - val_accuracy: 0.8309 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 12/600\n",
            "1274/1274 - 10s - loss: 0.2938 - accuracy: 0.8364 - val_loss: 0.2870 - val_accuracy: 0.8335 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 13/600\n",
            "1274/1274 - 10s - loss: 0.3470 - accuracy: 0.8325 - val_loss: 0.3182 - val_accuracy: 0.8388 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 14/600\n",
            "1274/1274 - 10s - loss: 0.2989 - accuracy: 0.8357 - val_loss: 0.2849 - val_accuracy: 0.8374 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 15/600\n",
            "1274/1274 - 10s - loss: 0.3090 - accuracy: 0.8355 - val_loss: 0.2935 - val_accuracy: 0.8400 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 16/600\n",
            "1274/1274 - 10s - loss: 0.2939 - accuracy: 0.8363 - val_loss: 0.2889 - val_accuracy: 0.8393 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 17/600\n",
            "1274/1274 - 10s - loss: 0.3376 - accuracy: 0.8346 - val_loss: 0.3311 - val_accuracy: 0.8341 - lr: 0.0025 - 10s/epoch - 8ms/step\n",
            "Epoch 18/600\n",
            "1274/1274 - 10s - loss: 0.2935 - accuracy: 0.8391 - val_loss: 0.2781 - val_accuracy: 0.8403 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 19/600\n",
            "1274/1274 - 10s - loss: 0.2784 - accuracy: 0.8390 - val_loss: 0.2732 - val_accuracy: 0.8419 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 20/600\n",
            "1274/1274 - 10s - loss: 0.2743 - accuracy: 0.8388 - val_loss: 0.2707 - val_accuracy: 0.8398 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 21/600\n",
            "1274/1274 - 10s - loss: 0.2766 - accuracy: 0.8375 - val_loss: 0.2722 - val_accuracy: 0.8411 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 22/600\n",
            "1274/1274 - 10s - loss: 0.2831 - accuracy: 0.8367 - val_loss: 0.2703 - val_accuracy: 0.8385 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 23/600\n",
            "1274/1274 - 10s - loss: 0.2715 - accuracy: 0.8380 - val_loss: 0.2691 - val_accuracy: 0.8356 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 24/600\n",
            "1274/1274 - 11s - loss: 0.2869 - accuracy: 0.8369 - val_loss: 0.2700 - val_accuracy: 0.8387 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 25/600\n",
            "1274/1274 - 10s - loss: 0.2718 - accuracy: 0.8372 - val_loss: 0.2679 - val_accuracy: 0.8341 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 26/600\n",
            "1274/1274 - 10s - loss: 0.2709 - accuracy: 0.8381 - val_loss: 0.2666 - val_accuracy: 0.8397 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 27/600\n",
            "1274/1274 - 10s - loss: 0.2980 - accuracy: 0.8374 - val_loss: 0.2707 - val_accuracy: 0.8411 - lr: 0.0012 - 10s/epoch - 8ms/step\n",
            "Epoch 28/600\n",
            "1274/1274 - 11s - loss: 0.2706 - accuracy: 0.8384 - val_loss: 0.2672 - val_accuracy: 0.8408 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 29/600\n",
            "1274/1274 - 11s - loss: 0.2768 - accuracy: 0.8396 - val_loss: 0.2704 - val_accuracy: 0.8392 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 30/600\n",
            "1274/1274 - 10s - loss: 0.2656 - accuracy: 0.8412 - val_loss: 0.2625 - val_accuracy: 0.8392 - lr: 6.2500e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 31/600\n",
            "1274/1274 - 10s - loss: 0.2636 - accuracy: 0.8405 - val_loss: 0.2622 - val_accuracy: 0.8422 - lr: 6.2500e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 32/600\n",
            "1274/1274 - 10s - loss: 0.2637 - accuracy: 0.8398 - val_loss: 0.2615 - val_accuracy: 0.8397 - lr: 6.2500e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 33/600\n",
            "1274/1274 - 10s - loss: 0.2627 - accuracy: 0.8385 - val_loss: 0.2618 - val_accuracy: 0.8397 - lr: 6.2500e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 34/600\n",
            "1274/1274 - 11s - loss: 0.2663 - accuracy: 0.8387 - val_loss: 0.2598 - val_accuracy: 0.8405 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 35/600\n",
            "1274/1274 - 11s - loss: 0.2615 - accuracy: 0.8407 - val_loss: 0.2592 - val_accuracy: 0.8409 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 36/600\n",
            "1274/1274 - 10s - loss: 0.2626 - accuracy: 0.8407 - val_loss: 0.2589 - val_accuracy: 0.8410 - lr: 6.2500e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 37/600\n",
            "1274/1274 - 10s - loss: 0.2612 - accuracy: 0.8409 - val_loss: 0.2586 - val_accuracy: 0.8403 - lr: 6.2500e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 38/600\n",
            "1274/1274 - 10s - loss: 0.2615 - accuracy: 0.8414 - val_loss: 0.2594 - val_accuracy: 0.8402 - lr: 6.2500e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 39/600\n",
            "1274/1274 - 11s - loss: 0.2635 - accuracy: 0.8386 - val_loss: 0.2606 - val_accuracy: 0.8400 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 40/600\n",
            "1274/1274 - 10s - loss: 0.2619 - accuracy: 0.8399 - val_loss: 0.2588 - val_accuracy: 0.8404 - lr: 6.2500e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 41/600\n",
            "1274/1274 - 10s - loss: 0.2568 - accuracy: 0.8403 - val_loss: 0.2547 - val_accuracy: 0.8409 - lr: 3.1250e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 42/600\n",
            "1274/1274 - 10s - loss: 0.2568 - accuracy: 0.8408 - val_loss: 0.2560 - val_accuracy: 0.8413 - lr: 3.1250e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 43/600\n",
            "1274/1274 - 10s - loss: 0.2569 - accuracy: 0.8410 - val_loss: 0.2548 - val_accuracy: 0.8402 - lr: 3.1250e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 44/600\n",
            "1274/1274 - 10s - loss: 0.2562 - accuracy: 0.8413 - val_loss: 0.2545 - val_accuracy: 0.8397 - lr: 3.1250e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 45/600\n",
            "1274/1274 - 10s - loss: 0.2571 - accuracy: 0.8397 - val_loss: 0.2551 - val_accuracy: 0.8406 - lr: 3.1250e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 46/600\n",
            "1274/1274 - 10s - loss: 0.2558 - accuracy: 0.8408 - val_loss: 0.2549 - val_accuracy: 0.8398 - lr: 3.1250e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 47/600\n",
            "1274/1274 - 10s - loss: 0.2558 - accuracy: 0.8411 - val_loss: 0.2560 - val_accuracy: 0.8387 - lr: 3.1250e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 48/600\n",
            "1274/1274 - 11s - loss: 0.2538 - accuracy: 0.8411 - val_loss: 0.2528 - val_accuracy: 0.8393 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 49/600\n",
            "1274/1274 - 10s - loss: 0.2537 - accuracy: 0.8421 - val_loss: 0.2531 - val_accuracy: 0.8421 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 50/600\n",
            "1274/1274 - 10s - loss: 0.2537 - accuracy: 0.8412 - val_loss: 0.2523 - val_accuracy: 0.8400 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 51/600\n",
            "1274/1274 - 10s - loss: 0.2534 - accuracy: 0.8403 - val_loss: 0.2520 - val_accuracy: 0.8423 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 52/600\n",
            "1274/1274 - 10s - loss: 0.2532 - accuracy: 0.8410 - val_loss: 0.2521 - val_accuracy: 0.8411 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 53/600\n",
            "1274/1274 - 10s - loss: 0.2534 - accuracy: 0.8408 - val_loss: 0.2520 - val_accuracy: 0.8413 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 54/600\n",
            "1274/1274 - 10s - loss: 0.2530 - accuracy: 0.8413 - val_loss: 0.2516 - val_accuracy: 0.8409 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 55/600\n",
            "1274/1274 - 10s - loss: 0.2528 - accuracy: 0.8415 - val_loss: 0.2515 - val_accuracy: 0.8413 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 56/600\n",
            "1274/1274 - 10s - loss: 0.2528 - accuracy: 0.8411 - val_loss: 0.2513 - val_accuracy: 0.8411 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 57/600\n",
            "1274/1274 - 10s - loss: 0.2525 - accuracy: 0.8425 - val_loss: 0.2516 - val_accuracy: 0.8425 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 58/600\n",
            "1274/1274 - 10s - loss: 0.2525 - accuracy: 0.8417 - val_loss: 0.2508 - val_accuracy: 0.8423 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 59/600\n",
            "1274/1274 - 10s - loss: 0.2524 - accuracy: 0.8410 - val_loss: 0.2517 - val_accuracy: 0.8426 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 60/600\n",
            "1274/1274 - 10s - loss: 0.2524 - accuracy: 0.8415 - val_loss: 0.2507 - val_accuracy: 0.8410 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 61/600\n",
            "1274/1274 - 10s - loss: 0.2526 - accuracy: 0.8409 - val_loss: 0.2506 - val_accuracy: 0.8423 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 62/600\n",
            "1274/1274 - 10s - loss: 0.2523 - accuracy: 0.8412 - val_loss: 0.2529 - val_accuracy: 0.8403 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 63/600\n",
            "1274/1274 - 10s - loss: 0.2522 - accuracy: 0.8410 - val_loss: 0.2511 - val_accuracy: 0.8412 - lr: 1.5625e-04 - 10s/epoch - 8ms/step\n",
            "Epoch 64/600\n",
            "1274/1274 - 12s - loss: 0.2509 - accuracy: 0.8408 - val_loss: 0.2496 - val_accuracy: 0.8420 - lr: 7.8125e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 65/600\n",
            "1274/1274 - 10s - loss: 0.2513 - accuracy: 0.8396 - val_loss: 0.2495 - val_accuracy: 0.8418 - lr: 7.8125e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 66/600\n",
            "1274/1274 - 10s - loss: 0.2511 - accuracy: 0.8411 - val_loss: 0.2506 - val_accuracy: 0.8419 - lr: 7.8125e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 67/600\n",
            "1274/1274 - 10s - loss: 0.2508 - accuracy: 0.8413 - val_loss: 0.2500 - val_accuracy: 0.8420 - lr: 7.8125e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 68/600\n",
            "1274/1274 - 10s - loss: 0.2510 - accuracy: 0.8411 - val_loss: 0.2497 - val_accuracy: 0.8418 - lr: 7.8125e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 69/600\n",
            "1274/1274 - 10s - loss: 0.2503 - accuracy: 0.8409 - val_loss: 0.2493 - val_accuracy: 0.8420 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 70/600\n",
            "1274/1274 - 10s - loss: 0.2502 - accuracy: 0.8420 - val_loss: 0.2492 - val_accuracy: 0.8412 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 71/600\n",
            "1274/1274 - 10s - loss: 0.2502 - accuracy: 0.8415 - val_loss: 0.2491 - val_accuracy: 0.8418 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 72/600\n",
            "1274/1274 - 10s - loss: 0.2500 - accuracy: 0.8418 - val_loss: 0.2490 - val_accuracy: 0.8412 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 73/600\n",
            "1274/1274 - 10s - loss: 0.2501 - accuracy: 0.8411 - val_loss: 0.2496 - val_accuracy: 0.8422 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 74/600\n",
            "1274/1274 - 10s - loss: 0.2501 - accuracy: 0.8418 - val_loss: 0.2491 - val_accuracy: 0.8417 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 75/600\n",
            "1274/1274 - 10s - loss: 0.2501 - accuracy: 0.8417 - val_loss: 0.2491 - val_accuracy: 0.8426 - lr: 3.9062e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 76/600\n",
            "1274/1274 - 10s - loss: 0.2496 - accuracy: 0.8425 - val_loss: 0.2486 - val_accuracy: 0.8412 - lr: 1.9531e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 77/600\n",
            "1274/1274 - 10s - loss: 0.2496 - accuracy: 0.8418 - val_loss: 0.2487 - val_accuracy: 0.8422 - lr: 1.9531e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 78/600\n",
            "1274/1274 - 10s - loss: 0.2497 - accuracy: 0.8411 - val_loss: 0.2486 - val_accuracy: 0.8417 - lr: 1.9531e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 79/600\n",
            "1274/1274 - 10s - loss: 0.2495 - accuracy: 0.8416 - val_loss: 0.2486 - val_accuracy: 0.8420 - lr: 1.9531e-05 - 10s/epoch - 8ms/step\n",
            "Epoch 80/600\n",
            "1274/1274 - 10s - loss: 0.2496 - accuracy: 0.8414 - val_loss: 0.2485 - val_accuracy: 0.8419 - lr: 9.7656e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 81/600\n",
            "1274/1274 - 10s - loss: 0.2496 - accuracy: 0.8410 - val_loss: 0.2485 - val_accuracy: 0.8419 - lr: 9.7656e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 82/600\n",
            "1274/1274 - 10s - loss: 0.2495 - accuracy: 0.8414 - val_loss: 0.2485 - val_accuracy: 0.8424 - lr: 9.7656e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 83/600\n",
            "1274/1274 - 10s - loss: 0.2493 - accuracy: 0.8420 - val_loss: 0.2485 - val_accuracy: 0.8420 - lr: 9.7656e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 84/600\n",
            "1274/1274 - 10s - loss: 0.2492 - accuracy: 0.8423 - val_loss: 0.2484 - val_accuracy: 0.8420 - lr: 4.8828e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 85/600\n",
            "1274/1274 - 10s - loss: 0.2492 - accuracy: 0.8422 - val_loss: 0.2484 - val_accuracy: 0.8420 - lr: 4.8828e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 86/600\n",
            "1274/1274 - 10s - loss: 0.2494 - accuracy: 0.8417 - val_loss: 0.2484 - val_accuracy: 0.8420 - lr: 4.8828e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 87/600\n",
            "1274/1274 - 10s - loss: 0.2493 - accuracy: 0.8418 - val_loss: 0.2484 - val_accuracy: 0.8420 - lr: 4.8828e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 88/600\n",
            "1274/1274 - 10s - loss: 0.2493 - accuracy: 0.8416 - val_loss: 0.2484 - val_accuracy: 0.8420 - lr: 2.4414e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 89/600\n",
            "1274/1274 - 10s - loss: 0.2494 - accuracy: 0.8407 - val_loss: 0.2484 - val_accuracy: 0.8420 - lr: 2.4414e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 90/600\n",
            "1274/1274 - 10s - loss: 0.2493 - accuracy: 0.8413 - val_loss: 0.2484 - val_accuracy: 0.8420 - lr: 2.4414e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 91/600\n",
            "1274/1274 - 10s - loss: 0.2492 - accuracy: 0.8418 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 1.2207e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 92/600\n",
            "1274/1274 - 10s - loss: 0.2492 - accuracy: 0.8421 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 1.2207e-06 - 10s/epoch - 8ms/step\n",
            "Epoch 93/600\n",
            "1274/1274 - 11s - loss: 0.2491 - accuracy: 0.8428 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 94/600\n",
            "1274/1274 - 10s - loss: 0.2493 - accuracy: 0.8412 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 6.1035e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 95/600\n",
            "1274/1274 - 10s - loss: 0.2491 - accuracy: 0.8423 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 6.1035e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 96/600\n",
            "1274/1274 - 10s - loss: 0.2491 - accuracy: 0.8427 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 6.1035e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 97/600\n",
            "1274/1274 - 10s - loss: 0.2491 - accuracy: 0.8423 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 6.1035e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 98/600\n",
            "1274/1274 - 10s - loss: 0.2492 - accuracy: 0.8421 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 3.0518e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 99/600\n",
            "1274/1274 - 10s - loss: 0.2493 - accuracy: 0.8420 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 3.0518e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 100/600\n",
            "1274/1274 - 10s - loss: 0.2493 - accuracy: 0.8409 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 3.0518e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 101/600\n",
            "1274/1274 - 10s - loss: 0.2492 - accuracy: 0.8421 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 1.5259e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 102/600\n",
            "1274/1274 - 11s - loss: 0.2492 - accuracy: 0.8422 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 103/600\n",
            "1274/1274 - 10s - loss: 0.2493 - accuracy: 0.8417 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 1.5259e-07 - 10s/epoch - 8ms/step\n",
            "Epoch 104/600\n",
            "1274/1274 - 12s - loss: 0.2494 - accuracy: 0.8413 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 7.6294e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 105/600\n",
            "1274/1274 - 17s - loss: 0.2492 - accuracy: 0.8417 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 7.6294e-08 - 17s/epoch - 13ms/step\n",
            "Epoch 106/600\n",
            "1274/1274 - 14s - loss: 0.2492 - accuracy: 0.8422 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 7.6294e-08 - 14s/epoch - 11ms/step\n",
            "Epoch 107/600\n",
            "1274/1274 - 12s - loss: 0.2491 - accuracy: 0.8429 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 3.8147e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 108/600\n",
            "1274/1274 - 17s - loss: 0.2492 - accuracy: 0.8423 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 3.8147e-08 - 17s/epoch - 13ms/step\n",
            "Epoch 109/600\n",
            "1274/1274 - 17s - loss: 0.2493 - accuracy: 0.8424 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 3.8147e-08 - 17s/epoch - 13ms/step\n",
            "Epoch 110/600\n",
            "1274/1274 - 14s - loss: 0.2493 - accuracy: 0.8422 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 1.9073e-08 - 14s/epoch - 11ms/step\n",
            "Epoch 111/600\n",
            "1274/1274 - 16s - loss: 0.2492 - accuracy: 0.8424 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 1.9073e-08 - 16s/epoch - 12ms/step\n",
            "Epoch 112/600\n",
            "1274/1274 - 15s - loss: 0.2492 - accuracy: 0.8418 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 1.9073e-08 - 15s/epoch - 12ms/step\n",
            "Epoch 113/600\n",
            "1274/1274 - 14s - loss: 0.2491 - accuracy: 0.8419 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 9.5367e-09 - 14s/epoch - 11ms/step\n",
            "Epoch 114/600\n",
            "1274/1274 - 14s - loss: 0.2491 - accuracy: 0.8419 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 9.5367e-09 - 14s/epoch - 11ms/step\n",
            "Epoch 115/600\n",
            "1274/1274 - 14s - loss: 0.2492 - accuracy: 0.8417 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 9.5367e-09 - 14s/epoch - 11ms/step\n",
            "Epoch 116/600\n",
            "1274/1274 - 14s - loss: 0.2492 - accuracy: 0.8420 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 4.7684e-09 - 14s/epoch - 11ms/step\n",
            "Epoch 117/600\n",
            "1274/1274 - 13s - loss: 0.2492 - accuracy: 0.8416 - val_loss: 0.2483 - val_accuracy: 0.8420 - lr: 4.7684e-09 - 13s/epoch - 10ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16  6]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " ...\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " ...\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ...  6 12  2]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ...  6 12 14]\n",
            " ...\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12  2]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12  2 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 24]\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ... 14 11 20]\n",
            " ...\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ...  2 11 24]\n",
            " [28 27 10 ...  2 11 24]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 24 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 20 25 15]\n",
            " ...\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 24 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ... 15 18 13]\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ... 15 18 23]\n",
            " ...\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 13]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 23 17  9]\n",
            " ...\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  1]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  1 21 22]\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  9 21 22]\n",
            " ...\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  1 21  4]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " ...\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ... 22  3  8]\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ... 22  3  8]\n",
            " ...\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ...  4  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " ...\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " ...\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_11 (Bidirecti  (None, 128)              48128     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1282/1282 - 16s - loss: 0.6990 - accuracy: 0.7907 - val_loss: 0.3722 - val_accuracy: 0.8358 - lr: 0.0050 - 16s/epoch - 12ms/step\n",
            "Epoch 2/600\n",
            "1282/1282 - 11s - loss: 0.3826 - accuracy: 0.8326 - val_loss: 0.3320 - val_accuracy: 0.8384 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 3/600\n",
            "1282/1282 - 11s - loss: 0.4456 - accuracy: 0.8293 - val_loss: 0.3448 - val_accuracy: 0.8386 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 4/600\n",
            "1282/1282 - 11s - loss: 0.3726 - accuracy: 0.8320 - val_loss: 0.3248 - val_accuracy: 0.8347 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 5/600\n",
            "1282/1282 - 11s - loss: 0.3582 - accuracy: 0.8326 - val_loss: 0.3287 - val_accuracy: 0.8363 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 6/600\n",
            "1282/1282 - 11s - loss: 0.3633 - accuracy: 0.8324 - val_loss: 0.3196 - val_accuracy: 0.8376 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 7/600\n",
            "1282/1282 - 11s - loss: 0.3221 - accuracy: 0.8359 - val_loss: 0.3041 - val_accuracy: 0.8414 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 8/600\n",
            "1282/1282 - 11s - loss: 0.4524 - accuracy: 0.8267 - val_loss: 0.3265 - val_accuracy: 0.8327 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 9/600\n",
            "1282/1282 - 11s - loss: 0.3665 - accuracy: 0.8304 - val_loss: 0.4240 - val_accuracy: 0.8317 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 10/600\n",
            "1282/1282 - 11s - loss: 0.3246 - accuracy: 0.8358 - val_loss: 0.3064 - val_accuracy: 0.8366 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 11/600\n",
            "1282/1282 - 11s - loss: 0.2962 - accuracy: 0.8367 - val_loss: 0.2873 - val_accuracy: 0.8352 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 12/600\n",
            "1282/1282 - 11s - loss: 0.2947 - accuracy: 0.8353 - val_loss: 0.2837 - val_accuracy: 0.8399 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 13/600\n",
            "1282/1282 - 11s - loss: 0.3241 - accuracy: 0.8341 - val_loss: 0.2918 - val_accuracy: 0.8378 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 14/600\n",
            "1282/1282 - 11s - loss: 0.2916 - accuracy: 0.8375 - val_loss: 0.2818 - val_accuracy: 0.8355 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 15/600\n",
            "1282/1282 - 11s - loss: 0.3131 - accuracy: 0.8346 - val_loss: 0.2826 - val_accuracy: 0.8399 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 16/600\n",
            "1282/1282 - 11s - loss: 0.2869 - accuracy: 0.8358 - val_loss: 0.2820 - val_accuracy: 0.8412 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 17/600\n",
            "1282/1282 - 11s - loss: 0.3203 - accuracy: 0.8348 - val_loss: 0.2823 - val_accuracy: 0.8403 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 18/600\n",
            "1282/1282 - 11s - loss: 0.2759 - accuracy: 0.8385 - val_loss: 0.2713 - val_accuracy: 0.8354 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 19/600\n",
            "1282/1282 - 11s - loss: 0.2757 - accuracy: 0.8377 - val_loss: 0.2733 - val_accuracy: 0.8370 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 20/600\n",
            "1282/1282 - 11s - loss: 0.2766 - accuracy: 0.8382 - val_loss: 0.2675 - val_accuracy: 0.8426 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 21/600\n",
            "1282/1282 - 11s - loss: 0.2717 - accuracy: 0.8377 - val_loss: 0.2674 - val_accuracy: 0.8349 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 22/600\n",
            "1282/1282 - 11s - loss: 0.2779 - accuracy: 0.8376 - val_loss: 0.2668 - val_accuracy: 0.8404 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 23/600\n",
            "1282/1282 - 11s - loss: 0.2729 - accuracy: 0.8378 - val_loss: 0.2744 - val_accuracy: 0.8371 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 24/600\n",
            "1282/1282 - 11s - loss: 0.2707 - accuracy: 0.8371 - val_loss: 0.2660 - val_accuracy: 0.8397 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 25/600\n",
            "1282/1282 - 11s - loss: 0.2754 - accuracy: 0.8376 - val_loss: 0.2682 - val_accuracy: 0.8376 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 26/600\n",
            "1282/1282 - 11s - loss: 0.2684 - accuracy: 0.8376 - val_loss: 0.2645 - val_accuracy: 0.8397 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 27/600\n",
            "1282/1282 - 11s - loss: 0.2709 - accuracy: 0.8375 - val_loss: 0.2652 - val_accuracy: 0.8408 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 28/600\n",
            "1282/1282 - 11s - loss: 0.2877 - accuracy: 0.8369 - val_loss: 0.2662 - val_accuracy: 0.8395 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 29/600\n",
            "1282/1282 - 11s - loss: 0.2689 - accuracy: 0.8371 - val_loss: 0.2644 - val_accuracy: 0.8397 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 30/600\n",
            "1282/1282 - 11s - loss: 0.2623 - accuracy: 0.8383 - val_loss: 0.2600 - val_accuracy: 0.8367 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 31/600\n",
            "1282/1282 - 11s - loss: 0.2622 - accuracy: 0.8390 - val_loss: 0.2587 - val_accuracy: 0.8404 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 32/600\n",
            "1282/1282 - 11s - loss: 0.2631 - accuracy: 0.8384 - val_loss: 0.2588 - val_accuracy: 0.8428 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 33/600\n",
            "1282/1282 - 11s - loss: 0.2635 - accuracy: 0.8381 - val_loss: 0.2605 - val_accuracy: 0.8400 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 34/600\n",
            "1282/1282 - 11s - loss: 0.2612 - accuracy: 0.8381 - val_loss: 0.2598 - val_accuracy: 0.8412 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 35/600\n",
            "1282/1282 - 11s - loss: 0.2578 - accuracy: 0.8404 - val_loss: 0.2551 - val_accuracy: 0.8400 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 36/600\n",
            "1282/1282 - 11s - loss: 0.2584 - accuracy: 0.8388 - val_loss: 0.2554 - val_accuracy: 0.8423 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 37/600\n",
            "1282/1282 - 11s - loss: 0.2575 - accuracy: 0.8386 - val_loss: 0.2545 - val_accuracy: 0.8419 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 38/600\n",
            "1282/1282 - 11s - loss: 0.2573 - accuracy: 0.8390 - val_loss: 0.2549 - val_accuracy: 0.8402 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 39/600\n",
            "1282/1282 - 11s - loss: 0.2570 - accuracy: 0.8401 - val_loss: 0.2546 - val_accuracy: 0.8401 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 40/600\n",
            "1282/1282 - 11s - loss: 0.2574 - accuracy: 0.8392 - val_loss: 0.2541 - val_accuracy: 0.8414 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 41/600\n",
            "1282/1282 - 11s - loss: 0.2568 - accuracy: 0.8391 - val_loss: 0.2538 - val_accuracy: 0.8410 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 42/600\n",
            "1282/1282 - 11s - loss: 0.2570 - accuracy: 0.8395 - val_loss: 0.2551 - val_accuracy: 0.8387 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 43/600\n",
            "1282/1282 - 11s - loss: 0.2564 - accuracy: 0.8395 - val_loss: 0.2545 - val_accuracy: 0.8374 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 44/600\n",
            "1282/1282 - 11s - loss: 0.2567 - accuracy: 0.8396 - val_loss: 0.2539 - val_accuracy: 0.8411 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 45/600\n",
            "1282/1282 - 11s - loss: 0.2546 - accuracy: 0.8396 - val_loss: 0.2522 - val_accuracy: 0.8397 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 46/600\n",
            "1282/1282 - 11s - loss: 0.2544 - accuracy: 0.8395 - val_loss: 0.2518 - val_accuracy: 0.8425 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 47/600\n",
            "1282/1282 - 11s - loss: 0.2544 - accuracy: 0.8389 - val_loss: 0.2520 - val_accuracy: 0.8421 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 48/600\n",
            "1282/1282 - 12s - loss: 0.2541 - accuracy: 0.8399 - val_loss: 0.2517 - val_accuracy: 0.8425 - lr: 1.5625e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 49/600\n",
            "1282/1282 - 11s - loss: 0.2542 - accuracy: 0.8400 - val_loss: 0.2518 - val_accuracy: 0.8418 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 50/600\n",
            "1282/1282 - 11s - loss: 0.2541 - accuracy: 0.8398 - val_loss: 0.2521 - val_accuracy: 0.8401 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 51/600\n",
            "1282/1282 - 11s - loss: 0.2538 - accuracy: 0.8407 - val_loss: 0.2518 - val_accuracy: 0.8414 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 52/600\n",
            "1282/1282 - 11s - loss: 0.2530 - accuracy: 0.8405 - val_loss: 0.2509 - val_accuracy: 0.8429 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 53/600\n",
            "1282/1282 - 11s - loss: 0.2529 - accuracy: 0.8413 - val_loss: 0.2509 - val_accuracy: 0.8415 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 54/600\n",
            "1282/1282 - 11s - loss: 0.2528 - accuracy: 0.8406 - val_loss: 0.2509 - val_accuracy: 0.8417 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 55/600\n",
            "1282/1282 - 11s - loss: 0.2528 - accuracy: 0.8403 - val_loss: 0.2507 - val_accuracy: 0.8392 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 56/600\n",
            "1282/1282 - 11s - loss: 0.2528 - accuracy: 0.8402 - val_loss: 0.2508 - val_accuracy: 0.8410 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 57/600\n",
            "1282/1282 - 11s - loss: 0.2528 - accuracy: 0.8400 - val_loss: 0.2507 - val_accuracy: 0.8415 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 58/600\n",
            "1282/1282 - 11s - loss: 0.2526 - accuracy: 0.8407 - val_loss: 0.2508 - val_accuracy: 0.8403 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 59/600\n",
            "1282/1282 - 11s - loss: 0.2520 - accuracy: 0.8411 - val_loss: 0.2503 - val_accuracy: 0.8419 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 60/600\n",
            "1282/1282 - 11s - loss: 0.2521 - accuracy: 0.8413 - val_loss: 0.2503 - val_accuracy: 0.8419 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 61/600\n",
            "1282/1282 - 11s - loss: 0.2521 - accuracy: 0.8399 - val_loss: 0.2501 - val_accuracy: 0.8402 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 62/600\n",
            "1282/1282 - 11s - loss: 0.2519 - accuracy: 0.8407 - val_loss: 0.2501 - val_accuracy: 0.8415 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 63/600\n",
            "1282/1282 - 11s - loss: 0.2521 - accuracy: 0.8395 - val_loss: 0.2501 - val_accuracy: 0.8398 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 64/600\n",
            "1282/1282 - 11s - loss: 0.2521 - accuracy: 0.8403 - val_loss: 0.2501 - val_accuracy: 0.8403 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 65/600\n",
            "1282/1282 - 11s - loss: 0.2517 - accuracy: 0.8411 - val_loss: 0.2499 - val_accuracy: 0.8413 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 66/600\n",
            "1282/1282 - 11s - loss: 0.2517 - accuracy: 0.8408 - val_loss: 0.2499 - val_accuracy: 0.8402 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 67/600\n",
            "1282/1282 - 11s - loss: 0.2517 - accuracy: 0.8405 - val_loss: 0.2499 - val_accuracy: 0.8394 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 68/600\n",
            "1282/1282 - 11s - loss: 0.2517 - accuracy: 0.8411 - val_loss: 0.2499 - val_accuracy: 0.8404 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 69/600\n",
            "1282/1282 - 11s - loss: 0.2516 - accuracy: 0.8407 - val_loss: 0.2498 - val_accuracy: 0.8399 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 70/600\n",
            "1282/1282 - 11s - loss: 0.2515 - accuracy: 0.8413 - val_loss: 0.2497 - val_accuracy: 0.8397 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 71/600\n",
            "1282/1282 - 11s - loss: 0.2517 - accuracy: 0.8410 - val_loss: 0.2497 - val_accuracy: 0.8401 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 72/600\n",
            "1282/1282 - 11s - loss: 0.2516 - accuracy: 0.8410 - val_loss: 0.2497 - val_accuracy: 0.8392 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 73/600\n",
            "1282/1282 - 11s - loss: 0.2516 - accuracy: 0.8400 - val_loss: 0.2497 - val_accuracy: 0.8396 - lr: 4.8828e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 74/600\n",
            "1282/1282 - 11s - loss: 0.2515 - accuracy: 0.8405 - val_loss: 0.2497 - val_accuracy: 0.8396 - lr: 4.8828e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 75/600\n",
            "1282/1282 - 11s - loss: 0.2515 - accuracy: 0.8402 - val_loss: 0.2497 - val_accuracy: 0.8396 - lr: 4.8828e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 76/600\n",
            "1282/1282 - 11s - loss: 0.2515 - accuracy: 0.8403 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 2.4414e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 77/600\n",
            "1282/1282 - 11s - loss: 0.2513 - accuracy: 0.8411 - val_loss: 0.2497 - val_accuracy: 0.8399 - lr: 2.4414e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 78/600\n",
            "1282/1282 - 11s - loss: 0.2514 - accuracy: 0.8405 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 2.4414e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 79/600\n",
            "1282/1282 - 11s - loss: 0.2514 - accuracy: 0.8411 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 2.4414e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 80/600\n",
            "1282/1282 - 11s - loss: 0.2514 - accuracy: 0.8413 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 81/600\n",
            "1282/1282 - 11s - loss: 0.2513 - accuracy: 0.8408 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 82/600\n",
            "1282/1282 - 11s - loss: 0.2514 - accuracy: 0.8407 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 83/600\n",
            "1282/1282 - 11s - loss: 0.2514 - accuracy: 0.8409 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 6.1035e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 84/600\n",
            "1282/1282 - 11s - loss: 0.2513 - accuracy: 0.8409 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 6.1035e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 85/600\n",
            "1282/1282 - 11s - loss: 0.2514 - accuracy: 0.8411 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 6.1035e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 86/600\n",
            "1282/1282 - 11s - loss: 0.2513 - accuracy: 0.8414 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 87/600\n",
            "1282/1282 - 11s - loss: 0.2513 - accuracy: 0.8411 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 88/600\n",
            "1282/1282 - 11s - loss: 0.2513 - accuracy: 0.8414 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 89/600\n",
            "1282/1282 - 11s - loss: 0.2514 - accuracy: 0.8405 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 90/600\n",
            "1282/1282 - 11s - loss: 0.2513 - accuracy: 0.8403 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 1.5259e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 91/600\n",
            "1282/1282 - 11s - loss: 0.2513 - accuracy: 0.8415 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 92/600\n",
            "1282/1282 - 11s - loss: 0.2513 - accuracy: 0.8408 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 7.6294e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 93/600\n",
            "1282/1282 - 11s - loss: 0.2513 - accuracy: 0.8408 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 7.6294e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 94/600\n",
            "1282/1282 - 11s - loss: 0.2515 - accuracy: 0.8402 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 7.6294e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 95/600\n",
            "1282/1282 - 11s - loss: 0.2514 - accuracy: 0.8414 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 96/600\n",
            "1282/1282 - 11s - loss: 0.2513 - accuracy: 0.8415 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 97/600\n",
            "1282/1282 - 11s - loss: 0.2514 - accuracy: 0.8412 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 98/600\n",
            "1282/1282 - 11s - loss: 0.2513 - accuracy: 0.8404 - val_loss: 0.2496 - val_accuracy: 0.8396 - lr: 1.9073e-08 - 11s/epoch - 9ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " ...\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16  6]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " ...\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16  6 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ...  6 12 14]\n",
            " ...\n",
            " [28 27 10 ...  6 12  2]\n",
            " [28 27 10 ...  6 12 14]\n",
            " [28 27 10 ...  6 12  2]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " ...\n",
            " [28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ... 14 11 24]\n",
            " ...\n",
            " [28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ...  2 11 20]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 24 25 15]\n",
            " ...\n",
            " [28 27 10 ... 20 25  7]\n",
            " [28 27 10 ... 24 25 15]\n",
            " [28 27 10 ... 20 25  7]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ... 15 18 13]\n",
            " ...\n",
            " [28 27 10 ...  7 18 13]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ...  7 18 13]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 13 17]\n",
            " ...\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 13 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  9]\n",
            " [28 27 10 ... 13 17  1]\n",
            " ...\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 13 17  1]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " ...\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  1 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  1 21 22]\n",
            " ...\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  1 21  4]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " ...\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ... 22  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  8]\n",
            " ...\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  8]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " ...\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  8 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " ...\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  8 19 29]]\n",
            "(12800, 21)\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_12 (Bidirecti  (None, 128)              48128     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 29)                3741      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,869\n",
            "Trainable params: 51,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1293/1293 - 16s - loss: 0.6759 - accuracy: 0.7914 - val_loss: 0.3580 - val_accuracy: 0.8326 - lr: 0.0050 - 16s/epoch - 12ms/step\n",
            "Epoch 2/600\n",
            "1293/1293 - 11s - loss: 0.4351 - accuracy: 0.8296 - val_loss: 1.1772 - val_accuracy: 0.7730 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 3/600\n",
            "1293/1293 - 11s - loss: 0.4001 - accuracy: 0.8357 - val_loss: 0.3164 - val_accuracy: 0.8380 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 4/600\n",
            "1293/1293 - 11s - loss: 0.3895 - accuracy: 0.8341 - val_loss: 0.3071 - val_accuracy: 0.8395 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 5/600\n",
            "1293/1293 - 11s - loss: 0.5742 - accuracy: 0.8294 - val_loss: 0.3946 - val_accuracy: 0.8400 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 6/600\n",
            "1293/1293 - 12s - loss: 0.3826 - accuracy: 0.8348 - val_loss: 0.3140 - val_accuracy: 0.8389 - lr: 0.0050 - 12s/epoch - 10ms/step\n",
            "Epoch 7/600\n",
            "1293/1293 - 11s - loss: 0.3548 - accuracy: 0.8366 - val_loss: 0.3109 - val_accuracy: 0.8404 - lr: 0.0050 - 11s/epoch - 9ms/step\n",
            "Epoch 8/600\n",
            "1293/1293 - 11s - loss: 0.2973 - accuracy: 0.8380 - val_loss: 0.3012 - val_accuracy: 0.8402 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 9/600\n",
            "1293/1293 - 11s - loss: 0.3029 - accuracy: 0.8382 - val_loss: 0.2866 - val_accuracy: 0.8378 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 10/600\n",
            "1293/1293 - 11s - loss: 0.3635 - accuracy: 0.8353 - val_loss: 0.3101 - val_accuracy: 0.8398 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 11/600\n",
            "1293/1293 - 11s - loss: 0.2992 - accuracy: 0.8398 - val_loss: 0.2867 - val_accuracy: 0.8373 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 12/600\n",
            "1293/1293 - 11s - loss: 0.3164 - accuracy: 0.8379 - val_loss: 0.2845 - val_accuracy: 0.8398 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 13/600\n",
            "1293/1293 - 11s - loss: 0.2874 - accuracy: 0.8396 - val_loss: 0.2848 - val_accuracy: 0.8389 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 14/600\n",
            "1293/1293 - 11s - loss: 0.3221 - accuracy: 0.8372 - val_loss: 0.2874 - val_accuracy: 0.8418 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 15/600\n",
            "1293/1293 - 11s - loss: 0.2838 - accuracy: 0.8401 - val_loss: 0.2791 - val_accuracy: 0.8385 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 16/600\n",
            "1293/1293 - 11s - loss: 0.3452 - accuracy: 0.8369 - val_loss: 0.2916 - val_accuracy: 0.8396 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 17/600\n",
            "1293/1293 - 11s - loss: 0.2863 - accuracy: 0.8395 - val_loss: 0.2783 - val_accuracy: 0.8392 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 18/600\n",
            "1293/1293 - 11s - loss: 0.3057 - accuracy: 0.8380 - val_loss: 0.2825 - val_accuracy: 0.8418 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 19/600\n",
            "1293/1293 - 11s - loss: 0.2829 - accuracy: 0.8389 - val_loss: 0.2795 - val_accuracy: 0.8410 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 20/600\n",
            "1293/1293 - 11s - loss: 0.3074 - accuracy: 0.8382 - val_loss: 0.2795 - val_accuracy: 0.8393 - lr: 0.0025 - 11s/epoch - 9ms/step\n",
            "Epoch 21/600\n",
            "1293/1293 - 11s - loss: 0.2718 - accuracy: 0.8392 - val_loss: 0.2666 - val_accuracy: 0.8391 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 22/600\n",
            "1293/1293 - 11s - loss: 0.2695 - accuracy: 0.8404 - val_loss: 0.2674 - val_accuracy: 0.8364 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 23/600\n",
            "1293/1293 - 11s - loss: 0.2766 - accuracy: 0.8399 - val_loss: 0.2645 - val_accuracy: 0.8402 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 24/600\n",
            "1293/1293 - 11s - loss: 0.2683 - accuracy: 0.8405 - val_loss: 0.2656 - val_accuracy: 0.8388 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 25/600\n",
            "1293/1293 - 11s - loss: 0.2745 - accuracy: 0.8402 - val_loss: 0.2629 - val_accuracy: 0.8398 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 26/600\n",
            "1293/1293 - 11s - loss: 0.2726 - accuracy: 0.8398 - val_loss: 0.3940 - val_accuracy: 0.8395 - lr: 0.0012 - 11s/epoch - 9ms/step\n",
            "Epoch 27/600\n",
            "1293/1293 - 11s - loss: 0.2771 - accuracy: 0.8407 - val_loss: 0.2637 - val_accuracy: 0.8401 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 28/600\n",
            "1293/1293 - 11s - loss: 0.2652 - accuracy: 0.8394 - val_loss: 0.2666 - val_accuracy: 0.8384 - lr: 0.0012 - 11s/epoch - 8ms/step\n",
            "Epoch 29/600\n",
            "1293/1293 - 11s - loss: 0.2595 - accuracy: 0.8410 - val_loss: 0.2576 - val_accuracy: 0.8411 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 30/600\n",
            "1293/1293 - 11s - loss: 0.2591 - accuracy: 0.8402 - val_loss: 0.2592 - val_accuracy: 0.8405 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 31/600\n",
            "1293/1293 - 11s - loss: 0.2637 - accuracy: 0.8403 - val_loss: 0.2559 - val_accuracy: 0.8395 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 32/600\n",
            "1293/1293 - 11s - loss: 0.2584 - accuracy: 0.8401 - val_loss: 0.2556 - val_accuracy: 0.8409 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 33/600\n",
            "1293/1293 - 11s - loss: 0.2586 - accuracy: 0.8392 - val_loss: 0.2558 - val_accuracy: 0.8418 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 34/600\n",
            "1293/1293 - 11s - loss: 0.2597 - accuracy: 0.8408 - val_loss: 0.2553 - val_accuracy: 0.8397 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 35/600\n",
            "1293/1293 - 11s - loss: 0.2581 - accuracy: 0.8412 - val_loss: 0.2558 - val_accuracy: 0.8405 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 36/600\n",
            "1293/1293 - 11s - loss: 0.2605 - accuracy: 0.8398 - val_loss: 0.2553 - val_accuracy: 0.8385 - lr: 6.2500e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 37/600\n",
            "1293/1293 - 11s - loss: 0.2608 - accuracy: 0.8402 - val_loss: 0.2561 - val_accuracy: 0.8380 - lr: 6.2500e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 38/600\n",
            "1293/1293 - 11s - loss: 0.2543 - accuracy: 0.8404 - val_loss: 0.2520 - val_accuracy: 0.8402 - lr: 3.1250e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 39/600\n",
            "1293/1293 - 11s - loss: 0.2539 - accuracy: 0.8405 - val_loss: 0.2519 - val_accuracy: 0.8379 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 40/600\n",
            "1293/1293 - 12s - loss: 0.2539 - accuracy: 0.8407 - val_loss: 0.2520 - val_accuracy: 0.8395 - lr: 3.1250e-04 - 12s/epoch - 9ms/step\n",
            "Epoch 41/600\n",
            "1293/1293 - 11s - loss: 0.2538 - accuracy: 0.8402 - val_loss: 0.2519 - val_accuracy: 0.8382 - lr: 3.1250e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 42/600\n",
            "1293/1293 - 11s - loss: 0.2537 - accuracy: 0.8408 - val_loss: 0.2523 - val_accuracy: 0.8415 - lr: 3.1250e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 43/600\n",
            "1293/1293 - 11s - loss: 0.2517 - accuracy: 0.8403 - val_loss: 0.2497 - val_accuracy: 0.8416 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 44/600\n",
            "1293/1293 - 11s - loss: 0.2513 - accuracy: 0.8422 - val_loss: 0.2508 - val_accuracy: 0.8423 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 45/600\n",
            "1293/1293 - 11s - loss: 0.2514 - accuracy: 0.8410 - val_loss: 0.2494 - val_accuracy: 0.8401 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 46/600\n",
            "1293/1293 - 11s - loss: 0.2514 - accuracy: 0.8402 - val_loss: 0.2493 - val_accuracy: 0.8416 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 47/600\n",
            "1293/1293 - 11s - loss: 0.2512 - accuracy: 0.8409 - val_loss: 0.2494 - val_accuracy: 0.8404 - lr: 1.5625e-04 - 11s/epoch - 8ms/step\n",
            "Epoch 48/600\n",
            "1293/1293 - 11s - loss: 0.2512 - accuracy: 0.8413 - val_loss: 0.2496 - val_accuracy: 0.8404 - lr: 1.5625e-04 - 11s/epoch - 9ms/step\n",
            "Epoch 49/600\n",
            "1293/1293 - 11s - loss: 0.2502 - accuracy: 0.8399 - val_loss: 0.2483 - val_accuracy: 0.8412 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 50/600\n",
            "1293/1293 - 11s - loss: 0.2499 - accuracy: 0.8410 - val_loss: 0.2484 - val_accuracy: 0.8400 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 51/600\n",
            "1293/1293 - 11s - loss: 0.2498 - accuracy: 0.8411 - val_loss: 0.2483 - val_accuracy: 0.8396 - lr: 7.8125e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 52/600\n",
            "1293/1293 - 11s - loss: 0.2499 - accuracy: 0.8403 - val_loss: 0.2487 - val_accuracy: 0.8404 - lr: 7.8125e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 53/600\n",
            "1293/1293 - 11s - loss: 0.2494 - accuracy: 0.8404 - val_loss: 0.2480 - val_accuracy: 0.8406 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 54/600\n",
            "1293/1293 - 11s - loss: 0.2493 - accuracy: 0.8405 - val_loss: 0.2480 - val_accuracy: 0.8406 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 55/600\n",
            "1293/1293 - 11s - loss: 0.2492 - accuracy: 0.8413 - val_loss: 0.2478 - val_accuracy: 0.8399 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 56/600\n",
            "1293/1293 - 11s - loss: 0.2493 - accuracy: 0.8411 - val_loss: 0.2477 - val_accuracy: 0.8417 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 57/600\n",
            "1293/1293 - 11s - loss: 0.2491 - accuracy: 0.8409 - val_loss: 0.2479 - val_accuracy: 0.8393 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 58/600\n",
            "1293/1293 - 11s - loss: 0.2492 - accuracy: 0.8406 - val_loss: 0.2477 - val_accuracy: 0.8398 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 59/600\n",
            "1293/1293 - 11s - loss: 0.2492 - accuracy: 0.8412 - val_loss: 0.2478 - val_accuracy: 0.8402 - lr: 3.9062e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 60/600\n",
            "1293/1293 - 11s - loss: 0.2489 - accuracy: 0.8415 - val_loss: 0.2474 - val_accuracy: 0.8400 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 61/600\n",
            "1293/1293 - 12s - loss: 0.2488 - accuracy: 0.8408 - val_loss: 0.2475 - val_accuracy: 0.8400 - lr: 1.9531e-05 - 12s/epoch - 9ms/step\n",
            "Epoch 62/600\n",
            "1293/1293 - 11s - loss: 0.2488 - accuracy: 0.8416 - val_loss: 0.2473 - val_accuracy: 0.8404 - lr: 1.9531e-05 - 11s/epoch - 9ms/step\n",
            "Epoch 63/600\n",
            "1293/1293 - 11s - loss: 0.2486 - accuracy: 0.8404 - val_loss: 0.2474 - val_accuracy: 0.8404 - lr: 1.9531e-05 - 11s/epoch - 8ms/step\n",
            "Epoch 64/600\n",
            "1293/1293 - 11s - loss: 0.2487 - accuracy: 0.8426 - val_loss: 0.2473 - val_accuracy: 0.8406 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 65/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8419 - val_loss: 0.2474 - val_accuracy: 0.8406 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 66/600\n",
            "1293/1293 - 12s - loss: 0.2485 - accuracy: 0.8423 - val_loss: 0.2472 - val_accuracy: 0.8408 - lr: 9.7656e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 67/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8417 - val_loss: 0.2473 - val_accuracy: 0.8407 - lr: 9.7656e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 68/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8417 - val_loss: 0.2472 - val_accuracy: 0.8405 - lr: 9.7656e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 69/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8414 - val_loss: 0.2472 - val_accuracy: 0.8406 - lr: 9.7656e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 70/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8412 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 4.8828e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 71/600\n",
            "1293/1293 - 11s - loss: 0.2484 - accuracy: 0.8415 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 4.8828e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 72/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8416 - val_loss: 0.2472 - val_accuracy: 0.8406 - lr: 4.8828e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 73/600\n",
            "1293/1293 - 11s - loss: 0.2484 - accuracy: 0.8414 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 2.4414e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 74/600\n",
            "1293/1293 - 11s - loss: 0.2486 - accuracy: 0.8409 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 2.4414e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 75/600\n",
            "1293/1293 - 12s - loss: 0.2483 - accuracy: 0.8426 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 2.4414e-06 - 12s/epoch - 9ms/step\n",
            "Epoch 76/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8412 - val_loss: 0.2472 - val_accuracy: 0.8406 - lr: 2.4414e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 77/600\n",
            "1293/1293 - 11s - loss: 0.2483 - accuracy: 0.8423 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 78/600\n",
            "1293/1293 - 11s - loss: 0.2484 - accuracy: 0.8418 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 1.2207e-06 - 11s/epoch - 9ms/step\n",
            "Epoch 79/600\n",
            "1293/1293 - 11s - loss: 0.2484 - accuracy: 0.8411 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 1.2207e-06 - 11s/epoch - 8ms/step\n",
            "Epoch 80/600\n",
            "1293/1293 - 11s - loss: 0.2484 - accuracy: 0.8415 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 6.1035e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 81/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8414 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 6.1035e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 82/600\n",
            "1293/1293 - 11s - loss: 0.2483 - accuracy: 0.8420 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 6.1035e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 83/600\n",
            "1293/1293 - 11s - loss: 0.2484 - accuracy: 0.8409 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 84/600\n",
            "1293/1293 - 11s - loss: 0.2483 - accuracy: 0.8419 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 3.0518e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 85/600\n",
            "1293/1293 - 11s - loss: 0.2483 - accuracy: 0.8421 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 3.0518e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 86/600\n",
            "1293/1293 - 11s - loss: 0.2482 - accuracy: 0.8418 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 87/600\n",
            "1293/1293 - 11s - loss: 0.2483 - accuracy: 0.8426 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 1.5259e-07 - 11s/epoch - 9ms/step\n",
            "Epoch 88/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8407 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 1.5259e-07 - 11s/epoch - 8ms/step\n",
            "Epoch 89/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8413 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 7.6294e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 90/600\n",
            "1293/1293 - 12s - loss: 0.2484 - accuracy: 0.8413 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 7.6294e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 91/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8418 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 7.6294e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 92/600\n",
            "1293/1293 - 11s - loss: 0.2483 - accuracy: 0.8420 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 93/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8410 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 3.8147e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 94/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8413 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 3.8147e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 95/600\n",
            "1293/1293 - 12s - loss: 0.2484 - accuracy: 0.8409 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 1.9073e-08 - 12s/epoch - 9ms/step\n",
            "Epoch 96/600\n",
            "1293/1293 - 11s - loss: 0.2483 - accuracy: 0.8412 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 1.9073e-08 - 11s/epoch - 8ms/step\n",
            "Epoch 97/600\n",
            "1293/1293 - 11s - loss: 0.2483 - accuracy: 0.8422 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 1.9073e-08 - 11s/epoch - 9ms/step\n",
            "Epoch 98/600\n",
            "1293/1293 - 11s - loss: 0.2484 - accuracy: 0.8413 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 9.5367e-09 - 11s/epoch - 8ms/step\n",
            "Epoch 99/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8405 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 9.5367e-09 - 11s/epoch - 8ms/step\n",
            "Epoch 100/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8407 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 9.5367e-09 - 11s/epoch - 8ms/step\n",
            "Epoch 101/600\n",
            "1293/1293 - 11s - loss: 0.2484 - accuracy: 0.8418 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 4.7684e-09 - 11s/epoch - 8ms/step\n",
            "Epoch 102/600\n",
            "1293/1293 - 11s - loss: 0.2484 - accuracy: 0.8405 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 4.7684e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 103/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8424 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 4.7684e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 104/600\n",
            "1293/1293 - 12s - loss: 0.2483 - accuracy: 0.8418 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 2.3842e-09 - 12s/epoch - 9ms/step\n",
            "Epoch 105/600\n",
            "1293/1293 - 11s - loss: 0.2484 - accuracy: 0.8413 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 2.3842e-09 - 11s/epoch - 9ms/step\n",
            "Epoch 106/600\n",
            "1293/1293 - 11s - loss: 0.2483 - accuracy: 0.8420 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 2.3842e-09 - 11s/epoch - 8ms/step\n",
            "Epoch 107/600\n",
            "1293/1293 - 11s - loss: 0.2485 - accuracy: 0.8410 - val_loss: 0.2471 - val_accuracy: 0.8406 - lr: 1.1921e-09 - 11s/epoch - 9ms/step\n",
            "[[28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " ...\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]\n",
            " [28  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[28]\n",
            " [28]\n",
            " [28]\n",
            " ...\n",
            " [28]\n",
            " [28]\n",
            " [28]]\n",
            "finding activity nr 3\n",
            "[[28 27]\n",
            " [28 27]\n",
            " [28 27]\n",
            " ...\n",
            " [28 27]\n",
            " [28 27]\n",
            " [28 27]]\n",
            "finding activity nr 4\n",
            "[[28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " ...\n",
            " [28 27 10]\n",
            " [28 27 10]\n",
            " [28 27 10]]\n",
            "finding activity nr 5\n",
            "[[28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " ...\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]\n",
            " [28 27 10 16]]\n",
            "finding activity nr 6\n",
            "[[28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16 26]\n",
            " ...\n",
            " [28 27 10 16 26]\n",
            " [28 27 10 16  6]\n",
            " [28 27 10 16 26]]\n",
            "finding activity nr 7\n",
            "[[28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16 26 12]\n",
            " ...\n",
            " [28 27 10 16 26 12]\n",
            " [28 27 10 16  6 12]\n",
            " [28 27 10 16 26 12]]\n",
            "finding activity nr 8\n",
            "[[28 27 10 ... 26 12  2]\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ... 26 12  2]\n",
            " ...\n",
            " [28 27 10 ... 26 12 14]\n",
            " [28 27 10 ...  6 12 14]\n",
            " [28 27 10 ... 26 12 14]]\n",
            "finding activity nr 9\n",
            "[[28 27 10 ... 12  2 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12  2 11]\n",
            " ...\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]\n",
            " [28 27 10 ... 12 14 11]]\n",
            "finding activity nr 10\n",
            "[[28 27 10 ...  2 11 20]\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ...  2 11 24]\n",
            " ...\n",
            " [28 27 10 ... 14 11 20]\n",
            " [28 27 10 ... 14 11 24]\n",
            " [28 27 10 ... 14 11 20]]\n",
            "finding activity nr 11\n",
            "[[28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " ...\n",
            " [28 27 10 ... 11 20 25]\n",
            " [28 27 10 ... 11 24 25]\n",
            " [28 27 10 ... 11 20 25]]\n",
            "finding activity nr 12\n",
            "[[28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 24 25 15]\n",
            " ...\n",
            " [28 27 10 ... 20 25 15]\n",
            " [28 27 10 ... 24 25  7]\n",
            " [28 27 10 ... 20 25 15]]\n",
            "finding activity nr 13\n",
            "[[28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25 15 18]\n",
            " ...\n",
            " [28 27 10 ... 25 15 18]\n",
            " [28 27 10 ... 25  7 18]\n",
            " [28 27 10 ... 25 15 18]]\n",
            "finding activity nr 14\n",
            "[[28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 23]\n",
            " [28 27 10 ... 15 18 23]\n",
            " ...\n",
            " [28 27 10 ... 15 18 13]\n",
            " [28 27 10 ...  7 18 23]\n",
            " [28 27 10 ... 15 18 23]]\n",
            "finding activity nr 15\n",
            "[[28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " ...\n",
            " [28 27 10 ... 18 13 17]\n",
            " [28 27 10 ... 18 23 17]\n",
            " [28 27 10 ... 18 23 17]]\n",
            "finding activity nr 16\n",
            "[[28 27 10 ... 23 17  1]\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  9]\n",
            " ...\n",
            " [28 27 10 ... 13 17  1]\n",
            " [28 27 10 ... 23 17  9]\n",
            " [28 27 10 ... 23 17  9]]\n",
            "finding activity nr 17\n",
            "[[28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " ...\n",
            " [28 27 10 ... 17  1 21]\n",
            " [28 27 10 ... 17  9 21]\n",
            " [28 27 10 ... 17  9 21]]\n",
            "finding activity nr 18\n",
            "[[28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21 22]\n",
            " [28 27 10 ...  9 21  4]\n",
            " ...\n",
            " [28 27 10 ...  1 21  4]\n",
            " [28 27 10 ...  9 21  4]\n",
            " [28 27 10 ...  9 21  4]]\n",
            "finding activity nr 19\n",
            "[[28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21 22  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " ...\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]\n",
            " [28 27 10 ... 21  4  3]]\n",
            "finding activity nr 20\n",
            "[[28 27 10 ...  4  3  5]\n",
            " [28 27 10 ... 22  3  5]\n",
            " [28 27 10 ...  4  3  5]\n",
            " ...\n",
            " [28 27 10 ...  4  3  5]\n",
            " [28 27 10 ...  4  3  8]\n",
            " [28 27 10 ...  4  3  5]]\n",
            "finding activity nr 21\n",
            "[[28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  5 19]\n",
            " ...\n",
            " [28 27 10 ...  3  5 19]\n",
            " [28 27 10 ...  3  8 19]\n",
            " [28 27 10 ...  3  5 19]]\n",
            "[[28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  5 19 29]\n",
            " ...\n",
            " [28 27 10 ...  5 19 29]\n",
            " [28 27 10 ...  8 19 29]\n",
            " [28 27 10 ...  5 19 29]]\n",
            "(12800, 21)\n"
          ]
        }
      ],
      "source": [
        "do_experiment('Model3', 5, True, 0, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVAQfSTZYbYG"
      },
      "outputs": [],
      "source": [
        "do_experiment('Model3', 4, True, 0, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdUa7PnsYeGx"
      },
      "outputs": [],
      "source": [
        "do_experiment('Model3', 3, True, 0, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LlOI06jYeJt"
      },
      "outputs": [],
      "source": [
        "do_experiment('Model3', 2, True, 0, 128)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Fold3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}