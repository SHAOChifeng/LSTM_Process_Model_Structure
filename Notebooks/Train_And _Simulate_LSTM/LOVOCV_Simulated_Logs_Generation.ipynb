{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsIsBxKIh8KI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f5ff7c-053e-46ca-946c-e76a23f36dfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jR-hJZyEh4Un"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Bidirectional, LSTM, Activation, Dropout, Embedding, Input\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "import math\n",
        "\n",
        "import os.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8L--oQhLiAPZ"
      },
      "outputs": [],
      "source": [
        "def save_log(loglist, filename): #save a list of lists \n",
        "  df = pd.DataFrame.from_records(loglist)\n",
        "  df.to_csv(filename, index=False)\n",
        "\n",
        "def remove_nan(lists):\n",
        "  newlists = []\n",
        "  for tr in lists:\n",
        "    newlists.append([int(x) for x in tr if str(x) != 'nan'])\n",
        "  return(newlists)\n",
        "\n",
        "def import_log(filepath):\n",
        "  df = pd.read_csv(filepath)\n",
        "  return(remove_nan(df.values.tolist()))\n",
        "\n",
        "\n",
        "\n",
        "def number_to_one_hot_X(X, dict_size): #if we want \n",
        "  newX = []\n",
        "  for example in X:\n",
        "    new_ex = []\n",
        "    for i in range(len(example)):\n",
        "      onehot = [0]*dict_size #changed\n",
        "      if example[i] != 0:\n",
        "        onehot[example[i] - 1] = 1 #-1 because begin counting at 0\n",
        "      new_ex.append(onehot)\n",
        "    newX.append(new_ex)\n",
        "  return(np.array(newX))\n",
        "\n",
        "def create_XY_prefix(log, mappingsize, prefixlen):\n",
        "  X = []\n",
        "  Y = []\n",
        "  for i in range(0, len(log)):\n",
        "    for k in range(1, len(log[i])):\n",
        "      X.append(log[i][max(0, k-prefixlen):k]) #get the prefix of 'encoded' activities\n",
        "      y = [0] *(mappingsize)\n",
        "      y[int(log[i][k])-1] = 1\n",
        "      Y.append(y)        \n",
        "  X = keras.preprocessing.sequence.pad_sequences(X, maxlen=prefixlen, padding='pre')\n",
        "  X = number_to_one_hot_X(X, mappingsize)\n",
        "  return(np.array(X), np.array(Y))\n",
        "\n",
        "def get_startend(log): \n",
        "  return log[0][0], log[0][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uM3vmwb2iAXd"
      },
      "outputs": [],
      "source": [
        "def get_model(maxlen, num_chars, bidirec, n_layers, lstmsize, dropout, l1, l2):\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=(maxlen, num_chars))) #If you don't use an embedding layer input should be one-hot-encoded\n",
        "  if bidirec == False:   \n",
        "    model.add(LSTM(lstmsize,kernel_initializer='glorot_uniform',return_sequences=(n_layers != 1),kernel_regularizer=regularizers.l1_l2(l1,l2),\n",
        "                   recurrent_regularizer=regularizers.l1_l2(l1,l2),input_shape=(maxlen, num_chars)))\n",
        "    model.add(Dropout(dropout))\n",
        "    for i in range(1, n_layers):\n",
        "      return_sequences = (i+1 != n_layers)\n",
        "      model.add(LSTM(lstmsize,kernel_initializer='glorot_uniform',return_sequences=return_sequences,\n",
        "                     kernel_regularizer=regularizers.l1_l2(l1,l2),recurrent_regularizer=regularizers.l1_l2(l1,l2)))\n",
        "      model.add(Dropout(dropout))\n",
        "  else:\n",
        "    model.add(Bidirectional(LSTM(lstmsize,kernel_initializer='glorot_uniform',return_sequences=(n_layers != 1),kernel_regularizer=regularizers.l1_l2(l1,l2),\n",
        "                   recurrent_regularizer=regularizers.l1_l2(l1,l2),input_shape=(maxlen, num_chars))))\n",
        "    model.add(Dropout(dropout))\n",
        "    for i in range(1, n_layers):\n",
        "      return_sequences = (i+1 != n_layers)\n",
        "      model.add(Bidirectional(LSTM(lstmsize,kernel_initializer='glorot_uniform',return_sequences=return_sequences,\n",
        "                     kernel_regularizer=regularizers.l1_l2(l1,l2),recurrent_regularizer=regularizers.l1_l2(l1,l2))))\n",
        "      model.add(Dropout(dropout))\n",
        "  model.add(Dense(num_chars, kernel_initializer='glorot_uniform',activation='softmax'))\n",
        "  opt = Adam(learning_rate=0.005)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics='accuracy')\n",
        "  return model\n",
        "\n",
        "\n",
        "def train_model(X_train, y_train,batch_size, maxlen, num_chars, bidirec, n_layers, lstmsize, dropout, l1, l2):\n",
        "  model = get_model(maxlen, num_chars, bidirec, n_layers, lstmsize, dropout, l1, l2)\n",
        "  model.summary()\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
        "  lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "  #train_model\n",
        "  history = model.fit(X_train, y_train, validation_split=0.2, callbacks=[early_stopping, lr_reducer], batch_size=batch_size, epochs=600, verbose=2)\n",
        "  return model\n",
        "\n",
        "def cut_end(log, endact):\n",
        "  logsize, tracesize = log.shape\n",
        "  print(log.shape)\n",
        "  newlog = []\n",
        "  for i in range(0, logsize):\n",
        "    trace = []\n",
        "    for j in range(0, tracesize):\n",
        "      if log[i][j] == endact:\n",
        "        trace.append(log[i][j])\n",
        "        break\n",
        "      else:\n",
        "        trace.append(log[i][j])\n",
        "    newlog.append(trace)\n",
        "  return(newlog)\n",
        "\n",
        "def normalize(probs): #normalize probabilities to sum to 1\n",
        "  examplesize, actsize = probs.shape\n",
        "  newy = []\n",
        "  for i in range(examplesize):\n",
        "    normalizer = 1 / float( sum(probs[i]) )\n",
        "    ynorm = [float(l) * normalizer for l in probs[i]]\n",
        "    newy.append(ynorm)\n",
        "  return newy\n",
        "\n",
        "\n",
        "def choose_act_all(all_y): #randomly choose an activity, stochastically\n",
        "  #p want a list of probabilities    \n",
        "  chosen_acts = []\n",
        "  for i in range(len(all_y)):\n",
        "      chosen_acts.append(np.random.choice(np.arange(0, len(all_y[i])), p=all_y[i])+1)  \n",
        "  return(chosen_acts)   # +1 because number encodig starts at 1 not 0\n",
        "\n",
        "def OHget_probabilities(rnnmodel, xlists,  nr_act, maxlen, prefixlen):\n",
        "  #assume xlist is a list with the x (prefix) untill now \n",
        "  all_x = keras.preprocessing.sequence.pad_sequences(xlists, maxlen=maxlen, padding=\"pre\")\n",
        "  all_x = all_x[:,-(prefixlen):]\n",
        "  all_x = number_to_one_hot_X(all_x, nr_act)\n",
        "  results = rnnmodel.predict(all_x)\n",
        "  return results\n",
        "\n",
        "def OHsimulate_log(RNNmodel, logsize, startact, endact, maxlen, mapping, prefixlen): #Use RNN to simulate log\n",
        "  log = np.zeros((logsize, maxlen+1), int)\n",
        "  for i in range(0, logsize): #start every trace with the start activity\n",
        "    log[i][0] = startact\n",
        "  print(log)\n",
        "  for j in range(1,maxlen+1): #check if 0 or 1 and ml or ml - 1 #we took 50 for with loops   \n",
        "    print(\"finding activity nr\", j+1)   \n",
        "    prefixes = np.array([log[i][0:j] for i in range(0, logsize)])\n",
        "    print(prefixes)\n",
        "    probs = OHget_probabilities(RNNmodel, prefixes, len(mapping), maxlen, prefixlen)\n",
        "    #we need to do this because otherwise probabilities sum over 1 \n",
        "    ynorm = normalize(probs) \n",
        "    nextacts = choose_act_all(ynorm) \n",
        "    for i in range(0, logsize):\n",
        "      log[i][j] = nextacts[i]\n",
        "  print(log)\n",
        "  corrected_log = cut_end(log, endact)      \n",
        "  return(corrected_log) \n",
        "\n",
        "\n",
        "def do_experiment(modelname, full_prefix, opt_prefixlen, number_of_variants):\n",
        "  path = '/content/drive/MyDrive/Experiment2/Original/'+modelname +\"/\"\n",
        "  full_log = remove_nan(import_log(path+\"Log_\"+modelname+\".csv\"))\n",
        "\n",
        "  maxlen = len(max(full_log,key=len))\n",
        "  #if we want to use the full prefix each time or not\n",
        "  if full_prefix == True:\n",
        "    prefixlen=maxlen - 1\n",
        "    print(\"prefix length:\", prefixlen)\n",
        "  else:\n",
        "    prefixlen=opt_prefixlen\n",
        "\n",
        "  #reload mapping\n",
        "  mappingfilename = path+\"Mapping_\"+modelname+\".txt\"\n",
        "  with open(mappingfilename) as f:\n",
        "    mapping = json.loads(f.read())\n",
        "\n",
        "  batch_size = 128\n",
        "\n",
        "  for i in range(0, number_of_variants):\n",
        "    SimLogPath = path + \"Simulated_Logs/Sim\"+str(i)+\".csv\"\n",
        "    if os.path.exists(SimLogPath):\n",
        "      print(\"Already done: \", i)\n",
        "      continue\n",
        "    train_log = import_log(path + \"Training_Logs/Train\"+str(i)+\".csv\")\n",
        "    start,end = get_startend(train_log)\n",
        "    X_train, y_train = create_XY_prefix(train_log, len(mapping), prefixlen)\n",
        "    model = train_model(X_train, y_train,batch_size, maxlen=prefixlen, num_chars=len(mapping), bidirec=True, n_layers=1, lstmsize=64, dropout=0.4, l1=0.001, l2=0.001)\n",
        "\n",
        "    simlog = OHsimulate_log(model, number_of_variants*100, start, end, maxlen-1, mapping, prefixlen)\n",
        "    \n",
        "    save_log(simlog, SimLogPath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9Vy8PyfiAb4",
        "outputId": "a70349da-af55-4dc6-f406-04a5d9e88727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1042/1042 - 13s - loss: 0.3654 - accuracy: 0.8073 - val_loss: 0.3608 - val_accuracy: 0.8065 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 74/600\n",
            "1042/1042 - 13s - loss: 0.3655 - accuracy: 0.8079 - val_loss: 0.3607 - val_accuracy: 0.8065 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 75/600\n",
            "1042/1042 - 13s - loss: 0.3654 - accuracy: 0.8076 - val_loss: 0.3608 - val_accuracy: 0.8059 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 76/600\n",
            "1042/1042 - 13s - loss: 0.3653 - accuracy: 0.8073 - val_loss: 0.3608 - val_accuracy: 0.8059 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 77/600\n",
            "1042/1042 - 13s - loss: 0.3655 - accuracy: 0.8081 - val_loss: 0.3608 - val_accuracy: 0.8061 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 78/600\n",
            "1042/1042 - 13s - loss: 0.3653 - accuracy: 0.8086 - val_loss: 0.3608 - val_accuracy: 0.8061 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 79/600\n",
            "1042/1042 - 13s - loss: 0.3654 - accuracy: 0.8076 - val_loss: 0.3608 - val_accuracy: 0.8059 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 80/600\n",
            "1042/1042 - 13s - loss: 0.3654 - accuracy: 0.8064 - val_loss: 0.3608 - val_accuracy: 0.8059 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12  1]\n",
            " [14 11  3  2 12  1]\n",
            " [14 11  3  2 12 13]\n",
            " ...\n",
            " [14 11  3  2 12  9]\n",
            " [14 11  3  2 12  7]\n",
            " [14 11  3  2 12 13]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12  1 13]\n",
            " [14 11  3 ... 12  1 13]\n",
            " [14 11  3 ... 12 13  9]\n",
            " ...\n",
            " [14 11  3 ... 12  9  7]\n",
            " [14 11  3 ... 12  7 13]\n",
            " [14 11  3 ... 12 13  9]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ...  1 13  5]\n",
            " [14 11  3 ...  1 13  5]\n",
            " [14 11  3 ... 13  9  1]\n",
            " ...\n",
            " [14 11  3 ...  9  7  5]\n",
            " [14 11  3 ...  7 13  1]\n",
            " [14 11  3 ... 13  9  7]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ... 13  5  7]\n",
            " [14 11  3 ... 13  5  7]\n",
            " [14 11  3 ...  9  1  5]\n",
            " ...\n",
            " [14 11  3 ...  7  5  1]\n",
            " [14 11  3 ... 13  1  9]\n",
            " [14 11  3 ...  9  7  5]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ...  5  7  9]\n",
            " [14 11  3 ...  5  7  9]\n",
            " [14 11  3 ...  1  5  7]\n",
            " ...\n",
            " [14 11  3 ...  5  1 13]\n",
            " [14 11  3 ...  1  9  5]\n",
            " [14 11  3 ...  7  5  1]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ...  7  9  8]\n",
            " [14 11  3 ...  7  9  8]\n",
            " [14 11  3 ...  5  7  8]\n",
            " ...\n",
            " [14 11  3 ...  1 13  8]\n",
            " [14 11  3 ...  9  5  8]\n",
            " [14 11  3 ...  5  1  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  7  8 10]\n",
            " ...\n",
            " [14 11  3 ... 13  8 10]\n",
            " [14 11  3 ...  5  8 10]\n",
            " [14 11  3 ...  1  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_37 (Bidirecti  (None, 128)              40960     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,895\n",
            "Trainable params: 42,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1041/1041 - 18s - loss: 0.7151 - accuracy: 0.7863 - val_loss: 0.4778 - val_accuracy: 0.8066 - lr: 0.0050 - 18s/epoch - 17ms/step\n",
            "Epoch 2/600\n",
            "1041/1041 - 13s - loss: 0.4822 - accuracy: 0.8065 - val_loss: 0.4630 - val_accuracy: 0.8065 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 3/600\n",
            "1041/1041 - 13s - loss: 0.4639 - accuracy: 0.8069 - val_loss: 0.4611 - val_accuracy: 0.8048 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 4/600\n",
            "1041/1041 - 13s - loss: 0.4578 - accuracy: 0.8067 - val_loss: 0.4291 - val_accuracy: 0.8074 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 5/600\n",
            "1041/1041 - 13s - loss: 0.4540 - accuracy: 0.8063 - val_loss: 0.4306 - val_accuracy: 0.8053 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 6/600\n",
            "1041/1041 - 13s - loss: 0.4495 - accuracy: 0.8071 - val_loss: 0.4297 - val_accuracy: 0.8071 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 7/600\n",
            "1041/1041 - 13s - loss: 0.4906 - accuracy: 0.8048 - val_loss: 0.4592 - val_accuracy: 0.8060 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 8/600\n",
            "1041/1041 - 13s - loss: 0.4221 - accuracy: 0.8064 - val_loss: 0.4103 - val_accuracy: 0.8059 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 9/600\n",
            "1041/1041 - 13s - loss: 0.4149 - accuracy: 0.8070 - val_loss: 0.4000 - val_accuracy: 0.8076 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 10/600\n",
            "1041/1041 - 13s - loss: 0.4152 - accuracy: 0.8064 - val_loss: 0.3970 - val_accuracy: 0.8054 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 11/600\n",
            "1041/1041 - 13s - loss: 0.4143 - accuracy: 0.8060 - val_loss: 0.3999 - val_accuracy: 0.8070 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 12/600\n",
            "1041/1041 - 13s - loss: 0.4127 - accuracy: 0.8054 - val_loss: 0.4006 - val_accuracy: 0.8076 - lr: 0.0025 - 13s/epoch - 13ms/step\n",
            "Epoch 13/600\n",
            "1041/1041 - 13s - loss: 0.4124 - accuracy: 0.8057 - val_loss: 0.3972 - val_accuracy: 0.8057 - lr: 0.0025 - 13s/epoch - 13ms/step\n",
            "Epoch 14/600\n",
            "1041/1041 - 13s - loss: 0.3954 - accuracy: 0.8061 - val_loss: 0.3868 - val_accuracy: 0.8054 - lr: 0.0012 - 13s/epoch - 13ms/step\n",
            "Epoch 15/600\n",
            "1041/1041 - 13s - loss: 0.3948 - accuracy: 0.8066 - val_loss: 0.3826 - val_accuracy: 0.8075 - lr: 0.0012 - 13s/epoch - 13ms/step\n",
            "Epoch 16/600\n",
            "1041/1041 - 13s - loss: 0.3938 - accuracy: 0.8058 - val_loss: 0.3855 - val_accuracy: 0.8039 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 17/600\n",
            "1041/1041 - 13s - loss: 0.3941 - accuracy: 0.8050 - val_loss: 0.3862 - val_accuracy: 0.8065 - lr: 0.0012 - 13s/epoch - 13ms/step\n",
            "Epoch 18/600\n",
            "1041/1041 - 13s - loss: 0.3928 - accuracy: 0.8054 - val_loss: 0.3812 - val_accuracy: 0.8053 - lr: 0.0012 - 13s/epoch - 13ms/step\n",
            "Epoch 19/600\n",
            "1041/1041 - 13s - loss: 0.3922 - accuracy: 0.8062 - val_loss: 0.3813 - val_accuracy: 0.8052 - lr: 0.0012 - 13s/epoch - 13ms/step\n",
            "Epoch 20/600\n",
            "1041/1041 - 13s - loss: 0.3924 - accuracy: 0.8062 - val_loss: 0.3818 - val_accuracy: 0.8057 - lr: 0.0012 - 13s/epoch - 13ms/step\n",
            "Epoch 21/600\n",
            "1041/1041 - 13s - loss: 0.3911 - accuracy: 0.8064 - val_loss: 0.3794 - val_accuracy: 0.8079 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 22/600\n",
            "1041/1041 - 13s - loss: 0.3913 - accuracy: 0.8058 - val_loss: 0.3828 - val_accuracy: 0.8059 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 23/600\n",
            "1041/1041 - 13s - loss: 0.3906 - accuracy: 0.8072 - val_loss: 0.3824 - val_accuracy: 0.8069 - lr: 0.0012 - 13s/epoch - 13ms/step\n",
            "Epoch 24/600\n",
            "1041/1041 - 13s - loss: 0.3914 - accuracy: 0.8063 - val_loss: 0.3831 - val_accuracy: 0.8072 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 25/600\n",
            "1041/1041 - 13s - loss: 0.3806 - accuracy: 0.8064 - val_loss: 0.3773 - val_accuracy: 0.8067 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 26/600\n",
            "1041/1041 - 13s - loss: 0.3803 - accuracy: 0.8063 - val_loss: 0.3741 - val_accuracy: 0.8051 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 27/600\n",
            "1041/1041 - 13s - loss: 0.3799 - accuracy: 0.8062 - val_loss: 0.3720 - val_accuracy: 0.8072 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 28/600\n",
            "1041/1041 - 13s - loss: 0.3793 - accuracy: 0.8066 - val_loss: 0.3723 - val_accuracy: 0.8067 - lr: 6.2500e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 29/600\n",
            "1041/1041 - 13s - loss: 0.3797 - accuracy: 0.8075 - val_loss: 0.3729 - val_accuracy: 0.8049 - lr: 6.2500e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 30/600\n",
            "1041/1041 - 13s - loss: 0.3791 - accuracy: 0.8064 - val_loss: 0.3709 - val_accuracy: 0.8065 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 31/600\n",
            "1041/1041 - 13s - loss: 0.3791 - accuracy: 0.8066 - val_loss: 0.3722 - val_accuracy: 0.8063 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 32/600\n",
            "1041/1041 - 13s - loss: 0.3789 - accuracy: 0.8055 - val_loss: 0.3730 - val_accuracy: 0.8069 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 33/600\n",
            "1041/1041 - 13s - loss: 0.3781 - accuracy: 0.8072 - val_loss: 0.3716 - val_accuracy: 0.8072 - lr: 6.2500e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 34/600\n",
            "1041/1041 - 13s - loss: 0.3729 - accuracy: 0.8065 - val_loss: 0.3657 - val_accuracy: 0.8061 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 35/600\n",
            "1041/1041 - 13s - loss: 0.3724 - accuracy: 0.8061 - val_loss: 0.3669 - val_accuracy: 0.8061 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 36/600\n",
            "1041/1041 - 13s - loss: 0.3723 - accuracy: 0.8070 - val_loss: 0.3670 - val_accuracy: 0.8049 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 37/600\n",
            "1041/1041 - 13s - loss: 0.3723 - accuracy: 0.8069 - val_loss: 0.3675 - val_accuracy: 0.8061 - lr: 3.1250e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 38/600\n",
            "1041/1041 - 13s - loss: 0.3692 - accuracy: 0.8061 - val_loss: 0.3634 - val_accuracy: 0.8070 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 39/600\n",
            "1041/1041 - 13s - loss: 0.3687 - accuracy: 0.8066 - val_loss: 0.3637 - val_accuracy: 0.8063 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 40/600\n",
            "1041/1041 - 13s - loss: 0.3685 - accuracy: 0.8067 - val_loss: 0.3631 - val_accuracy: 0.8059 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 41/600\n",
            "1041/1041 - 13s - loss: 0.3682 - accuracy: 0.8060 - val_loss: 0.3630 - val_accuracy: 0.8079 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 42/600\n",
            "1041/1041 - 13s - loss: 0.3683 - accuracy: 0.8067 - val_loss: 0.3630 - val_accuracy: 0.8053 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 43/600\n",
            "1041/1041 - 13s - loss: 0.3683 - accuracy: 0.8063 - val_loss: 0.3637 - val_accuracy: 0.8073 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 44/600\n",
            "1041/1041 - 13s - loss: 0.3679 - accuracy: 0.8075 - val_loss: 0.3635 - val_accuracy: 0.8058 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 45/600\n",
            "1041/1041 - 13s - loss: 0.3664 - accuracy: 0.8067 - val_loss: 0.3621 - val_accuracy: 0.8066 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 46/600\n",
            "1041/1041 - 13s - loss: 0.3662 - accuracy: 0.8058 - val_loss: 0.3616 - val_accuracy: 0.8087 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 47/600\n",
            "1041/1041 - 13s - loss: 0.3661 - accuracy: 0.8060 - val_loss: 0.3615 - val_accuracy: 0.8056 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 48/600\n",
            "1041/1041 - 13s - loss: 0.3659 - accuracy: 0.8062 - val_loss: 0.3621 - val_accuracy: 0.8078 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 49/600\n",
            "1041/1041 - 13s - loss: 0.3659 - accuracy: 0.8065 - val_loss: 0.3618 - val_accuracy: 0.8071 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 50/600\n",
            "1041/1041 - 13s - loss: 0.3649 - accuracy: 0.8068 - val_loss: 0.3611 - val_accuracy: 0.8070 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 51/600\n",
            "1041/1041 - 13s - loss: 0.3648 - accuracy: 0.8074 - val_loss: 0.3607 - val_accuracy: 0.8054 - lr: 3.9062e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 52/600\n",
            "1041/1041 - 13s - loss: 0.3647 - accuracy: 0.8069 - val_loss: 0.3607 - val_accuracy: 0.8071 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 53/600\n",
            "1041/1041 - 13s - loss: 0.3646 - accuracy: 0.8072 - val_loss: 0.3611 - val_accuracy: 0.8063 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 54/600\n",
            "1041/1041 - 13s - loss: 0.3648 - accuracy: 0.8070 - val_loss: 0.3606 - val_accuracy: 0.8061 - lr: 3.9062e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 55/600\n",
            "1041/1041 - 13s - loss: 0.3644 - accuracy: 0.8069 - val_loss: 0.3603 - val_accuracy: 0.8063 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 56/600\n",
            "1041/1041 - 13s - loss: 0.3642 - accuracy: 0.8064 - val_loss: 0.3601 - val_accuracy: 0.8075 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 57/600\n",
            "1041/1041 - 13s - loss: 0.3641 - accuracy: 0.8076 - val_loss: 0.3603 - val_accuracy: 0.8060 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 58/600\n",
            "1041/1041 - 13s - loss: 0.3642 - accuracy: 0.8077 - val_loss: 0.3601 - val_accuracy: 0.8052 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 59/600\n",
            "1041/1041 - 13s - loss: 0.3640 - accuracy: 0.8068 - val_loss: 0.3601 - val_accuracy: 0.8076 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 60/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8081 - val_loss: 0.3600 - val_accuracy: 0.8066 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 61/600\n",
            "1041/1041 - 13s - loss: 0.3637 - accuracy: 0.8067 - val_loss: 0.3599 - val_accuracy: 0.8077 - lr: 9.7656e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 62/600\n",
            "1041/1041 - 13s - loss: 0.3637 - accuracy: 0.8080 - val_loss: 0.3601 - val_accuracy: 0.8057 - lr: 9.7656e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 63/600\n",
            "1041/1041 - 13s - loss: 0.3637 - accuracy: 0.8081 - val_loss: 0.3600 - val_accuracy: 0.8058 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 64/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8071 - val_loss: 0.3599 - val_accuracy: 0.8049 - lr: 9.7656e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 65/600\n",
            "1041/1041 - 13s - loss: 0.3636 - accuracy: 0.8095 - val_loss: 0.3598 - val_accuracy: 0.8051 - lr: 4.8828e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 66/600\n",
            "1041/1041 - 13s - loss: 0.3636 - accuracy: 0.8076 - val_loss: 0.3598 - val_accuracy: 0.8072 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 67/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8078 - val_loss: 0.3598 - val_accuracy: 0.8059 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 68/600\n",
            "1041/1041 - 13s - loss: 0.3636 - accuracy: 0.8083 - val_loss: 0.3597 - val_accuracy: 0.8071 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 69/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8085 - val_loss: 0.3597 - val_accuracy: 0.8069 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 70/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8076 - val_loss: 0.3597 - val_accuracy: 0.8063 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 71/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8076 - val_loss: 0.3597 - val_accuracy: 0.8057 - lr: 2.4414e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 72/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8078 - val_loss: 0.3597 - val_accuracy: 0.8064 - lr: 1.2207e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 73/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8077 - val_loss: 0.3597 - val_accuracy: 0.8057 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 74/600\n",
            "1041/1041 - 13s - loss: 0.3633 - accuracy: 0.8080 - val_loss: 0.3597 - val_accuracy: 0.8061 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 75/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8082 - val_loss: 0.3597 - val_accuracy: 0.8058 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 76/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8082 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 77/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8089 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 78/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8079 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 79/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8076 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 80/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8082 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 81/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8074 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 82/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8081 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 83/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8084 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 84/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8071 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 85/600\n",
            "1041/1041 - 13s - loss: 0.3636 - accuracy: 0.8076 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 86/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8076 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 87/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8081 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 88/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8083 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 3.8147e-08 - 13s/epoch - 13ms/step\n",
            "Epoch 89/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8084 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 90/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8076 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12  5]\n",
            " [14 11  3  2 12  9]\n",
            " [14 11  3  2 12  5]\n",
            " ...\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12  7]\n",
            " [14 11  3  2 12  7]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12  5  7]\n",
            " [14 11  3 ... 12  9  7]\n",
            " [14 11  3 ... 12  5  9]\n",
            " ...\n",
            " [14 11  3 ... 12 13  9]\n",
            " [14 11  3 ... 12  7  1]\n",
            " [14 11  3 ... 12  7 13]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ...  5  7  1]\n",
            " [14 11  3 ...  9  7  5]\n",
            " [14 11  3 ...  5  9 13]\n",
            " ...\n",
            " [14 11  3 ... 13  9  5]\n",
            " [14 11  3 ...  7  1  5]\n",
            " [14 11  3 ...  7 13  5]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ...  7  1 13]\n",
            " [14 11  3 ...  7  5 13]\n",
            " [14 11  3 ...  9 13  7]\n",
            " ...\n",
            " [14 11  3 ...  9  5  1]\n",
            " [14 11  3 ...  1  5 13]\n",
            " [14 11  3 ... 13  5  9]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ...  1 13  9]\n",
            " [14 11  3 ...  5 13  1]\n",
            " [14 11  3 ... 13  7  1]\n",
            " ...\n",
            " [14 11  3 ...  5  1  7]\n",
            " [14 11  3 ...  5 13  9]\n",
            " [14 11  3 ...  5  9  1]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ... 13  9  8]\n",
            " [14 11  3 ... 13  1  8]\n",
            " [14 11  3 ...  7  1  8]\n",
            " ...\n",
            " [14 11  3 ...  1  7  8]\n",
            " [14 11  3 ... 13  9  8]\n",
            " [14 11  3 ...  9  1  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  1  8 10]\n",
            " [14 11  3 ...  1  8 10]\n",
            " ...\n",
            " [14 11  3 ...  7  8 10]\n",
            " [14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  1  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_38 (Bidirecti  (None, 128)              40960     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,895\n",
            "Trainable params: 42,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1041/1041 - 18s - loss: 0.7206 - accuracy: 0.7865 - val_loss: 0.4848 - val_accuracy: 0.8066 - lr: 0.0050 - 18s/epoch - 17ms/step\n",
            "Epoch 2/600\n",
            "1041/1041 - 13s - loss: 0.4842 - accuracy: 0.8055 - val_loss: 0.4688 - val_accuracy: 0.8071 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 3/600\n",
            "1041/1041 - 13s - loss: 0.4674 - accuracy: 0.8063 - val_loss: 0.4662 - val_accuracy: 0.8064 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 4/600\n",
            "1041/1041 - 13s - loss: 0.4599 - accuracy: 0.8062 - val_loss: 0.4667 - val_accuracy: 0.8049 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 5/600\n",
            "1041/1041 - 13s - loss: 0.4858 - accuracy: 0.8050 - val_loss: 0.7195 - val_accuracy: 0.8063 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 6/600\n",
            "1041/1041 - 13s - loss: 0.4731 - accuracy: 0.8060 - val_loss: 0.4467 - val_accuracy: 0.8059 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 7/600\n",
            "1041/1041 - 13s - loss: 0.4444 - accuracy: 0.8058 - val_loss: 0.4506 - val_accuracy: 0.8064 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 8/600\n",
            "1041/1041 - 13s - loss: 0.4459 - accuracy: 0.8060 - val_loss: 0.4291 - val_accuracy: 0.8052 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 9/600\n",
            "1041/1041 - 13s - loss: 0.4476 - accuracy: 0.8050 - val_loss: 0.4306 - val_accuracy: 0.8080 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 10/600\n",
            "1041/1041 - 13s - loss: 0.4473 - accuracy: 0.8057 - val_loss: 0.4348 - val_accuracy: 0.8051 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 11/600\n",
            "1041/1041 - 13s - loss: 0.4879 - accuracy: 0.8051 - val_loss: 0.4402 - val_accuracy: 0.8071 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 12/600\n",
            "1041/1041 - 13s - loss: 0.4151 - accuracy: 0.8063 - val_loss: 0.4069 - val_accuracy: 0.8072 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 13/600\n",
            "1041/1041 - 13s - loss: 0.4136 - accuracy: 0.8047 - val_loss: 0.4020 - val_accuracy: 0.8059 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 14/600\n",
            "1041/1041 - 13s - loss: 0.4120 - accuracy: 0.8066 - val_loss: 0.4002 - val_accuracy: 0.8042 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 15/600\n",
            "1041/1041 - 13s - loss: 0.4124 - accuracy: 0.8063 - val_loss: 0.4148 - val_accuracy: 0.8053 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 16/600\n",
            "1041/1041 - 13s - loss: 0.4113 - accuracy: 0.8069 - val_loss: 0.4123 - val_accuracy: 0.8062 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 17/600\n",
            "1041/1041 - 13s - loss: 0.4117 - accuracy: 0.8074 - val_loss: 0.3967 - val_accuracy: 0.8065 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 18/600\n",
            "1041/1041 - 13s - loss: 0.4097 - accuracy: 0.8048 - val_loss: 0.4215 - val_accuracy: 0.8053 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 19/600\n",
            "1041/1041 - 13s - loss: 0.4273 - accuracy: 0.8052 - val_loss: 0.3975 - val_accuracy: 0.8068 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 20/600\n",
            "1041/1041 - 13s - loss: 0.4068 - accuracy: 0.8064 - val_loss: 0.3944 - val_accuracy: 0.8072 - lr: 0.0025 - 13s/epoch - 13ms/step\n",
            "Epoch 21/600\n",
            "1041/1041 - 13s - loss: 0.4078 - accuracy: 0.8059 - val_loss: 0.4008 - val_accuracy: 0.8059 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 22/600\n",
            "1041/1041 - 13s - loss: 0.4085 - accuracy: 0.8063 - val_loss: 0.4110 - val_accuracy: 0.8057 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 23/600\n",
            "1041/1041 - 13s - loss: 0.4152 - accuracy: 0.8054 - val_loss: 0.5513 - val_accuracy: 0.8082 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 24/600\n",
            "1041/1041 - 13s - loss: 0.4038 - accuracy: 0.8062 - val_loss: 0.3889 - val_accuracy: 0.8067 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 25/600\n",
            "1041/1041 - 13s - loss: 0.3919 - accuracy: 0.8057 - val_loss: 0.3801 - val_accuracy: 0.8062 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 26/600\n",
            "1041/1041 - 13s - loss: 0.3911 - accuracy: 0.8066 - val_loss: 0.3819 - val_accuracy: 0.8079 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 27/600\n",
            "1041/1041 - 13s - loss: 0.3908 - accuracy: 0.8065 - val_loss: 0.3851 - val_accuracy: 0.8050 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 28/600\n",
            "1041/1041 - 13s - loss: 0.3905 - accuracy: 0.8078 - val_loss: 0.3799 - val_accuracy: 0.8045 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 29/600\n",
            "1041/1041 - 13s - loss: 0.3896 - accuracy: 0.8066 - val_loss: 0.3826 - val_accuracy: 0.8081 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 30/600\n",
            "1041/1041 - 13s - loss: 0.3906 - accuracy: 0.8058 - val_loss: 0.3780 - val_accuracy: 0.8060 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 31/600\n",
            "1041/1041 - 13s - loss: 0.3896 - accuracy: 0.8074 - val_loss: 0.3827 - val_accuracy: 0.8055 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 32/600\n",
            "1041/1041 - 13s - loss: 0.3896 - accuracy: 0.8061 - val_loss: 0.3763 - val_accuracy: 0.8070 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 33/600\n",
            "1041/1041 - 13s - loss: 0.3888 - accuracy: 0.8061 - val_loss: 0.3808 - val_accuracy: 0.8067 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 34/600\n",
            "1041/1041 - 13s - loss: 0.3899 - accuracy: 0.8062 - val_loss: 0.3800 - val_accuracy: 0.8056 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 35/600\n",
            "1041/1041 - 13s - loss: 0.3906 - accuracy: 0.8058 - val_loss: 0.3839 - val_accuracy: 0.8057 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 36/600\n",
            "1041/1041 - 13s - loss: 0.3794 - accuracy: 0.8060 - val_loss: 0.3718 - val_accuracy: 0.8060 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 37/600\n",
            "1041/1041 - 13s - loss: 0.3787 - accuracy: 0.8075 - val_loss: 0.3721 - val_accuracy: 0.8062 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 38/600\n",
            "1041/1041 - 13s - loss: 0.3791 - accuracy: 0.8069 - val_loss: 0.3727 - val_accuracy: 0.8063 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 39/600\n",
            "1041/1041 - 13s - loss: 0.3779 - accuracy: 0.8064 - val_loss: 0.3695 - val_accuracy: 0.8060 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 40/600\n",
            "1041/1041 - 13s - loss: 0.3784 - accuracy: 0.8061 - val_loss: 0.3732 - val_accuracy: 0.8047 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 41/600\n",
            "1041/1041 - 13s - loss: 0.3781 - accuracy: 0.8063 - val_loss: 0.3686 - val_accuracy: 0.8074 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 42/600\n",
            "1041/1041 - 13s - loss: 0.3777 - accuracy: 0.8059 - val_loss: 0.3716 - val_accuracy: 0.8055 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 43/600\n",
            "1041/1041 - 13s - loss: 0.3774 - accuracy: 0.8067 - val_loss: 0.3757 - val_accuracy: 0.8065 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 44/600\n",
            "1041/1041 - 13s - loss: 0.3774 - accuracy: 0.8055 - val_loss: 0.3680 - val_accuracy: 0.8071 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 45/600\n",
            "1041/1041 - 13s - loss: 0.3768 - accuracy: 0.8064 - val_loss: 0.3703 - val_accuracy: 0.8057 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 46/600\n",
            "1041/1041 - 13s - loss: 0.3770 - accuracy: 0.8063 - val_loss: 0.3702 - val_accuracy: 0.8064 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 47/600\n",
            "1041/1041 - 13s - loss: 0.3771 - accuracy: 0.8064 - val_loss: 0.3709 - val_accuracy: 0.8077 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 48/600\n",
            "1041/1041 - 13s - loss: 0.3717 - accuracy: 0.8068 - val_loss: 0.3642 - val_accuracy: 0.8082 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 49/600\n",
            "1041/1041 - 13s - loss: 0.3714 - accuracy: 0.8057 - val_loss: 0.3654 - val_accuracy: 0.8060 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 50/600\n",
            "1041/1041 - 13s - loss: 0.3712 - accuracy: 0.8079 - val_loss: 0.3657 - val_accuracy: 0.8049 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 51/600\n",
            "1041/1041 - 13s - loss: 0.3709 - accuracy: 0.8061 - val_loss: 0.3672 - val_accuracy: 0.8064 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 52/600\n",
            "1041/1041 - 13s - loss: 0.3682 - accuracy: 0.8058 - val_loss: 0.3638 - val_accuracy: 0.8077 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 53/600\n",
            "1041/1041 - 13s - loss: 0.3676 - accuracy: 0.8062 - val_loss: 0.3628 - val_accuracy: 0.8054 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 54/600\n",
            "1041/1041 - 13s - loss: 0.3674 - accuracy: 0.8059 - val_loss: 0.3620 - val_accuracy: 0.8051 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 55/600\n",
            "1041/1041 - 13s - loss: 0.3675 - accuracy: 0.8058 - val_loss: 0.3632 - val_accuracy: 0.8076 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 56/600\n",
            "1041/1041 - 13s - loss: 0.3673 - accuracy: 0.8063 - val_loss: 0.3623 - val_accuracy: 0.8057 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 57/600\n",
            "1041/1041 - 13s - loss: 0.3674 - accuracy: 0.8062 - val_loss: 0.3638 - val_accuracy: 0.8064 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 58/600\n",
            "1041/1041 - 13s - loss: 0.3655 - accuracy: 0.8068 - val_loss: 0.3606 - val_accuracy: 0.8072 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 59/600\n",
            "1041/1041 - 13s - loss: 0.3652 - accuracy: 0.8069 - val_loss: 0.3621 - val_accuracy: 0.8053 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 60/600\n",
            "1041/1041 - 13s - loss: 0.3651 - accuracy: 0.8072 - val_loss: 0.3608 - val_accuracy: 0.8064 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 61/600\n",
            "1041/1041 - 13s - loss: 0.3653 - accuracy: 0.8065 - val_loss: 0.3609 - val_accuracy: 0.8047 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 62/600\n",
            "1041/1041 - 13s - loss: 0.3644 - accuracy: 0.8073 - val_loss: 0.3603 - val_accuracy: 0.8054 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 63/600\n",
            "1041/1041 - 13s - loss: 0.3642 - accuracy: 0.8067 - val_loss: 0.3598 - val_accuracy: 0.8078 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 64/600\n",
            "1041/1041 - 13s - loss: 0.3642 - accuracy: 0.8066 - val_loss: 0.3601 - val_accuracy: 0.8051 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 65/600\n",
            "1041/1041 - 13s - loss: 0.3640 - accuracy: 0.8067 - val_loss: 0.3601 - val_accuracy: 0.8060 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 66/600\n",
            "1041/1041 - 13s - loss: 0.3642 - accuracy: 0.8070 - val_loss: 0.3600 - val_accuracy: 0.8062 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 67/600\n",
            "1041/1041 - 13s - loss: 0.3636 - accuracy: 0.8077 - val_loss: 0.3594 - val_accuracy: 0.8054 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 68/600\n",
            "1041/1041 - 13s - loss: 0.3636 - accuracy: 0.8066 - val_loss: 0.3595 - val_accuracy: 0.8067 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 69/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8072 - val_loss: 0.3594 - val_accuracy: 0.8076 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 70/600\n",
            "1041/1041 - 13s - loss: 0.3636 - accuracy: 0.8064 - val_loss: 0.3595 - val_accuracy: 0.8060 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 71/600\n",
            "1041/1041 - 13s - loss: 0.3633 - accuracy: 0.8078 - val_loss: 0.3593 - val_accuracy: 0.8075 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 72/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8075 - val_loss: 0.3592 - val_accuracy: 0.8055 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 73/600\n",
            "1041/1041 - 13s - loss: 0.3633 - accuracy: 0.8067 - val_loss: 0.3592 - val_accuracy: 0.8059 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 74/600\n",
            "1041/1041 - 13s - loss: 0.3633 - accuracy: 0.8078 - val_loss: 0.3593 - val_accuracy: 0.8060 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 75/600\n",
            "1041/1041 - 13s - loss: 0.3633 - accuracy: 0.8070 - val_loss: 0.3591 - val_accuracy: 0.8057 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 76/600\n",
            "1041/1041 - 13s - loss: 0.3632 - accuracy: 0.8072 - val_loss: 0.3592 - val_accuracy: 0.8066 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 77/600\n",
            "1041/1041 - 13s - loss: 0.3631 - accuracy: 0.8074 - val_loss: 0.3592 - val_accuracy: 0.8070 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 78/600\n",
            "1041/1041 - 13s - loss: 0.3631 - accuracy: 0.8071 - val_loss: 0.3591 - val_accuracy: 0.8066 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 79/600\n",
            "1041/1041 - 13s - loss: 0.3630 - accuracy: 0.8079 - val_loss: 0.3591 - val_accuracy: 0.8066 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 80/600\n",
            "1041/1041 - 13s - loss: 0.3630 - accuracy: 0.8078 - val_loss: 0.3591 - val_accuracy: 0.8054 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 81/600\n",
            "1041/1041 - 13s - loss: 0.3631 - accuracy: 0.8081 - val_loss: 0.3591 - val_accuracy: 0.8054 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 82/600\n",
            "1041/1041 - 13s - loss: 0.3630 - accuracy: 0.8084 - val_loss: 0.3591 - val_accuracy: 0.8056 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 83/600\n",
            "1041/1041 - 13s - loss: 0.3631 - accuracy: 0.8069 - val_loss: 0.3591 - val_accuracy: 0.8057 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 84/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8077 - val_loss: 0.3591 - val_accuracy: 0.8052 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 85/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8077 - val_loss: 0.3591 - val_accuracy: 0.8055 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 86/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8079 - val_loss: 0.3591 - val_accuracy: 0.8055 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 87/600\n",
            "1041/1041 - 13s - loss: 0.3630 - accuracy: 0.8066 - val_loss: 0.3591 - val_accuracy: 0.8054 - lr: 6.1035e-07 - 13s/epoch - 13ms/step\n",
            "Epoch 88/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8081 - val_loss: 0.3591 - val_accuracy: 0.8052 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 89/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8079 - val_loss: 0.3591 - val_accuracy: 0.8052 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12  5]\n",
            " [14 11  3  2 12  1]\n",
            " [14 11  3  2 12  9]\n",
            " ...\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12  5]\n",
            " [14 11  3  2 12  7]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12  5  9]\n",
            " [14 11  3 ... 12  1 13]\n",
            " [14 11  3 ... 12  9 13]\n",
            " ...\n",
            " [14 11  3 ... 12 13  9]\n",
            " [14 11  3 ... 12  5  1]\n",
            " [14 11  3 ... 12  7 13]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ...  5  9  7]\n",
            " [14 11  3 ...  1 13  7]\n",
            " [14 11  3 ...  9 13  1]\n",
            " ...\n",
            " [14 11  3 ... 13  9  1]\n",
            " [14 11  3 ...  5  1 13]\n",
            " [14 11  3 ...  7 13  1]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ...  9  7  1]\n",
            " [14 11  3 ... 13  7  5]\n",
            " [14 11  3 ... 13  1  5]\n",
            " ...\n",
            " [14 11  3 ...  9  1  5]\n",
            " [14 11  3 ...  1 13  9]\n",
            " [14 11  3 ... 13  1  9]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ...  7  1 13]\n",
            " [14 11  3 ...  7  5  9]\n",
            " [14 11  3 ...  1  5  7]\n",
            " ...\n",
            " [14 11  3 ...  1  5  7]\n",
            " [14 11  3 ... 13  9  7]\n",
            " [14 11  3 ...  1  9  5]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ...  1 13  8]\n",
            " [14 11  3 ...  5  9  8]\n",
            " [14 11  3 ...  5  7  8]\n",
            " ...\n",
            " [14 11  3 ...  5  7  8]\n",
            " [14 11  3 ...  9  7  8]\n",
            " [14 11  3 ...  9  5  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ... 13  8 10]\n",
            " [14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  7  8 10]\n",
            " ...\n",
            " [14 11  3 ...  7  8 10]\n",
            " [14 11  3 ...  7  8 10]\n",
            " [14 11  3 ...  5  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_39 (Bidirecti  (None, 128)              40960     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,895\n",
            "Trainable params: 42,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1041/1041 - 17s - loss: 0.7140 - accuracy: 0.7851 - val_loss: 0.4741 - val_accuracy: 0.8069 - lr: 0.0050 - 17s/epoch - 17ms/step\n",
            "Epoch 2/600\n",
            "1041/1041 - 13s - loss: 0.4813 - accuracy: 0.8055 - val_loss: 0.4503 - val_accuracy: 0.8047 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 3/600\n",
            "1041/1041 - 13s - loss: 0.4650 - accuracy: 0.8067 - val_loss: 0.4466 - val_accuracy: 0.8069 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 4/600\n",
            "1041/1041 - 13s - loss: 0.4538 - accuracy: 0.8078 - val_loss: 0.4280 - val_accuracy: 0.8063 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 5/600\n",
            "1041/1041 - 13s - loss: 0.4502 - accuracy: 0.8059 - val_loss: 0.4259 - val_accuracy: 0.8069 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 6/600\n",
            "1041/1041 - 13s - loss: 0.4551 - accuracy: 0.8061 - val_loss: 0.4328 - val_accuracy: 0.8053 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 7/600\n",
            "1041/1041 - 13s - loss: 0.4416 - accuracy: 0.8073 - val_loss: 0.4274 - val_accuracy: 0.8047 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 8/600\n",
            "1041/1041 - 13s - loss: 0.4484 - accuracy: 0.8056 - val_loss: 0.4266 - val_accuracy: 0.8078 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 9/600\n",
            "1041/1041 - 13s - loss: 0.4136 - accuracy: 0.8064 - val_loss: 0.3975 - val_accuracy: 0.8046 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 10/600\n",
            "1041/1041 - 13s - loss: 0.4112 - accuracy: 0.8063 - val_loss: 0.4010 - val_accuracy: 0.8058 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 11/600\n",
            "1041/1041 - 13s - loss: 0.4114 - accuracy: 0.8064 - val_loss: 0.3965 - val_accuracy: 0.8063 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 12/600\n",
            "1041/1041 - 13s - loss: 0.4095 - accuracy: 0.8065 - val_loss: 0.4173 - val_accuracy: 0.8050 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 13/600\n",
            "1041/1041 - 13s - loss: 0.4107 - accuracy: 0.8065 - val_loss: 0.3963 - val_accuracy: 0.8073 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 14/600\n",
            "1041/1041 - 13s - loss: 0.4099 - accuracy: 0.8051 - val_loss: 0.3951 - val_accuracy: 0.8069 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 15/600\n",
            "1041/1041 - 13s - loss: 0.4090 - accuracy: 0.8058 - val_loss: 0.3973 - val_accuracy: 0.8049 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 16/600\n",
            "1041/1041 - 13s - loss: 0.4101 - accuracy: 0.8049 - val_loss: 0.3943 - val_accuracy: 0.8055 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 17/600\n",
            "1041/1041 - 13s - loss: 0.4081 - accuracy: 0.8055 - val_loss: 0.3965 - val_accuracy: 0.8070 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 18/600\n",
            "1041/1041 - 13s - loss: 0.4065 - accuracy: 0.8052 - val_loss: 0.4000 - val_accuracy: 0.8066 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 19/600\n",
            "1041/1041 - 13s - loss: 0.4096 - accuracy: 0.8064 - val_loss: 0.3989 - val_accuracy: 0.8069 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 20/600\n",
            "1041/1041 - 13s - loss: 0.3913 - accuracy: 0.8060 - val_loss: 0.3796 - val_accuracy: 0.8052 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 21/600\n",
            "1041/1041 - 13s - loss: 0.3905 - accuracy: 0.8063 - val_loss: 0.3820 - val_accuracy: 0.8049 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 22/600\n",
            "1041/1041 - 13s - loss: 0.3905 - accuracy: 0.8059 - val_loss: 0.3790 - val_accuracy: 0.8077 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 23/600\n",
            "1041/1041 - 13s - loss: 0.3904 - accuracy: 0.8060 - val_loss: 0.3782 - val_accuracy: 0.8066 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 24/600\n",
            "1041/1041 - 13s - loss: 0.3891 - accuracy: 0.8057 - val_loss: 0.3883 - val_accuracy: 0.8044 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 25/600\n",
            "1041/1041 - 13s - loss: 0.3893 - accuracy: 0.8055 - val_loss: 0.3799 - val_accuracy: 0.8060 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 26/600\n",
            "1041/1041 - 13s - loss: 0.3890 - accuracy: 0.8065 - val_loss: 0.3801 - val_accuracy: 0.8067 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 27/600\n",
            "1041/1041 - 13s - loss: 0.3797 - accuracy: 0.8069 - val_loss: 0.3736 - val_accuracy: 0.8070 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 28/600\n",
            "1041/1041 - 13s - loss: 0.3789 - accuracy: 0.8057 - val_loss: 0.3731 - val_accuracy: 0.8054 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 29/600\n",
            "1041/1041 - 13s - loss: 0.3784 - accuracy: 0.8062 - val_loss: 0.3774 - val_accuracy: 0.8063 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 30/600\n",
            "1041/1041 - 13s - loss: 0.3781 - accuracy: 0.8072 - val_loss: 0.3703 - val_accuracy: 0.8053 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 31/600\n",
            "1041/1041 - 13s - loss: 0.3772 - accuracy: 0.8070 - val_loss: 0.3707 - val_accuracy: 0.8057 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 32/600\n",
            "1041/1041 - 13s - loss: 0.3775 - accuracy: 0.8055 - val_loss: 0.3697 - val_accuracy: 0.8061 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 33/600\n",
            "1041/1041 - 13s - loss: 0.3774 - accuracy: 0.8067 - val_loss: 0.3776 - val_accuracy: 0.8051 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 34/600\n",
            "1041/1041 - 13s - loss: 0.3777 - accuracy: 0.8067 - val_loss: 0.3702 - val_accuracy: 0.8060 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 35/600\n",
            "1041/1041 - 13s - loss: 0.3773 - accuracy: 0.8054 - val_loss: 0.3700 - val_accuracy: 0.8051 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 36/600\n",
            "1041/1041 - 13s - loss: 0.3721 - accuracy: 0.8046 - val_loss: 0.3656 - val_accuracy: 0.8051 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 37/600\n",
            "1041/1041 - 13s - loss: 0.3712 - accuracy: 0.8066 - val_loss: 0.3658 - val_accuracy: 0.8062 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 38/600\n",
            "1041/1041 - 13s - loss: 0.3710 - accuracy: 0.8077 - val_loss: 0.3659 - val_accuracy: 0.8054 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 39/600\n",
            "1041/1041 - 13s - loss: 0.3713 - accuracy: 0.8064 - val_loss: 0.3658 - val_accuracy: 0.8065 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 40/600\n",
            "1041/1041 - 13s - loss: 0.3684 - accuracy: 0.8054 - val_loss: 0.3639 - val_accuracy: 0.8066 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 41/600\n",
            "1041/1041 - 13s - loss: 0.3681 - accuracy: 0.8070 - val_loss: 0.3626 - val_accuracy: 0.8057 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 42/600\n",
            "1041/1041 - 13s - loss: 0.3676 - accuracy: 0.8065 - val_loss: 0.3627 - val_accuracy: 0.8049 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 43/600\n",
            "1041/1041 - 13s - loss: 0.3676 - accuracy: 0.8067 - val_loss: 0.3623 - val_accuracy: 0.8057 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 44/600\n",
            "1041/1041 - 13s - loss: 0.3673 - accuracy: 0.8075 - val_loss: 0.3633 - val_accuracy: 0.8070 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 45/600\n",
            "1041/1041 - 13s - loss: 0.3673 - accuracy: 0.8073 - val_loss: 0.3622 - val_accuracy: 0.8063 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 46/600\n",
            "1041/1041 - 13s - loss: 0.3671 - accuracy: 0.8058 - val_loss: 0.3626 - val_accuracy: 0.8044 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 47/600\n",
            "1041/1041 - 13s - loss: 0.3659 - accuracy: 0.8056 - val_loss: 0.3611 - val_accuracy: 0.8052 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 48/600\n",
            "1041/1041 - 13s - loss: 0.3656 - accuracy: 0.8066 - val_loss: 0.3606 - val_accuracy: 0.8048 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 49/600\n",
            "1041/1041 - 13s - loss: 0.3654 - accuracy: 0.8075 - val_loss: 0.3622 - val_accuracy: 0.8047 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 50/600\n",
            "1041/1041 - 13s - loss: 0.3653 - accuracy: 0.8075 - val_loss: 0.3610 - val_accuracy: 0.8068 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 51/600\n",
            "1041/1041 - 13s - loss: 0.3651 - accuracy: 0.8071 - val_loss: 0.3610 - val_accuracy: 0.8061 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 52/600\n",
            "1041/1041 - 13s - loss: 0.3646 - accuracy: 0.8057 - val_loss: 0.3606 - val_accuracy: 0.8045 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 53/600\n",
            "1041/1041 - 13s - loss: 0.3642 - accuracy: 0.8075 - val_loss: 0.3601 - val_accuracy: 0.8070 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 54/600\n",
            "1041/1041 - 13s - loss: 0.3641 - accuracy: 0.8085 - val_loss: 0.3600 - val_accuracy: 0.8062 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 55/600\n",
            "1041/1041 - 13s - loss: 0.3642 - accuracy: 0.8066 - val_loss: 0.3603 - val_accuracy: 0.8066 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 56/600\n",
            "1041/1041 - 13s - loss: 0.3641 - accuracy: 0.8069 - val_loss: 0.3599 - val_accuracy: 0.8080 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 57/600\n",
            "1041/1041 - 13s - loss: 0.3640 - accuracy: 0.8068 - val_loss: 0.3598 - val_accuracy: 0.8065 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 58/600\n",
            "1041/1041 - 13s - loss: 0.3641 - accuracy: 0.8071 - val_loss: 0.3600 - val_accuracy: 0.8063 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 59/600\n",
            "1041/1041 - 13s - loss: 0.3641 - accuracy: 0.8063 - val_loss: 0.3598 - val_accuracy: 0.8060 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 60/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8069 - val_loss: 0.3601 - val_accuracy: 0.8071 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 61/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8074 - val_loss: 0.3594 - val_accuracy: 0.8083 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 62/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8077 - val_loss: 0.3596 - val_accuracy: 0.8053 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 63/600\n",
            "1041/1041 - 13s - loss: 0.3633 - accuracy: 0.8080 - val_loss: 0.3595 - val_accuracy: 0.8051 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 64/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8066 - val_loss: 0.3595 - val_accuracy: 0.8065 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 65/600\n",
            "1041/1041 - 13s - loss: 0.3631 - accuracy: 0.8084 - val_loss: 0.3593 - val_accuracy: 0.8057 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 66/600\n",
            "1041/1041 - 13s - loss: 0.3632 - accuracy: 0.8074 - val_loss: 0.3593 - val_accuracy: 0.8057 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 67/600\n",
            "1041/1041 - 13s - loss: 0.3632 - accuracy: 0.8086 - val_loss: 0.3593 - val_accuracy: 0.8066 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 68/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8074 - val_loss: 0.3595 - val_accuracy: 0.8054 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 69/600\n",
            "1041/1041 - 13s - loss: 0.3628 - accuracy: 0.8090 - val_loss: 0.3593 - val_accuracy: 0.8043 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 70/600\n",
            "1041/1041 - 13s - loss: 0.3631 - accuracy: 0.8075 - val_loss: 0.3593 - val_accuracy: 0.8056 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 71/600\n",
            "1041/1041 - 13s - loss: 0.3630 - accuracy: 0.8080 - val_loss: 0.3591 - val_accuracy: 0.8063 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 72/600\n",
            "1041/1041 - 13s - loss: 0.3631 - accuracy: 0.8080 - val_loss: 0.3592 - val_accuracy: 0.8053 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 73/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8078 - val_loss: 0.3591 - val_accuracy: 0.8066 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 74/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8081 - val_loss: 0.3591 - val_accuracy: 0.8064 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 75/600\n",
            "1041/1041 - 13s - loss: 0.3628 - accuracy: 0.8078 - val_loss: 0.3591 - val_accuracy: 0.8066 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 76/600\n",
            "1041/1041 - 13s - loss: 0.3630 - accuracy: 0.8071 - val_loss: 0.3591 - val_accuracy: 0.8056 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 77/600\n",
            "1041/1041 - 13s - loss: 0.3628 - accuracy: 0.8081 - val_loss: 0.3591 - val_accuracy: 0.8045 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 78/600\n",
            "1041/1041 - 13s - loss: 0.3628 - accuracy: 0.8075 - val_loss: 0.3591 - val_accuracy: 0.8062 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 79/600\n",
            "1041/1041 - 13s - loss: 0.3627 - accuracy: 0.8083 - val_loss: 0.3591 - val_accuracy: 0.8064 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 80/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8079 - val_loss: 0.3591 - val_accuracy: 0.8060 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 81/600\n",
            "1041/1041 - 13s - loss: 0.3627 - accuracy: 0.8083 - val_loss: 0.3591 - val_accuracy: 0.8062 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 82/600\n",
            "1041/1041 - 13s - loss: 0.3627 - accuracy: 0.8088 - val_loss: 0.3591 - val_accuracy: 0.8062 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 83/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8075 - val_loss: 0.3591 - val_accuracy: 0.8060 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 84/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8080 - val_loss: 0.3591 - val_accuracy: 0.8060 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 85/600\n",
            "1041/1041 - 13s - loss: 0.3627 - accuracy: 0.8083 - val_loss: 0.3591 - val_accuracy: 0.8062 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 86/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8078 - val_loss: 0.3591 - val_accuracy: 0.8062 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 87/600\n",
            "1041/1041 - 13s - loss: 0.3627 - accuracy: 0.8086 - val_loss: 0.3591 - val_accuracy: 0.8062 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 88/600\n",
            "1041/1041 - 13s - loss: 0.3627 - accuracy: 0.8084 - val_loss: 0.3591 - val_accuracy: 0.8061 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 89/600\n",
            "1041/1041 - 13s - loss: 0.3628 - accuracy: 0.8075 - val_loss: 0.3591 - val_accuracy: 0.8060 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 90/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8073 - val_loss: 0.3591 - val_accuracy: 0.8062 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 91/600\n",
            "1041/1041 - 13s - loss: 0.3628 - accuracy: 0.8076 - val_loss: 0.3591 - val_accuracy: 0.8060 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 92/600\n",
            "1041/1041 - 13s - loss: 0.3628 - accuracy: 0.8081 - val_loss: 0.3591 - val_accuracy: 0.8062 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 93/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8076 - val_loss: 0.3591 - val_accuracy: 0.8062 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 94/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8076 - val_loss: 0.3591 - val_accuracy: 0.8061 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 95/600\n",
            "1041/1041 - 13s - loss: 0.3628 - accuracy: 0.8082 - val_loss: 0.3591 - val_accuracy: 0.8061 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 96/600\n",
            "1041/1041 - 13s - loss: 0.3628 - accuracy: 0.8080 - val_loss: 0.3591 - val_accuracy: 0.8061 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 97/600\n",
            "1041/1041 - 13s - loss: 0.3628 - accuracy: 0.8082 - val_loss: 0.3591 - val_accuracy: 0.8061 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12  1]\n",
            " [14 11  3  2 12  5]\n",
            " [14 11  3  2 12  5]\n",
            " ...\n",
            " [14 11  3  2 12  7]\n",
            " [14 11  3  2 12  1]\n",
            " [14 11  3  2 12  7]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12  1 13]\n",
            " [14 11  3 ... 12  5  7]\n",
            " [14 11  3 ... 12  5 13]\n",
            " ...\n",
            " [14 11  3 ... 12  7  1]\n",
            " [14 11  3 ... 12  1  5]\n",
            " [14 11  3 ... 12  7  9]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ...  1 13  7]\n",
            " [14 11  3 ...  5  7 13]\n",
            " [14 11  3 ...  5 13  9]\n",
            " ...\n",
            " [14 11  3 ...  7  1  9]\n",
            " [14 11  3 ...  1  5  7]\n",
            " [14 11  3 ...  7  9 13]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ... 13  7  9]\n",
            " [14 11  3 ...  7 13  1]\n",
            " [14 11  3 ... 13  9  7]\n",
            " ...\n",
            " [14 11  3 ...  1  9  5]\n",
            " [14 11  3 ...  5  7  9]\n",
            " [14 11  3 ...  9 13  5]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ...  7  9  5]\n",
            " [14 11  3 ... 13  1  9]\n",
            " [14 11  3 ...  9  7  1]\n",
            " ...\n",
            " [14 11  3 ...  9  5 13]\n",
            " [14 11  3 ...  7  9 13]\n",
            " [14 11  3 ... 13  5  1]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ...  9  5  8]\n",
            " [14 11  3 ...  1  9  8]\n",
            " [14 11  3 ...  7  1  8]\n",
            " ...\n",
            " [14 11  3 ...  5 13  8]\n",
            " [14 11  3 ...  9 13  8]\n",
            " [14 11  3 ...  5  1  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ...  5  8 10]\n",
            " [14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  1  8 10]\n",
            " ...\n",
            " [14 11  3 ... 13  8 10]\n",
            " [14 11  3 ... 13  8 10]\n",
            " [14 11  3 ...  1  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_40 (Bidirecti  (None, 128)              40960     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,895\n",
            "Trainable params: 42,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1042/1042 - 17s - loss: 0.7185 - accuracy: 0.7824 - val_loss: 0.4706 - val_accuracy: 0.8060 - lr: 0.0050 - 17s/epoch - 17ms/step\n",
            "Epoch 2/600\n",
            "1042/1042 - 13s - loss: 0.4783 - accuracy: 0.8050 - val_loss: 0.4478 - val_accuracy: 0.8053 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 3/600\n",
            "1042/1042 - 13s - loss: 0.4646 - accuracy: 0.8058 - val_loss: 0.4500 - val_accuracy: 0.8051 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 4/600\n",
            "1042/1042 - 13s - loss: 0.4543 - accuracy: 0.8061 - val_loss: 0.4304 - val_accuracy: 0.8055 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 5/600\n",
            "1042/1042 - 13s - loss: 0.4509 - accuracy: 0.8064 - val_loss: 0.4352 - val_accuracy: 0.8040 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 6/600\n",
            "1042/1042 - 13s - loss: 0.4519 - accuracy: 0.8062 - val_loss: 0.4184 - val_accuracy: 0.8066 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 7/600\n",
            "1042/1042 - 13s - loss: 0.4472 - accuracy: 0.8055 - val_loss: 0.4183 - val_accuracy: 0.8068 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 8/600\n",
            "1042/1042 - 13s - loss: 0.4533 - accuracy: 0.8064 - val_loss: 0.4247 - val_accuracy: 0.8056 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 9/600\n",
            "1042/1042 - 13s - loss: 0.4410 - accuracy: 0.8052 - val_loss: 0.4175 - val_accuracy: 0.8072 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 10/600\n",
            "1042/1042 - 13s - loss: 0.4687 - accuracy: 0.8045 - val_loss: 0.4289 - val_accuracy: 0.8049 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 11/600\n",
            "1042/1042 - 13s - loss: 0.4365 - accuracy: 0.8064 - val_loss: 0.4269 - val_accuracy: 0.8068 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 12/600\n",
            "1042/1042 - 13s - loss: 0.4385 - accuracy: 0.8059 - val_loss: 0.4223 - val_accuracy: 0.8060 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 13/600\n",
            "1042/1042 - 13s - loss: 0.4117 - accuracy: 0.8047 - val_loss: 0.4006 - val_accuracy: 0.8071 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 14/600\n",
            "1042/1042 - 13s - loss: 0.4116 - accuracy: 0.8060 - val_loss: 0.4000 - val_accuracy: 0.8052 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 15/600\n",
            "1042/1042 - 13s - loss: 0.4104 - accuracy: 0.8063 - val_loss: 0.3979 - val_accuracy: 0.8069 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 16/600\n",
            "1042/1042 - 13s - loss: 0.4092 - accuracy: 0.8063 - val_loss: 0.3960 - val_accuracy: 0.8043 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 17/600\n",
            "1042/1042 - 13s - loss: 0.4110 - accuracy: 0.8053 - val_loss: 0.3996 - val_accuracy: 0.8052 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 18/600\n",
            "1042/1042 - 13s - loss: 0.4082 - accuracy: 0.8051 - val_loss: 0.3913 - val_accuracy: 0.8039 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 19/600\n",
            "1042/1042 - 13s - loss: 0.4106 - accuracy: 0.8057 - val_loss: 0.4039 - val_accuracy: 0.8052 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 20/600\n",
            "1042/1042 - 13s - loss: 0.4063 - accuracy: 0.8058 - val_loss: 0.3910 - val_accuracy: 0.8064 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 21/600\n",
            "1042/1042 - 13s - loss: 0.4079 - accuracy: 0.8068 - val_loss: 0.4039 - val_accuracy: 0.8059 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 22/600\n",
            "1042/1042 - 13s - loss: 0.4069 - accuracy: 0.8054 - val_loss: 0.3930 - val_accuracy: 0.8060 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 23/600\n",
            "1042/1042 - 13s - loss: 0.4083 - accuracy: 0.8062 - val_loss: 0.3907 - val_accuracy: 0.8051 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 24/600\n",
            "1042/1042 - 13s - loss: 0.4068 - accuracy: 0.8063 - val_loss: 0.3973 - val_accuracy: 0.8043 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 25/600\n",
            "1042/1042 - 13s - loss: 0.4069 - accuracy: 0.8051 - val_loss: 0.3912 - val_accuracy: 0.8049 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 26/600\n",
            "1042/1042 - 13s - loss: 0.4072 - accuracy: 0.8063 - val_loss: 0.3910 - val_accuracy: 0.8066 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 27/600\n",
            "1042/1042 - 13s - loss: 0.3904 - accuracy: 0.8051 - val_loss: 0.3798 - val_accuracy: 0.8060 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 28/600\n",
            "1042/1042 - 13s - loss: 0.3900 - accuracy: 0.8065 - val_loss: 0.3780 - val_accuracy: 0.8046 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 29/600\n",
            "1042/1042 - 13s - loss: 0.3898 - accuracy: 0.8054 - val_loss: 0.3784 - val_accuracy: 0.8070 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 30/600\n",
            "1042/1042 - 13s - loss: 0.3890 - accuracy: 0.8060 - val_loss: 0.3798 - val_accuracy: 0.8042 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 31/600\n",
            "1042/1042 - 13s - loss: 0.3888 - accuracy: 0.8049 - val_loss: 0.3834 - val_accuracy: 0.8050 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 32/600\n",
            "1042/1042 - 13s - loss: 0.3793 - accuracy: 0.8067 - val_loss: 0.3717 - val_accuracy: 0.8065 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 33/600\n",
            "1042/1042 - 13s - loss: 0.3789 - accuracy: 0.8064 - val_loss: 0.3715 - val_accuracy: 0.8049 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 34/600\n",
            "1042/1042 - 13s - loss: 0.3781 - accuracy: 0.8069 - val_loss: 0.3694 - val_accuracy: 0.8053 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 35/600\n",
            "1042/1042 - 13s - loss: 0.3785 - accuracy: 0.8065 - val_loss: 0.3696 - val_accuracy: 0.8064 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 36/600\n",
            "1042/1042 - 13s - loss: 0.3781 - accuracy: 0.8065 - val_loss: 0.3706 - val_accuracy: 0.8075 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 37/600\n",
            "1042/1042 - 13s - loss: 0.3780 - accuracy: 0.8067 - val_loss: 0.3674 - val_accuracy: 0.8075 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 38/600\n",
            "1042/1042 - 13s - loss: 0.3777 - accuracy: 0.8058 - val_loss: 0.3694 - val_accuracy: 0.8045 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 39/600\n",
            "1042/1042 - 13s - loss: 0.3768 - accuracy: 0.8073 - val_loss: 0.3717 - val_accuracy: 0.8045 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 40/600\n",
            "1042/1042 - 13s - loss: 0.3772 - accuracy: 0.8065 - val_loss: 0.3753 - val_accuracy: 0.8074 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 41/600\n",
            "1042/1042 - 13s - loss: 0.3723 - accuracy: 0.8063 - val_loss: 0.3654 - val_accuracy: 0.8082 - lr: 3.1250e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 42/600\n",
            "1042/1042 - 13s - loss: 0.3719 - accuracy: 0.8055 - val_loss: 0.3650 - val_accuracy: 0.8072 - lr: 3.1250e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 43/600\n",
            "1042/1042 - 13s - loss: 0.3716 - accuracy: 0.8062 - val_loss: 0.3667 - val_accuracy: 0.8056 - lr: 3.1250e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 44/600\n",
            "1042/1042 - 13s - loss: 0.3713 - accuracy: 0.8054 - val_loss: 0.3645 - val_accuracy: 0.8085 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 45/600\n",
            "1042/1042 - 13s - loss: 0.3711 - accuracy: 0.8057 - val_loss: 0.3655 - val_accuracy: 0.8079 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 46/600\n",
            "1042/1042 - 13s - loss: 0.3712 - accuracy: 0.8064 - val_loss: 0.3650 - val_accuracy: 0.8054 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 47/600\n",
            "1042/1042 - 13s - loss: 0.3707 - accuracy: 0.8054 - val_loss: 0.3644 - val_accuracy: 0.8063 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 48/600\n",
            "1042/1042 - 13s - loss: 0.3681 - accuracy: 0.8064 - val_loss: 0.3628 - val_accuracy: 0.8086 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 49/600\n",
            "1042/1042 - 13s - loss: 0.3678 - accuracy: 0.8067 - val_loss: 0.3630 - val_accuracy: 0.8064 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 50/600\n",
            "1042/1042 - 13s - loss: 0.3675 - accuracy: 0.8065 - val_loss: 0.3615 - val_accuracy: 0.8062 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 51/600\n",
            "1042/1042 - 13s - loss: 0.3673 - accuracy: 0.8069 - val_loss: 0.3621 - val_accuracy: 0.8062 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 52/600\n",
            "1042/1042 - 13s - loss: 0.3673 - accuracy: 0.8070 - val_loss: 0.3639 - val_accuracy: 0.8066 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 53/600\n",
            "1042/1042 - 13s - loss: 0.3670 - accuracy: 0.8073 - val_loss: 0.3612 - val_accuracy: 0.8055 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 54/600\n",
            "1042/1042 - 13s - loss: 0.3675 - accuracy: 0.8060 - val_loss: 0.3616 - val_accuracy: 0.8062 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 55/600\n",
            "1042/1042 - 13s - loss: 0.3670 - accuracy: 0.8068 - val_loss: 0.3611 - val_accuracy: 0.8051 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 56/600\n",
            "1042/1042 - 13s - loss: 0.3674 - accuracy: 0.8058 - val_loss: 0.3618 - val_accuracy: 0.8065 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 57/600\n",
            "1042/1042 - 13s - loss: 0.3670 - accuracy: 0.8060 - val_loss: 0.3613 - val_accuracy: 0.8072 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 58/600\n",
            "1042/1042 - 13s - loss: 0.3669 - accuracy: 0.8059 - val_loss: 0.3623 - val_accuracy: 0.8044 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 59/600\n",
            "1042/1042 - 13s - loss: 0.3654 - accuracy: 0.8070 - val_loss: 0.3600 - val_accuracy: 0.8046 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 60/600\n",
            "1042/1042 - 13s - loss: 0.3652 - accuracy: 0.8067 - val_loss: 0.3604 - val_accuracy: 0.8069 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 61/600\n",
            "1042/1042 - 13s - loss: 0.3652 - accuracy: 0.8063 - val_loss: 0.3601 - val_accuracy: 0.8081 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 62/600\n",
            "1042/1042 - 13s - loss: 0.3651 - accuracy: 0.8066 - val_loss: 0.3607 - val_accuracy: 0.8055 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 63/600\n",
            "1042/1042 - 13s - loss: 0.3644 - accuracy: 0.8061 - val_loss: 0.3594 - val_accuracy: 0.8057 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 64/600\n",
            "1042/1042 - 13s - loss: 0.3642 - accuracy: 0.8075 - val_loss: 0.3593 - val_accuracy: 0.8071 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 65/600\n",
            "1042/1042 - 13s - loss: 0.3641 - accuracy: 0.8055 - val_loss: 0.3594 - val_accuracy: 0.8065 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 66/600\n",
            "1042/1042 - 13s - loss: 0.3639 - accuracy: 0.8081 - val_loss: 0.3594 - val_accuracy: 0.8056 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 67/600\n",
            "1042/1042 - 13s - loss: 0.3636 - accuracy: 0.8063 - val_loss: 0.3590 - val_accuracy: 0.8061 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 68/600\n",
            "1042/1042 - 13s - loss: 0.3636 - accuracy: 0.8077 - val_loss: 0.3592 - val_accuracy: 0.8058 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 69/600\n",
            "1042/1042 - 13s - loss: 0.3637 - accuracy: 0.8069 - val_loss: 0.3593 - val_accuracy: 0.8064 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 70/600\n",
            "1042/1042 - 13s - loss: 0.3635 - accuracy: 0.8071 - val_loss: 0.3592 - val_accuracy: 0.8064 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 71/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8076 - val_loss: 0.3592 - val_accuracy: 0.8058 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 72/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8074 - val_loss: 0.3590 - val_accuracy: 0.8059 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 73/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8066 - val_loss: 0.3590 - val_accuracy: 0.8059 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 74/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8073 - val_loss: 0.3589 - val_accuracy: 0.8058 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 75/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8088 - val_loss: 0.3588 - val_accuracy: 0.8049 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 76/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8072 - val_loss: 0.3589 - val_accuracy: 0.8056 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 77/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8070 - val_loss: 0.3588 - val_accuracy: 0.8058 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 78/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8074 - val_loss: 0.3588 - val_accuracy: 0.8061 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 79/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8074 - val_loss: 0.3589 - val_accuracy: 0.8062 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 80/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8078 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 81/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8080 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 82/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8083 - val_loss: 0.3588 - val_accuracy: 0.8058 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 83/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8077 - val_loss: 0.3588 - val_accuracy: 0.8057 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 84/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8063 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 85/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8074 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 86/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8077 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 87/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8073 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 88/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8084 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 89/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8073 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 90/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8073 - val_loss: 0.3588 - val_accuracy: 0.8060 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 91/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8071 - val_loss: 0.3588 - val_accuracy: 0.8060 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 92/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8072 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 93/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8082 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 94/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8081 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 95/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8077 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 96/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8083 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 97/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8084 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 98/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8082 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 99/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8074 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 100/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8071 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 101/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8072 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 102/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8075 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 103/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8079 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 104/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8070 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12  7]\n",
            " [14 11  3  2 12  7]\n",
            " [14 11  3  2 12 13]\n",
            " ...\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12 13]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12  7  5]\n",
            " [14 11  3 ... 12  7  9]\n",
            " [14 11  3 ... 12 13  9]\n",
            " ...\n",
            " [14 11  3 ... 12 13  1]\n",
            " [14 11  3 ... 12 13  5]\n",
            " [14 11  3 ... 12 13  7]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ...  7  5  9]\n",
            " [14 11  3 ...  7  9  1]\n",
            " [14 11  3 ... 13  9  1]\n",
            " ...\n",
            " [14 11  3 ... 13  1  5]\n",
            " [14 11  3 ... 13  5  7]\n",
            " [14 11  3 ... 13  7  1]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ...  5  9 13]\n",
            " [14 11  3 ...  9  1  5]\n",
            " [14 11  3 ...  9  1  7]\n",
            " ...\n",
            " [14 11  3 ...  1  5  7]\n",
            " [14 11  3 ...  5  7  9]\n",
            " [14 11  3 ...  7  1  5]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ...  9 13  1]\n",
            " [14 11  3 ...  1  5 13]\n",
            " [14 11  3 ...  1  7  5]\n",
            " ...\n",
            " [14 11  3 ...  5  7  9]\n",
            " [14 11  3 ...  7  9  1]\n",
            " [14 11  3 ...  1  5  9]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ... 13  1  8]\n",
            " [14 11  3 ...  5 13  8]\n",
            " [14 11  3 ...  7  5  8]\n",
            " ...\n",
            " [14 11  3 ...  7  9  8]\n",
            " [14 11  3 ...  9  1  8]\n",
            " [14 11  3 ...  5  9  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ...  1  8 10]\n",
            " [14 11  3 ... 13  8 10]\n",
            " [14 11  3 ...  5  8 10]\n",
            " ...\n",
            " [14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  1  8 10]\n",
            " [14 11  3 ...  9  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_41 (Bidirecti  (None, 128)              40960     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,895\n",
            "Trainable params: 42,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1041/1041 - 17s - loss: 0.7030 - accuracy: 0.7872 - val_loss: 0.4722 - val_accuracy: 0.8065 - lr: 0.0050 - 17s/epoch - 17ms/step\n",
            "Epoch 2/600\n",
            "1041/1041 - 13s - loss: 0.4756 - accuracy: 0.8069 - val_loss: 0.4412 - val_accuracy: 0.8055 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 3/600\n",
            "1041/1041 - 13s - loss: 0.4599 - accuracy: 0.8058 - val_loss: 0.4498 - val_accuracy: 0.8050 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 4/600\n",
            "1041/1041 - 13s - loss: 0.4537 - accuracy: 0.8062 - val_loss: 0.4456 - val_accuracy: 0.8050 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 5/600\n",
            "1041/1041 - 13s - loss: 0.4477 - accuracy: 0.8066 - val_loss: 0.4324 - val_accuracy: 0.8076 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 6/600\n",
            "1041/1041 - 13s - loss: 0.4455 - accuracy: 0.8055 - val_loss: 0.4293 - val_accuracy: 0.8059 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 7/600\n",
            "1041/1041 - 13s - loss: 0.4816 - accuracy: 0.8058 - val_loss: 0.4258 - val_accuracy: 0.8072 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 8/600\n",
            "1041/1041 - 13s - loss: 0.4409 - accuracy: 0.8051 - val_loss: 0.4173 - val_accuracy: 0.8080 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 9/600\n",
            "1041/1041 - 13s - loss: 0.4405 - accuracy: 0.8050 - val_loss: 0.4141 - val_accuracy: 0.8076 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 10/600\n",
            "1041/1041 - 13s - loss: 0.4803 - accuracy: 0.8046 - val_loss: 0.5516 - val_accuracy: 0.8065 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 11/600\n",
            "1041/1041 - 13s - loss: 0.4685 - accuracy: 0.8055 - val_loss: 0.4366 - val_accuracy: 0.8061 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 12/600\n",
            "1041/1041 - 13s - loss: 0.4408 - accuracy: 0.8067 - val_loss: 0.4205 - val_accuracy: 0.8048 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 13/600\n",
            "1041/1041 - 13s - loss: 0.4122 - accuracy: 0.8061 - val_loss: 0.4015 - val_accuracy: 0.8066 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 14/600\n",
            "1041/1041 - 13s - loss: 0.4116 - accuracy: 0.8067 - val_loss: 0.3934 - val_accuracy: 0.8058 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 15/600\n",
            "1041/1041 - 12s - loss: 0.4094 - accuracy: 0.8053 - val_loss: 0.3937 - val_accuracy: 0.8050 - lr: 0.0025 - 12s/epoch - 12ms/step\n",
            "Epoch 16/600\n",
            "1041/1041 - 13s - loss: 0.4080 - accuracy: 0.8059 - val_loss: 0.4070 - val_accuracy: 0.8074 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 17/600\n",
            "1041/1041 - 13s - loss: 0.4081 - accuracy: 0.8069 - val_loss: 0.4060 - val_accuracy: 0.8052 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 18/600\n",
            "1041/1041 - 13s - loss: 0.3927 - accuracy: 0.8061 - val_loss: 0.3831 - val_accuracy: 0.8059 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 19/600\n",
            "1041/1041 - 13s - loss: 0.3916 - accuracy: 0.8056 - val_loss: 0.3840 - val_accuracy: 0.8071 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 20/600\n",
            "1041/1041 - 13s - loss: 0.3914 - accuracy: 0.8064 - val_loss: 0.3793 - val_accuracy: 0.8053 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 21/600\n",
            "1041/1041 - 13s - loss: 0.3905 - accuracy: 0.8058 - val_loss: 0.3837 - val_accuracy: 0.8062 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 22/600\n",
            "1041/1041 - 13s - loss: 0.3906 - accuracy: 0.8059 - val_loss: 0.3771 - val_accuracy: 0.8053 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 23/600\n",
            "1041/1041 - 13s - loss: 0.3899 - accuracy: 0.8070 - val_loss: 0.3771 - val_accuracy: 0.8049 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 24/600\n",
            "1041/1041 - 13s - loss: 0.3891 - accuracy: 0.8064 - val_loss: 0.3802 - val_accuracy: 0.8065 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 25/600\n",
            "1041/1041 - 13s - loss: 0.3902 - accuracy: 0.8052 - val_loss: 0.3804 - val_accuracy: 0.8063 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 26/600\n",
            "1041/1041 - 13s - loss: 0.3799 - accuracy: 0.8056 - val_loss: 0.3716 - val_accuracy: 0.8079 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 27/600\n",
            "1041/1041 - 13s - loss: 0.3794 - accuracy: 0.8073 - val_loss: 0.3715 - val_accuracy: 0.8060 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 28/600\n",
            "1041/1041 - 13s - loss: 0.3784 - accuracy: 0.8070 - val_loss: 0.3721 - val_accuracy: 0.8057 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 29/600\n",
            "1041/1041 - 13s - loss: 0.3788 - accuracy: 0.8056 - val_loss: 0.3696 - val_accuracy: 0.8068 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 30/600\n",
            "1041/1041 - 13s - loss: 0.3780 - accuracy: 0.8074 - val_loss: 0.3726 - val_accuracy: 0.8060 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 31/600\n",
            "1041/1041 - 13s - loss: 0.3784 - accuracy: 0.8062 - val_loss: 0.3709 - val_accuracy: 0.8074 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 32/600\n",
            "1041/1041 - 13s - loss: 0.3780 - accuracy: 0.8057 - val_loss: 0.3699 - val_accuracy: 0.8054 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 33/600\n",
            "1041/1041 - 13s - loss: 0.3726 - accuracy: 0.8057 - val_loss: 0.3656 - val_accuracy: 0.8069 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 34/600\n",
            "1041/1041 - 13s - loss: 0.3717 - accuracy: 0.8074 - val_loss: 0.3645 - val_accuracy: 0.8070 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 35/600\n",
            "1041/1041 - 13s - loss: 0.3723 - accuracy: 0.8054 - val_loss: 0.3651 - val_accuracy: 0.8054 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 36/600\n",
            "1041/1041 - 13s - loss: 0.3714 - accuracy: 0.8064 - val_loss: 0.3654 - val_accuracy: 0.8076 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 37/600\n",
            "1041/1041 - 13s - loss: 0.3715 - accuracy: 0.8055 - val_loss: 0.3641 - val_accuracy: 0.8077 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 38/600\n",
            "1041/1041 - 13s - loss: 0.3712 - accuracy: 0.8056 - val_loss: 0.3664 - val_accuracy: 0.8064 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 39/600\n",
            "1041/1041 - 13s - loss: 0.3709 - accuracy: 0.8064 - val_loss: 0.3644 - val_accuracy: 0.8045 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 40/600\n",
            "1041/1041 - 13s - loss: 0.3709 - accuracy: 0.8060 - val_loss: 0.3639 - val_accuracy: 0.8062 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 41/600\n",
            "1041/1041 - 13s - loss: 0.3706 - accuracy: 0.8070 - val_loss: 0.3635 - val_accuracy: 0.8072 - lr: 3.1250e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 42/600\n",
            "1041/1041 - 14s - loss: 0.3709 - accuracy: 0.8058 - val_loss: 0.3630 - val_accuracy: 0.8061 - lr: 3.1250e-04 - 14s/epoch - 13ms/step\n",
            "Epoch 43/600\n",
            "1041/1041 - 13s - loss: 0.3703 - accuracy: 0.8066 - val_loss: 0.3636 - val_accuracy: 0.8057 - lr: 3.1250e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 44/600\n",
            "1041/1041 - 13s - loss: 0.3704 - accuracy: 0.8074 - val_loss: 0.3635 - val_accuracy: 0.8058 - lr: 3.1250e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 45/600\n",
            "1041/1041 - 13s - loss: 0.3700 - accuracy: 0.8063 - val_loss: 0.3635 - val_accuracy: 0.8042 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 46/600\n",
            "1041/1041 - 13s - loss: 0.3672 - accuracy: 0.8069 - val_loss: 0.3608 - val_accuracy: 0.8068 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 47/600\n",
            "1041/1041 - 13s - loss: 0.3671 - accuracy: 0.8062 - val_loss: 0.3615 - val_accuracy: 0.8045 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 48/600\n",
            "1041/1041 - 13s - loss: 0.3668 - accuracy: 0.8066 - val_loss: 0.3620 - val_accuracy: 0.8047 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 49/600\n",
            "1041/1041 - 13s - loss: 0.3667 - accuracy: 0.8072 - val_loss: 0.3612 - val_accuracy: 0.8060 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 50/600\n",
            "1041/1041 - 13s - loss: 0.3650 - accuracy: 0.8067 - val_loss: 0.3607 - val_accuracy: 0.8054 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 51/600\n",
            "1041/1041 - 13s - loss: 0.3650 - accuracy: 0.8076 - val_loss: 0.3600 - val_accuracy: 0.8078 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 52/600\n",
            "1041/1041 - 13s - loss: 0.3648 - accuracy: 0.8072 - val_loss: 0.3597 - val_accuracy: 0.8044 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 53/600\n",
            "1041/1041 - 13s - loss: 0.3651 - accuracy: 0.8061 - val_loss: 0.3602 - val_accuracy: 0.8082 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 54/600\n",
            "1041/1041 - 13s - loss: 0.3648 - accuracy: 0.8068 - val_loss: 0.3595 - val_accuracy: 0.8071 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 55/600\n",
            "1041/1041 - 13s - loss: 0.3649 - accuracy: 0.8065 - val_loss: 0.3596 - val_accuracy: 0.8075 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 56/600\n",
            "1041/1041 - 13s - loss: 0.3646 - accuracy: 0.8073 - val_loss: 0.3604 - val_accuracy: 0.8048 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 57/600\n",
            "1041/1041 - 13s - loss: 0.3646 - accuracy: 0.8061 - val_loss: 0.3602 - val_accuracy: 0.8060 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 58/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8065 - val_loss: 0.3594 - val_accuracy: 0.8054 - lr: 3.9062e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 59/600\n",
            "1041/1041 - 13s - loss: 0.3637 - accuracy: 0.8074 - val_loss: 0.3592 - val_accuracy: 0.8053 - lr: 3.9062e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 60/600\n",
            "1041/1041 - 13s - loss: 0.3639 - accuracy: 0.8071 - val_loss: 0.3591 - val_accuracy: 0.8058 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 61/600\n",
            "1041/1041 - 13s - loss: 0.3637 - accuracy: 0.8072 - val_loss: 0.3588 - val_accuracy: 0.8076 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 62/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8076 - val_loss: 0.3588 - val_accuracy: 0.8046 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 63/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8062 - val_loss: 0.3589 - val_accuracy: 0.8064 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 64/600\n",
            "1041/1041 - 13s - loss: 0.3636 - accuracy: 0.8065 - val_loss: 0.3598 - val_accuracy: 0.8062 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 65/600\n",
            "1041/1041 - 13s - loss: 0.3631 - accuracy: 0.8072 - val_loss: 0.3584 - val_accuracy: 0.8080 - lr: 1.9531e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 66/600\n",
            "1041/1041 - 13s - loss: 0.3630 - accuracy: 0.8074 - val_loss: 0.3584 - val_accuracy: 0.8070 - lr: 1.9531e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 67/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8069 - val_loss: 0.3585 - val_accuracy: 0.8069 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 68/600\n",
            "1041/1041 - 13s - loss: 0.3630 - accuracy: 0.8068 - val_loss: 0.3588 - val_accuracy: 0.8065 - lr: 1.9531e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 69/600\n",
            "1041/1041 - 13s - loss: 0.3627 - accuracy: 0.8086 - val_loss: 0.3582 - val_accuracy: 0.8052 - lr: 9.7656e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 70/600\n",
            "1041/1041 - 13s - loss: 0.3628 - accuracy: 0.8074 - val_loss: 0.3582 - val_accuracy: 0.8072 - lr: 9.7656e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 71/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8073 - val_loss: 0.3582 - val_accuracy: 0.8058 - lr: 9.7656e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 72/600\n",
            "1041/1041 - 13s - loss: 0.3628 - accuracy: 0.8076 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 9.7656e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 73/600\n",
            "1041/1041 - 13s - loss: 0.3626 - accuracy: 0.8072 - val_loss: 0.3581 - val_accuracy: 0.8055 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 74/600\n",
            "1041/1041 - 13s - loss: 0.3626 - accuracy: 0.8085 - val_loss: 0.3581 - val_accuracy: 0.8053 - lr: 4.8828e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 75/600\n",
            "1041/1041 - 13s - loss: 0.3625 - accuracy: 0.8075 - val_loss: 0.3581 - val_accuracy: 0.8056 - lr: 4.8828e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 76/600\n",
            "1041/1041 - 13s - loss: 0.3625 - accuracy: 0.8086 - val_loss: 0.3581 - val_accuracy: 0.8050 - lr: 4.8828e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 77/600\n",
            "1041/1041 - 13s - loss: 0.3625 - accuracy: 0.8081 - val_loss: 0.3581 - val_accuracy: 0.8062 - lr: 2.4414e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 78/600\n",
            "1041/1041 - 13s - loss: 0.3624 - accuracy: 0.8087 - val_loss: 0.3581 - val_accuracy: 0.8060 - lr: 2.4414e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 79/600\n",
            "1041/1041 - 13s - loss: 0.3625 - accuracy: 0.8082 - val_loss: 0.3581 - val_accuracy: 0.8062 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 80/600\n",
            "1041/1041 - 13s - loss: 0.3624 - accuracy: 0.8087 - val_loss: 0.3580 - val_accuracy: 0.8062 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 81/600\n",
            "1041/1041 - 13s - loss: 0.3624 - accuracy: 0.8080 - val_loss: 0.3580 - val_accuracy: 0.8069 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 82/600\n",
            "1041/1041 - 13s - loss: 0.3626 - accuracy: 0.8077 - val_loss: 0.3581 - val_accuracy: 0.8061 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 83/600\n",
            "1041/1041 - 13s - loss: 0.3625 - accuracy: 0.8081 - val_loss: 0.3580 - val_accuracy: 0.8061 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 84/600\n",
            "1041/1041 - 13s - loss: 0.3624 - accuracy: 0.8081 - val_loss: 0.3580 - val_accuracy: 0.8061 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 85/600\n",
            "1041/1041 - 13s - loss: 0.3626 - accuracy: 0.8075 - val_loss: 0.3580 - val_accuracy: 0.8061 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 86/600\n",
            "1041/1041 - 13s - loss: 0.3624 - accuracy: 0.8084 - val_loss: 0.3580 - val_accuracy: 0.8061 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 87/600\n",
            "1041/1041 - 13s - loss: 0.3624 - accuracy: 0.8078 - val_loss: 0.3580 - val_accuracy: 0.8061 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 88/600\n",
            "1041/1041 - 13s - loss: 0.3624 - accuracy: 0.8096 - val_loss: 0.3580 - val_accuracy: 0.8061 - lr: 3.0518e-07 - 13s/epoch - 13ms/step\n",
            "Epoch 89/600\n",
            "1041/1041 - 13s - loss: 0.3625 - accuracy: 0.8078 - val_loss: 0.3580 - val_accuracy: 0.8061 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 90/600\n",
            "1041/1041 - 13s - loss: 0.3625 - accuracy: 0.8076 - val_loss: 0.3580 - val_accuracy: 0.8061 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 91/600\n",
            "1041/1041 - 13s - loss: 0.3624 - accuracy: 0.8081 - val_loss: 0.3580 - val_accuracy: 0.8061 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 92/600\n",
            "1041/1041 - 13s - loss: 0.3625 - accuracy: 0.8072 - val_loss: 0.3580 - val_accuracy: 0.8061 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 93/600\n",
            "1041/1041 - 13s - loss: 0.3626 - accuracy: 0.8070 - val_loss: 0.3580 - val_accuracy: 0.8061 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 94/600\n",
            "1041/1041 - 13s - loss: 0.3625 - accuracy: 0.8082 - val_loss: 0.3580 - val_accuracy: 0.8062 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 95/600\n",
            "1041/1041 - 13s - loss: 0.3624 - accuracy: 0.8083 - val_loss: 0.3580 - val_accuracy: 0.8062 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 96/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8088 - val_loss: 0.3580 - val_accuracy: 0.8062 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 97/600\n",
            "1041/1041 - 13s - loss: 0.3624 - accuracy: 0.8084 - val_loss: 0.3580 - val_accuracy: 0.8061 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 98/600\n",
            "1041/1041 - 13s - loss: 0.3626 - accuracy: 0.8079 - val_loss: 0.3580 - val_accuracy: 0.8061 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12 13]\n",
            " [14 11  3  2 12  1]\n",
            " [14 11  3  2 12 13]\n",
            " ...\n",
            " [14 11  3  2 12  5]\n",
            " [14 11  3  2 12  7]\n",
            " [14 11  3  2 12  7]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12 13  7]\n",
            " [14 11  3 ... 12  1  7]\n",
            " [14 11  3 ... 12 13  7]\n",
            " ...\n",
            " [14 11  3 ... 12  5 13]\n",
            " [14 11  3 ... 12  7  1]\n",
            " [14 11  3 ... 12  7 13]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ... 13  7  5]\n",
            " [14 11  3 ...  1  7  5]\n",
            " [14 11  3 ... 13  7  5]\n",
            " ...\n",
            " [14 11  3 ...  5 13  7]\n",
            " [14 11  3 ...  7  1  5]\n",
            " [14 11  3 ...  7 13  9]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ...  7  5  9]\n",
            " [14 11  3 ...  7  5 13]\n",
            " [14 11  3 ...  7  5  1]\n",
            " ...\n",
            " [14 11  3 ... 13  7  1]\n",
            " [14 11  3 ...  1  5  9]\n",
            " [14 11  3 ... 13  9  5]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ...  5  9  1]\n",
            " [14 11  3 ...  5 13  9]\n",
            " [14 11  3 ...  5  1  9]\n",
            " ...\n",
            " [14 11  3 ...  7  1  9]\n",
            " [14 11  3 ...  5  9 13]\n",
            " [14 11  3 ...  9  5  1]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ...  9  1  8]\n",
            " [14 11  3 ... 13  9  8]\n",
            " [14 11  3 ...  1  9  8]\n",
            " ...\n",
            " [14 11  3 ...  1  9  8]\n",
            " [14 11  3 ...  9 13  8]\n",
            " [14 11  3 ...  5  1  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ...  1  8 10]\n",
            " [14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  9  8 10]\n",
            " ...\n",
            " [14 11  3 ...  9  8 10]\n",
            " [14 11  3 ... 13  8 10]\n",
            " [14 11  3 ...  1  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_42 (Bidirecti  (None, 128)              40960     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,895\n",
            "Trainable params: 42,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1042/1042 - 18s - loss: 0.7206 - accuracy: 0.7832 - val_loss: 0.4797 - val_accuracy: 0.8074 - lr: 0.0050 - 18s/epoch - 17ms/step\n",
            "Epoch 2/600\n",
            "1042/1042 - 13s - loss: 0.4817 - accuracy: 0.8052 - val_loss: 0.4424 - val_accuracy: 0.8057 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 3/600\n",
            "1042/1042 - 13s - loss: 0.4637 - accuracy: 0.8057 - val_loss: 0.4508 - val_accuracy: 0.8044 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 4/600\n",
            "1042/1042 - 13s - loss: 0.4574 - accuracy: 0.8059 - val_loss: 0.4564 - val_accuracy: 0.8066 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 5/600\n",
            "1042/1042 - 13s - loss: 0.4539 - accuracy: 0.8066 - val_loss: 0.4332 - val_accuracy: 0.8052 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 6/600\n",
            "1042/1042 - 13s - loss: 0.4523 - accuracy: 0.8066 - val_loss: 0.4330 - val_accuracy: 0.8069 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 7/600\n",
            "1042/1042 - 13s - loss: 0.4665 - accuracy: 0.8060 - val_loss: 0.4309 - val_accuracy: 0.8055 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 8/600\n",
            "1042/1042 - 13s - loss: 0.4412 - accuracy: 0.8064 - val_loss: 0.4180 - val_accuracy: 0.8074 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 9/600\n",
            "1042/1042 - 13s - loss: 0.4445 - accuracy: 0.8055 - val_loss: 0.4209 - val_accuracy: 0.8065 - lr: 0.0050 - 13s/epoch - 13ms/step\n",
            "Epoch 10/600\n",
            "1042/1042 - 13s - loss: 0.4577 - accuracy: 0.8048 - val_loss: 0.4297 - val_accuracy: 0.8055 - lr: 0.0050 - 13s/epoch - 13ms/step\n",
            "Epoch 11/600\n",
            "1042/1042 - 13s - loss: 0.4392 - accuracy: 0.8056 - val_loss: 0.4378 - val_accuracy: 0.8050 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 12/600\n",
            "1042/1042 - 13s - loss: 0.4134 - accuracy: 0.8069 - val_loss: 0.4090 - val_accuracy: 0.8054 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 13/600\n",
            "1042/1042 - 13s - loss: 0.4130 - accuracy: 0.8051 - val_loss: 0.3968 - val_accuracy: 0.8063 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 14/600\n",
            "1042/1042 - 13s - loss: 0.4145 - accuracy: 0.8063 - val_loss: 0.4051 - val_accuracy: 0.8054 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 15/600\n",
            "1042/1042 - 13s - loss: 0.4106 - accuracy: 0.8060 - val_loss: 0.3998 - val_accuracy: 0.8052 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 16/600\n",
            "1042/1042 - 13s - loss: 0.4108 - accuracy: 0.8060 - val_loss: 0.3975 - val_accuracy: 0.8045 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 17/600\n",
            "1042/1042 - 13s - loss: 0.3938 - accuracy: 0.8054 - val_loss: 0.3834 - val_accuracy: 0.8061 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 18/600\n",
            "1042/1042 - 13s - loss: 0.3924 - accuracy: 0.8055 - val_loss: 0.3887 - val_accuracy: 0.8051 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 19/600\n",
            "1042/1042 - 13s - loss: 0.3928 - accuracy: 0.8052 - val_loss: 0.3815 - val_accuracy: 0.8057 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 20/600\n",
            "1042/1042 - 13s - loss: 0.3923 - accuracy: 0.8067 - val_loss: 0.3825 - val_accuracy: 0.8066 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 21/600\n",
            "1042/1042 - 13s - loss: 0.3911 - accuracy: 0.8072 - val_loss: 0.3811 - val_accuracy: 0.8053 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 22/600\n",
            "1042/1042 - 13s - loss: 0.3912 - accuracy: 0.8065 - val_loss: 0.3893 - val_accuracy: 0.8064 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 23/600\n",
            "1042/1042 - 13s - loss: 0.3899 - accuracy: 0.8070 - val_loss: 0.3818 - val_accuracy: 0.8036 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 24/600\n",
            "1042/1042 - 13s - loss: 0.3915 - accuracy: 0.8050 - val_loss: 0.3801 - val_accuracy: 0.8068 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 25/600\n",
            "1042/1042 - 13s - loss: 0.3903 - accuracy: 0.8050 - val_loss: 0.3895 - val_accuracy: 0.8052 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 26/600\n",
            "1042/1042 - 13s - loss: 0.3904 - accuracy: 0.8070 - val_loss: 0.3816 - val_accuracy: 0.8050 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 27/600\n",
            "1042/1042 - 13s - loss: 0.3899 - accuracy: 0.8067 - val_loss: 0.3792 - val_accuracy: 0.8063 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 28/600\n",
            "1042/1042 - 13s - loss: 0.3895 - accuracy: 0.8059 - val_loss: 0.3791 - val_accuracy: 0.8052 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 29/600\n",
            "1042/1042 - 13s - loss: 0.3907 - accuracy: 0.8066 - val_loss: 0.3804 - val_accuracy: 0.8081 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 30/600\n",
            "1042/1042 - 13s - loss: 0.3900 - accuracy: 0.8065 - val_loss: 0.3795 - val_accuracy: 0.8050 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 31/600\n",
            "1042/1042 - 13s - loss: 0.3892 - accuracy: 0.8059 - val_loss: 0.3840 - val_accuracy: 0.8055 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 32/600\n",
            "1042/1042 - 13s - loss: 0.3797 - accuracy: 0.8072 - val_loss: 0.3721 - val_accuracy: 0.8057 - lr: 6.2500e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 33/600\n",
            "1042/1042 - 13s - loss: 0.3796 - accuracy: 0.8053 - val_loss: 0.3712 - val_accuracy: 0.8066 - lr: 6.2500e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 34/600\n",
            "1042/1042 - 13s - loss: 0.3796 - accuracy: 0.8051 - val_loss: 0.3713 - val_accuracy: 0.8080 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 35/600\n",
            "1042/1042 - 13s - loss: 0.3786 - accuracy: 0.8066 - val_loss: 0.3733 - val_accuracy: 0.8051 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 36/600\n",
            "1042/1042 - 13s - loss: 0.3784 - accuracy: 0.8065 - val_loss: 0.3708 - val_accuracy: 0.8068 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 37/600\n",
            "1042/1042 - 13s - loss: 0.3778 - accuracy: 0.8060 - val_loss: 0.3713 - val_accuracy: 0.8053 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 38/600\n",
            "1042/1042 - 13s - loss: 0.3783 - accuracy: 0.8064 - val_loss: 0.3731 - val_accuracy: 0.8060 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 39/600\n",
            "1042/1042 - 13s - loss: 0.3789 - accuracy: 0.8054 - val_loss: 0.3694 - val_accuracy: 0.8055 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 40/600\n",
            "1042/1042 - 13s - loss: 0.3776 - accuracy: 0.8068 - val_loss: 0.3779 - val_accuracy: 0.8058 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 41/600\n",
            "1042/1042 - 13s - loss: 0.3777 - accuracy: 0.8062 - val_loss: 0.3701 - val_accuracy: 0.8074 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 42/600\n",
            "1042/1042 - 13s - loss: 0.3780 - accuracy: 0.8060 - val_loss: 0.3695 - val_accuracy: 0.8078 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 43/600\n",
            "1042/1042 - 13s - loss: 0.3726 - accuracy: 0.8058 - val_loss: 0.3655 - val_accuracy: 0.8061 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 44/600\n",
            "1042/1042 - 13s - loss: 0.3720 - accuracy: 0.8074 - val_loss: 0.3649 - val_accuracy: 0.8070 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 45/600\n",
            "1042/1042 - 13s - loss: 0.3717 - accuracy: 0.8064 - val_loss: 0.3684 - val_accuracy: 0.8067 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 46/600\n",
            "1042/1042 - 13s - loss: 0.3713 - accuracy: 0.8067 - val_loss: 0.3656 - val_accuracy: 0.8069 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 47/600\n",
            "1042/1042 - 13s - loss: 0.3711 - accuracy: 0.8074 - val_loss: 0.3659 - val_accuracy: 0.8058 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 48/600\n",
            "1042/1042 - 13s - loss: 0.3686 - accuracy: 0.8065 - val_loss: 0.3633 - val_accuracy: 0.8079 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 49/600\n",
            "1042/1042 - 13s - loss: 0.3685 - accuracy: 0.8069 - val_loss: 0.3645 - val_accuracy: 0.8066 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 50/600\n",
            "1042/1042 - 13s - loss: 0.3681 - accuracy: 0.8074 - val_loss: 0.3637 - val_accuracy: 0.8070 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 51/600\n",
            "1042/1042 - 13s - loss: 0.3682 - accuracy: 0.8068 - val_loss: 0.3625 - val_accuracy: 0.8075 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 52/600\n",
            "1042/1042 - 13s - loss: 0.3679 - accuracy: 0.8072 - val_loss: 0.3635 - val_accuracy: 0.8061 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 53/600\n",
            "1042/1042 - 13s - loss: 0.3680 - accuracy: 0.8055 - val_loss: 0.3624 - val_accuracy: 0.8061 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 54/600\n",
            "1042/1042 - 13s - loss: 0.3679 - accuracy: 0.8069 - val_loss: 0.3626 - val_accuracy: 0.8053 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 55/600\n",
            "1042/1042 - 13s - loss: 0.3663 - accuracy: 0.8065 - val_loss: 0.3615 - val_accuracy: 0.8044 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 56/600\n",
            "1042/1042 - 13s - loss: 0.3661 - accuracy: 0.8076 - val_loss: 0.3617 - val_accuracy: 0.8066 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 57/600\n",
            "1042/1042 - 13s - loss: 0.3662 - accuracy: 0.8063 - val_loss: 0.3619 - val_accuracy: 0.8053 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 58/600\n",
            "1042/1042 - 13s - loss: 0.3658 - accuracy: 0.8069 - val_loss: 0.3623 - val_accuracy: 0.8050 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 59/600\n",
            "1042/1042 - 13s - loss: 0.3653 - accuracy: 0.8074 - val_loss: 0.3608 - val_accuracy: 0.8058 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 60/600\n",
            "1042/1042 - 13s - loss: 0.3652 - accuracy: 0.8061 - val_loss: 0.3608 - val_accuracy: 0.8058 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 61/600\n",
            "1042/1042 - 13s - loss: 0.3652 - accuracy: 0.8068 - val_loss: 0.3606 - val_accuracy: 0.8055 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 62/600\n",
            "1042/1042 - 13s - loss: 0.3651 - accuracy: 0.8066 - val_loss: 0.3605 - val_accuracy: 0.8073 - lr: 3.9062e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 63/600\n",
            "1042/1042 - 13s - loss: 0.3652 - accuracy: 0.8060 - val_loss: 0.3605 - val_accuracy: 0.8081 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 64/600\n",
            "1042/1042 - 13s - loss: 0.3649 - accuracy: 0.8075 - val_loss: 0.3610 - val_accuracy: 0.8061 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 65/600\n",
            "1042/1042 - 13s - loss: 0.3651 - accuracy: 0.8050 - val_loss: 0.3604 - val_accuracy: 0.8059 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 66/600\n",
            "1042/1042 - 13s - loss: 0.3644 - accuracy: 0.8070 - val_loss: 0.3603 - val_accuracy: 0.8068 - lr: 1.9531e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 67/600\n",
            "1042/1042 - 13s - loss: 0.3645 - accuracy: 0.8060 - val_loss: 0.3604 - val_accuracy: 0.8050 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 68/600\n",
            "1042/1042 - 13s - loss: 0.3645 - accuracy: 0.8070 - val_loss: 0.3601 - val_accuracy: 0.8071 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 69/600\n",
            "1042/1042 - 13s - loss: 0.3644 - accuracy: 0.8082 - val_loss: 0.3603 - val_accuracy: 0.8055 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 70/600\n",
            "1042/1042 - 13s - loss: 0.3644 - accuracy: 0.8066 - val_loss: 0.3602 - val_accuracy: 0.8061 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 71/600\n",
            "1042/1042 - 13s - loss: 0.3642 - accuracy: 0.8075 - val_loss: 0.3602 - val_accuracy: 0.8063 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 72/600\n",
            "1042/1042 - 13s - loss: 0.3640 - accuracy: 0.8085 - val_loss: 0.3600 - val_accuracy: 0.8060 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 73/600\n",
            "1042/1042 - 13s - loss: 0.3641 - accuracy: 0.8083 - val_loss: 0.3600 - val_accuracy: 0.8064 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 74/600\n",
            "1042/1042 - 13s - loss: 0.3639 - accuracy: 0.8081 - val_loss: 0.3600 - val_accuracy: 0.8059 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 75/600\n",
            "1042/1042 - 13s - loss: 0.3641 - accuracy: 0.8073 - val_loss: 0.3599 - val_accuracy: 0.8059 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 76/600\n",
            "1042/1042 - 13s - loss: 0.3642 - accuracy: 0.8074 - val_loss: 0.3600 - val_accuracy: 0.8054 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 77/600\n",
            "1042/1042 - 13s - loss: 0.3639 - accuracy: 0.8071 - val_loss: 0.3599 - val_accuracy: 0.8055 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 78/600\n",
            "1042/1042 - 13s - loss: 0.3640 - accuracy: 0.8076 - val_loss: 0.3598 - val_accuracy: 0.8079 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 79/600\n",
            "1042/1042 - 13s - loss: 0.3641 - accuracy: 0.8067 - val_loss: 0.3599 - val_accuracy: 0.8051 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 80/600\n",
            "1042/1042 - 13s - loss: 0.3639 - accuracy: 0.8077 - val_loss: 0.3599 - val_accuracy: 0.8045 - lr: 4.8828e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 81/600\n",
            "1042/1042 - 13s - loss: 0.3638 - accuracy: 0.8078 - val_loss: 0.3598 - val_accuracy: 0.8064 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 82/600\n",
            "1042/1042 - 13s - loss: 0.3639 - accuracy: 0.8090 - val_loss: 0.3598 - val_accuracy: 0.8058 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 83/600\n",
            "1042/1042 - 13s - loss: 0.3640 - accuracy: 0.8074 - val_loss: 0.3598 - val_accuracy: 0.8058 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 84/600\n",
            "1042/1042 - 13s - loss: 0.3639 - accuracy: 0.8080 - val_loss: 0.3598 - val_accuracy: 0.8058 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 85/600\n",
            "1042/1042 - 13s - loss: 0.3638 - accuracy: 0.8075 - val_loss: 0.3598 - val_accuracy: 0.8058 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 86/600\n",
            "1042/1042 - 13s - loss: 0.3638 - accuracy: 0.8083 - val_loss: 0.3598 - val_accuracy: 0.8061 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 87/600\n",
            "1042/1042 - 13s - loss: 0.3637 - accuracy: 0.8084 - val_loss: 0.3598 - val_accuracy: 0.8059 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 88/600\n",
            "1042/1042 - 13s - loss: 0.3640 - accuracy: 0.8072 - val_loss: 0.3598 - val_accuracy: 0.8061 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 89/600\n",
            "1042/1042 - 13s - loss: 0.3639 - accuracy: 0.8077 - val_loss: 0.3598 - val_accuracy: 0.8059 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 90/600\n",
            "1042/1042 - 13s - loss: 0.3639 - accuracy: 0.8084 - val_loss: 0.3598 - val_accuracy: 0.8061 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 91/600\n",
            "1042/1042 - 13s - loss: 0.3638 - accuracy: 0.8082 - val_loss: 0.3598 - val_accuracy: 0.8059 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 92/600\n",
            "1042/1042 - 12s - loss: 0.3637 - accuracy: 0.8080 - val_loss: 0.3598 - val_accuracy: 0.8058 - lr: 3.0518e-07 - 12s/epoch - 12ms/step\n",
            "Epoch 93/600\n",
            "1042/1042 - 13s - loss: 0.3637 - accuracy: 0.8083 - val_loss: 0.3598 - val_accuracy: 0.8060 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 94/600\n",
            "1042/1042 - 13s - loss: 0.3638 - accuracy: 0.8082 - val_loss: 0.3598 - val_accuracy: 0.8060 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 95/600\n",
            "1042/1042 - 13s - loss: 0.3638 - accuracy: 0.8076 - val_loss: 0.3598 - val_accuracy: 0.8060 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 96/600\n",
            "1042/1042 - 13s - loss: 0.3639 - accuracy: 0.8075 - val_loss: 0.3598 - val_accuracy: 0.8060 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 97/600\n",
            "1042/1042 - 12s - loss: 0.3640 - accuracy: 0.8064 - val_loss: 0.3598 - val_accuracy: 0.8060 - lr: 7.6294e-08 - 12s/epoch - 12ms/step\n",
            "Epoch 98/600\n",
            "1042/1042 - 13s - loss: 0.3638 - accuracy: 0.8072 - val_loss: 0.3598 - val_accuracy: 0.8060 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12 13]\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12  9]\n",
            " ...\n",
            " [14 11  3  2 12  7]\n",
            " [14 11  3  2 12  1]\n",
            " [14 11  3  2 12  9]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12 13  1]\n",
            " [14 11  3 ... 12 13  9]\n",
            " [14 11  3 ... 12  9 13]\n",
            " ...\n",
            " [14 11  3 ... 12  7  5]\n",
            " [14 11  3 ... 12  1  7]\n",
            " [14 11  3 ... 12  9 13]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ... 13  1  5]\n",
            " [14 11  3 ... 13  9  7]\n",
            " [14 11  3 ...  9 13  7]\n",
            " ...\n",
            " [14 11  3 ...  7  5  1]\n",
            " [14 11  3 ...  1  7 13]\n",
            " [14 11  3 ...  9 13  7]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ...  1  5  9]\n",
            " [14 11  3 ...  9  7  1]\n",
            " [14 11  3 ... 13  7  1]\n",
            " ...\n",
            " [14 11  3 ...  5  1 13]\n",
            " [14 11  3 ...  7 13  5]\n",
            " [14 11  3 ... 13  7  1]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ...  5  9  7]\n",
            " [14 11  3 ...  7  1  5]\n",
            " [14 11  3 ...  7  1  5]\n",
            " ...\n",
            " [14 11  3 ...  1 13  9]\n",
            " [14 11  3 ... 13  5  9]\n",
            " [14 11  3 ...  7  1  5]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ...  9  7  8]\n",
            " [14 11  3 ...  1  5  8]\n",
            " [14 11  3 ...  1  5  8]\n",
            " ...\n",
            " [14 11  3 ... 13  9  8]\n",
            " [14 11  3 ...  5  9  8]\n",
            " [14 11  3 ...  1  5  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ...  7  8 10]\n",
            " [14 11  3 ...  5  8 10]\n",
            " [14 11  3 ...  5  8 10]\n",
            " ...\n",
            " [14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  5  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_43 (Bidirecti  (None, 128)              40960     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,895\n",
            "Trainable params: 42,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1041/1041 - 17s - loss: 0.7145 - accuracy: 0.7844 - val_loss: 0.4758 - val_accuracy: 0.8045 - lr: 0.0050 - 17s/epoch - 17ms/step\n",
            "Epoch 2/600\n",
            "1041/1041 - 13s - loss: 0.4812 - accuracy: 0.8069 - val_loss: 0.4543 - val_accuracy: 0.8058 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 3/600\n",
            "1041/1041 - 13s - loss: 0.4640 - accuracy: 0.8058 - val_loss: 0.4382 - val_accuracy: 0.8036 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 4/600\n",
            "1041/1041 - 13s - loss: 0.4571 - accuracy: 0.8063 - val_loss: 0.4280 - val_accuracy: 0.8081 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 5/600\n",
            "1041/1041 - 13s - loss: 0.5100 - accuracy: 0.8050 - val_loss: 0.4625 - val_accuracy: 0.8051 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 6/600\n",
            "1041/1041 - 13s - loss: 0.4536 - accuracy: 0.8059 - val_loss: 0.4263 - val_accuracy: 0.8073 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 7/600\n",
            "1041/1041 - 13s - loss: 0.4450 - accuracy: 0.8054 - val_loss: 0.4387 - val_accuracy: 0.8066 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 8/600\n",
            "1041/1041 - 13s - loss: 0.4450 - accuracy: 0.8061 - val_loss: 0.4312 - val_accuracy: 0.8065 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 9/600\n",
            "1041/1041 - 13s - loss: 0.4429 - accuracy: 0.8059 - val_loss: 0.4528 - val_accuracy: 0.8071 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 10/600\n",
            "1041/1041 - 13s - loss: 0.4156 - accuracy: 0.8062 - val_loss: 0.4024 - val_accuracy: 0.8052 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 11/600\n",
            "1041/1041 - 12s - loss: 0.4133 - accuracy: 0.8059 - val_loss: 0.4116 - val_accuracy: 0.8047 - lr: 0.0025 - 12s/epoch - 12ms/step\n",
            "Epoch 12/600\n",
            "1041/1041 - 13s - loss: 0.4114 - accuracy: 0.8058 - val_loss: 0.4054 - val_accuracy: 0.8047 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 13/600\n",
            "1041/1041 - 13s - loss: 0.4121 - accuracy: 0.8055 - val_loss: 0.4028 - val_accuracy: 0.8050 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 14/600\n",
            "1041/1041 - 13s - loss: 0.3941 - accuracy: 0.8067 - val_loss: 0.3832 - val_accuracy: 0.8070 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 15/600\n",
            "1041/1041 - 13s - loss: 0.3934 - accuracy: 0.8070 - val_loss: 0.3831 - val_accuracy: 0.8083 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 16/600\n",
            "1041/1041 - 13s - loss: 0.3923 - accuracy: 0.8065 - val_loss: 0.3808 - val_accuracy: 0.8055 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 17/600\n",
            "1041/1041 - 13s - loss: 0.3916 - accuracy: 0.8068 - val_loss: 0.3871 - val_accuracy: 0.8076 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 18/600\n",
            "1041/1041 - 13s - loss: 0.3910 - accuracy: 0.8060 - val_loss: 0.3854 - val_accuracy: 0.8049 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 19/600\n",
            "1041/1041 - 13s - loss: 0.3915 - accuracy: 0.8055 - val_loss: 0.3797 - val_accuracy: 0.8069 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 20/600\n",
            "1041/1041 - 13s - loss: 0.3914 - accuracy: 0.8059 - val_loss: 0.3802 - val_accuracy: 0.8047 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 21/600\n",
            "1041/1041 - 13s - loss: 0.3902 - accuracy: 0.8062 - val_loss: 0.3867 - val_accuracy: 0.8056 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 22/600\n",
            "1041/1041 - 13s - loss: 0.3896 - accuracy: 0.8062 - val_loss: 0.3844 - val_accuracy: 0.8071 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 23/600\n",
            "1041/1041 - 13s - loss: 0.3806 - accuracy: 0.8058 - val_loss: 0.3736 - val_accuracy: 0.8047 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 24/600\n",
            "1041/1041 - 13s - loss: 0.3796 - accuracy: 0.8052 - val_loss: 0.3755 - val_accuracy: 0.8045 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 25/600\n",
            "1041/1041 - 13s - loss: 0.3801 - accuracy: 0.8053 - val_loss: 0.3720 - val_accuracy: 0.8075 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 26/600\n",
            "1041/1041 - 13s - loss: 0.3792 - accuracy: 0.8067 - val_loss: 0.3747 - val_accuracy: 0.8076 - lr: 6.2500e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 27/600\n",
            "1041/1041 - 13s - loss: 0.3789 - accuracy: 0.8056 - val_loss: 0.3720 - val_accuracy: 0.8069 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 28/600\n",
            "1041/1041 - 13s - loss: 0.3787 - accuracy: 0.8065 - val_loss: 0.3716 - val_accuracy: 0.8044 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 29/600\n",
            "1041/1041 - 13s - loss: 0.3785 - accuracy: 0.8057 - val_loss: 0.3707 - val_accuracy: 0.8076 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 30/600\n",
            "1041/1041 - 13s - loss: 0.3780 - accuracy: 0.8067 - val_loss: 0.3717 - val_accuracy: 0.8055 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 31/600\n",
            "1041/1041 - 13s - loss: 0.3776 - accuracy: 0.8071 - val_loss: 0.3694 - val_accuracy: 0.8065 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 32/600\n",
            "1041/1041 - 13s - loss: 0.3780 - accuracy: 0.8059 - val_loss: 0.3751 - val_accuracy: 0.8077 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 33/600\n",
            "1041/1041 - 13s - loss: 0.3781 - accuracy: 0.8060 - val_loss: 0.3741 - val_accuracy: 0.8077 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 34/600\n",
            "1041/1041 - 13s - loss: 0.3770 - accuracy: 0.8069 - val_loss: 0.3702 - val_accuracy: 0.8030 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 35/600\n",
            "1041/1041 - 13s - loss: 0.3721 - accuracy: 0.8063 - val_loss: 0.3660 - val_accuracy: 0.8054 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 36/600\n",
            "1041/1041 - 13s - loss: 0.3718 - accuracy: 0.8068 - val_loss: 0.3670 - val_accuracy: 0.8055 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 37/600\n",
            "1041/1041 - 13s - loss: 0.3714 - accuracy: 0.8059 - val_loss: 0.3655 - val_accuracy: 0.8052 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 38/600\n",
            "1041/1041 - 13s - loss: 0.3712 - accuracy: 0.8056 - val_loss: 0.3651 - val_accuracy: 0.8060 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 39/600\n",
            "1041/1041 - 13s - loss: 0.3710 - accuracy: 0.8059 - val_loss: 0.3670 - val_accuracy: 0.8065 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 40/600\n",
            "1041/1041 - 13s - loss: 0.3709 - accuracy: 0.8058 - val_loss: 0.3642 - val_accuracy: 0.8060 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 41/600\n",
            "1041/1041 - 13s - loss: 0.3705 - accuracy: 0.8069 - val_loss: 0.3654 - val_accuracy: 0.8064 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 42/600\n",
            "1041/1041 - 13s - loss: 0.3702 - accuracy: 0.8070 - val_loss: 0.3648 - val_accuracy: 0.8064 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 43/600\n",
            "1041/1041 - 13s - loss: 0.3707 - accuracy: 0.8055 - val_loss: 0.3664 - val_accuracy: 0.8074 - lr: 3.1250e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 44/600\n",
            "1041/1041 - 13s - loss: 0.3674 - accuracy: 0.8066 - val_loss: 0.3622 - val_accuracy: 0.8060 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 45/600\n",
            "1041/1041 - 13s - loss: 0.3672 - accuracy: 0.8054 - val_loss: 0.3618 - val_accuracy: 0.8050 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 46/600\n",
            "1041/1041 - 13s - loss: 0.3670 - accuracy: 0.8067 - val_loss: 0.3619 - val_accuracy: 0.8047 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 47/600\n",
            "1041/1041 - 13s - loss: 0.3670 - accuracy: 0.8070 - val_loss: 0.3627 - val_accuracy: 0.8061 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 48/600\n",
            "1041/1041 - 13s - loss: 0.3666 - accuracy: 0.8063 - val_loss: 0.3619 - val_accuracy: 0.8051 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 49/600\n",
            "1041/1041 - 13s - loss: 0.3652 - accuracy: 0.8057 - val_loss: 0.3607 - val_accuracy: 0.8076 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 50/600\n",
            "1041/1041 - 13s - loss: 0.3649 - accuracy: 0.8066 - val_loss: 0.3601 - val_accuracy: 0.8087 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 51/600\n",
            "1041/1041 - 13s - loss: 0.3647 - accuracy: 0.8081 - val_loss: 0.3604 - val_accuracy: 0.8067 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 52/600\n",
            "1041/1041 - 13s - loss: 0.3647 - accuracy: 0.8072 - val_loss: 0.3607 - val_accuracy: 0.8061 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 53/600\n",
            "1041/1041 - 13s - loss: 0.3647 - accuracy: 0.8062 - val_loss: 0.3603 - val_accuracy: 0.8044 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 54/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8073 - val_loss: 0.3599 - val_accuracy: 0.8075 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 55/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8068 - val_loss: 0.3597 - val_accuracy: 0.8074 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 56/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8057 - val_loss: 0.3596 - val_accuracy: 0.8067 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 57/600\n",
            "1041/1041 - 13s - loss: 0.3636 - accuracy: 0.8075 - val_loss: 0.3598 - val_accuracy: 0.8075 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 58/600\n",
            "1041/1041 - 13s - loss: 0.3636 - accuracy: 0.8075 - val_loss: 0.3596 - val_accuracy: 0.8071 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 59/600\n",
            "1041/1041 - 13s - loss: 0.3636 - accuracy: 0.8059 - val_loss: 0.3593 - val_accuracy: 0.8059 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 60/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8060 - val_loss: 0.3596 - val_accuracy: 0.8047 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 61/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8068 - val_loss: 0.3595 - val_accuracy: 0.8057 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 62/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8067 - val_loss: 0.3596 - val_accuracy: 0.8058 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 63/600\n",
            "1041/1041 - 13s - loss: 0.3630 - accuracy: 0.8074 - val_loss: 0.3591 - val_accuracy: 0.8047 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 64/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8072 - val_loss: 0.3592 - val_accuracy: 0.8055 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 65/600\n",
            "1041/1041 - 13s - loss: 0.3628 - accuracy: 0.8077 - val_loss: 0.3590 - val_accuracy: 0.8049 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 66/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8070 - val_loss: 0.3590 - val_accuracy: 0.8071 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 67/600\n",
            "1041/1041 - 13s - loss: 0.3627 - accuracy: 0.8069 - val_loss: 0.3589 - val_accuracy: 0.8057 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 68/600\n",
            "1041/1041 - 13s - loss: 0.3625 - accuracy: 0.8073 - val_loss: 0.3588 - val_accuracy: 0.8044 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 69/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8080 - val_loss: 0.3589 - val_accuracy: 0.8053 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 70/600\n",
            "1041/1041 - 13s - loss: 0.3625 - accuracy: 0.8076 - val_loss: 0.3590 - val_accuracy: 0.8070 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 71/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8080 - val_loss: 0.3587 - val_accuracy: 0.8059 - lr: 4.8828e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 72/600\n",
            "1041/1041 - 13s - loss: 0.3624 - accuracy: 0.8076 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 4.8828e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 73/600\n",
            "1041/1041 - 13s - loss: 0.3625 - accuracy: 0.8076 - val_loss: 0.3588 - val_accuracy: 0.8051 - lr: 4.8828e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 74/600\n",
            "1041/1041 - 13s - loss: 0.3624 - accuracy: 0.8074 - val_loss: 0.3587 - val_accuracy: 0.8076 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 75/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8076 - val_loss: 0.3587 - val_accuracy: 0.8068 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 76/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8077 - val_loss: 0.3587 - val_accuracy: 0.8064 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 77/600\n",
            "1041/1041 - 13s - loss: 0.3621 - accuracy: 0.8090 - val_loss: 0.3587 - val_accuracy: 0.8065 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 78/600\n",
            "1041/1041 - 13s - loss: 0.3624 - accuracy: 0.8073 - val_loss: 0.3587 - val_accuracy: 0.8070 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 79/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8081 - val_loss: 0.3587 - val_accuracy: 0.8068 - lr: 1.2207e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 80/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8082 - val_loss: 0.3587 - val_accuracy: 0.8061 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 81/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8082 - val_loss: 0.3587 - val_accuracy: 0.8061 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 82/600\n",
            "1041/1041 - 13s - loss: 0.3620 - accuracy: 0.8096 - val_loss: 0.3586 - val_accuracy: 0.8064 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 83/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8079 - val_loss: 0.3586 - val_accuracy: 0.8060 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 84/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8081 - val_loss: 0.3586 - val_accuracy: 0.8061 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 85/600\n",
            "1041/1041 - 13s - loss: 0.3621 - accuracy: 0.8087 - val_loss: 0.3586 - val_accuracy: 0.8064 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 86/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8080 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 87/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8085 - val_loss: 0.3586 - val_accuracy: 0.8064 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 88/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8074 - val_loss: 0.3586 - val_accuracy: 0.8064 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 89/600\n",
            "1041/1041 - 13s - loss: 0.3621 - accuracy: 0.8084 - val_loss: 0.3586 - val_accuracy: 0.8062 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 90/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8070 - val_loss: 0.3586 - val_accuracy: 0.8064 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 91/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8083 - val_loss: 0.3586 - val_accuracy: 0.8069 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 92/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8080 - val_loss: 0.3586 - val_accuracy: 0.8069 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 93/600\n",
            "1041/1041 - 13s - loss: 0.3621 - accuracy: 0.8075 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 94/600\n",
            "1041/1041 - 13s - loss: 0.3624 - accuracy: 0.8080 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 95/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8075 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 96/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8076 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 97/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8080 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 98/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8076 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 99/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8082 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 100/600\n",
            "1041/1041 - 13s - loss: 0.3621 - accuracy: 0.8086 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 101/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8079 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 102/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8083 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 9.5367e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 103/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8082 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 9.5367e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 104/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8078 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 9.5367e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 105/600\n",
            "1041/1041 - 13s - loss: 0.3621 - accuracy: 0.8086 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 4.7684e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 106/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8075 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 4.7684e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 107/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8073 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 4.7684e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 108/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8079 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 2.3842e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 109/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8081 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 2.3842e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 110/600\n",
            "1041/1041 - 13s - loss: 0.3622 - accuracy: 0.8079 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 2.3842e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 111/600\n",
            "1041/1041 - 13s - loss: 0.3621 - accuracy: 0.8083 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 1.1921e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 112/600\n",
            "1041/1041 - 13s - loss: 0.3623 - accuracy: 0.8074 - val_loss: 0.3586 - val_accuracy: 0.8070 - lr: 1.1921e-09 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12  9]\n",
            " [14 11  3  2 12  5]\n",
            " [14 11  3  2 12  9]\n",
            " ...\n",
            " [14 11  3  2 12  7]\n",
            " [14 11  3  2 12  9]\n",
            " [14 11  3  2 12  5]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12  9  5]\n",
            " [14 11  3 ... 12  5  9]\n",
            " [14 11  3 ... 12  9  5]\n",
            " ...\n",
            " [14 11  3 ... 12  7  5]\n",
            " [14 11  3 ... 12  9  1]\n",
            " [14 11  3 ... 12  5 13]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ...  9  5  1]\n",
            " [14 11  3 ...  5  9  7]\n",
            " [14 11  3 ...  9  5  7]\n",
            " ...\n",
            " [14 11  3 ...  7  5  9]\n",
            " [14 11  3 ...  9  1  7]\n",
            " [14 11  3 ...  5 13  9]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ...  5  1 13]\n",
            " [14 11  3 ...  9  7  1]\n",
            " [14 11  3 ...  5  7  1]\n",
            " ...\n",
            " [14 11  3 ...  5  9  1]\n",
            " [14 11  3 ...  1  7  5]\n",
            " [14 11  3 ... 13  9  7]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ...  1 13  7]\n",
            " [14 11  3 ...  7  1 13]\n",
            " [14 11  3 ...  7  1 13]\n",
            " ...\n",
            " [14 11  3 ...  9  1 13]\n",
            " [14 11  3 ...  7  5 13]\n",
            " [14 11  3 ...  9  7  1]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ... 13  7  8]\n",
            " [14 11  3 ...  1 13  8]\n",
            " [14 11  3 ...  1 13  8]\n",
            " ...\n",
            " [14 11  3 ...  1 13  8]\n",
            " [14 11  3 ...  5 13  8]\n",
            " [14 11  3 ...  7  1  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ...  7  8 10]\n",
            " [14 11  3 ... 13  8 10]\n",
            " [14 11  3 ... 13  8 10]\n",
            " ...\n",
            " [14 11  3 ... 13  8 10]\n",
            " [14 11  3 ... 13  8 10]\n",
            " [14 11  3 ...  1  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_44 (Bidirecti  (None, 128)              40960     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,895\n",
            "Trainable params: 42,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1042/1042 - 17s - loss: 0.7184 - accuracy: 0.7857 - val_loss: 0.4659 - val_accuracy: 0.8065 - lr: 0.0050 - 17s/epoch - 17ms/step\n",
            "Epoch 2/600\n",
            "1042/1042 - 13s - loss: 0.4801 - accuracy: 0.8071 - val_loss: 0.4454 - val_accuracy: 0.8066 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 3/600\n",
            "1042/1042 - 13s - loss: 0.4662 - accuracy: 0.8065 - val_loss: 0.4385 - val_accuracy: 0.8054 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 4/600\n",
            "1042/1042 - 13s - loss: 0.4549 - accuracy: 0.8067 - val_loss: 0.4354 - val_accuracy: 0.8078 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 5/600\n",
            "1042/1042 - 13s - loss: 0.4489 - accuracy: 0.8063 - val_loss: 0.4327 - val_accuracy: 0.8044 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 6/600\n",
            "1042/1042 - 13s - loss: 0.4483 - accuracy: 0.8043 - val_loss: 0.4375 - val_accuracy: 0.8060 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 7/600\n",
            "1042/1042 - 13s - loss: 0.4772 - accuracy: 0.8047 - val_loss: 0.4296 - val_accuracy: 0.8055 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 8/600\n",
            "1042/1042 - 13s - loss: 0.4397 - accuracy: 0.8061 - val_loss: 0.4243 - val_accuracy: 0.8056 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 9/600\n",
            "1042/1042 - 13s - loss: 0.4393 - accuracy: 0.8064 - val_loss: 0.4353 - val_accuracy: 0.8053 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 10/600\n",
            "1042/1042 - 13s - loss: 0.4515 - accuracy: 0.8049 - val_loss: 0.5859 - val_accuracy: 0.8053 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 11/600\n",
            "1042/1042 - 13s - loss: 0.4524 - accuracy: 0.8062 - val_loss: 0.4342 - val_accuracy: 0.8062 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 12/600\n",
            "1042/1042 - 13s - loss: 0.4111 - accuracy: 0.8071 - val_loss: 0.3989 - val_accuracy: 0.8055 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 13/600\n",
            "1042/1042 - 13s - loss: 0.4113 - accuracy: 0.8067 - val_loss: 0.3935 - val_accuracy: 0.8052 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 14/600\n",
            "1042/1042 - 13s - loss: 0.4096 - accuracy: 0.8054 - val_loss: 0.3998 - val_accuracy: 0.8048 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 15/600\n",
            "1042/1042 - 13s - loss: 0.4094 - accuracy: 0.8059 - val_loss: 0.3986 - val_accuracy: 0.8078 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 16/600\n",
            "1042/1042 - 13s - loss: 0.4083 - accuracy: 0.8060 - val_loss: 0.4007 - val_accuracy: 0.8043 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 17/600\n",
            "1042/1042 - 13s - loss: 0.3936 - accuracy: 0.8057 - val_loss: 0.3824 - val_accuracy: 0.8060 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 18/600\n",
            "1042/1042 - 13s - loss: 0.3921 - accuracy: 0.8061 - val_loss: 0.3859 - val_accuracy: 0.8054 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 19/600\n",
            "1042/1042 - 13s - loss: 0.3919 - accuracy: 0.8054 - val_loss: 0.3787 - val_accuracy: 0.8077 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 20/600\n",
            "1042/1042 - 13s - loss: 0.3911 - accuracy: 0.8063 - val_loss: 0.3790 - val_accuracy: 0.8045 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 21/600\n",
            "1042/1042 - 13s - loss: 0.3901 - accuracy: 0.8055 - val_loss: 0.3772 - val_accuracy: 0.8049 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 22/600\n",
            "1042/1042 - 13s - loss: 0.3891 - accuracy: 0.8070 - val_loss: 0.3788 - val_accuracy: 0.8061 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 23/600\n",
            "1042/1042 - 13s - loss: 0.3893 - accuracy: 0.8068 - val_loss: 0.3806 - val_accuracy: 0.8063 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 24/600\n",
            "1042/1042 - 13s - loss: 0.3892 - accuracy: 0.8058 - val_loss: 0.3780 - val_accuracy: 0.8077 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 25/600\n",
            "1042/1042 - 13s - loss: 0.3803 - accuracy: 0.8052 - val_loss: 0.3723 - val_accuracy: 0.8049 - lr: 6.2500e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 26/600\n",
            "1042/1042 - 13s - loss: 0.3796 - accuracy: 0.8054 - val_loss: 0.3690 - val_accuracy: 0.8069 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 27/600\n",
            "1042/1042 - 13s - loss: 0.3792 - accuracy: 0.8064 - val_loss: 0.3733 - val_accuracy: 0.8070 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 28/600\n",
            "1042/1042 - 13s - loss: 0.3789 - accuracy: 0.8064 - val_loss: 0.3717 - val_accuracy: 0.8058 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 29/600\n",
            "1042/1042 - 13s - loss: 0.3789 - accuracy: 0.8065 - val_loss: 0.3701 - val_accuracy: 0.8063 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 30/600\n",
            "1042/1042 - 13s - loss: 0.3735 - accuracy: 0.8060 - val_loss: 0.3653 - val_accuracy: 0.8093 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 31/600\n",
            "1042/1042 - 13s - loss: 0.3729 - accuracy: 0.8072 - val_loss: 0.3658 - val_accuracy: 0.8052 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 32/600\n",
            "1042/1042 - 13s - loss: 0.3730 - accuracy: 0.8049 - val_loss: 0.3661 - val_accuracy: 0.8036 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 33/600\n",
            "1042/1042 - 13s - loss: 0.3721 - accuracy: 0.8072 - val_loss: 0.3659 - val_accuracy: 0.8061 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 34/600\n",
            "1042/1042 - 13s - loss: 0.3699 - accuracy: 0.8065 - val_loss: 0.3628 - val_accuracy: 0.8051 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 35/600\n",
            "1042/1042 - 13s - loss: 0.3694 - accuracy: 0.8074 - val_loss: 0.3632 - val_accuracy: 0.8068 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 36/600\n",
            "1042/1042 - 13s - loss: 0.3690 - accuracy: 0.8065 - val_loss: 0.3629 - val_accuracy: 0.8073 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 37/600\n",
            "1042/1042 - 13s - loss: 0.3689 - accuracy: 0.8068 - val_loss: 0.3619 - val_accuracy: 0.8093 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 38/600\n",
            "1042/1042 - 13s - loss: 0.3686 - accuracy: 0.8072 - val_loss: 0.3622 - val_accuracy: 0.8085 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 39/600\n",
            "1042/1042 - 13s - loss: 0.3688 - accuracy: 0.8061 - val_loss: 0.3623 - val_accuracy: 0.8066 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 40/600\n",
            "1042/1042 - 13s - loss: 0.3686 - accuracy: 0.8069 - val_loss: 0.3618 - val_accuracy: 0.8070 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 41/600\n",
            "1042/1042 - 13s - loss: 0.3683 - accuracy: 0.8073 - val_loss: 0.3623 - val_accuracy: 0.8052 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 42/600\n",
            "1042/1042 - 13s - loss: 0.3681 - accuracy: 0.8071 - val_loss: 0.3632 - val_accuracy: 0.8078 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 43/600\n",
            "1042/1042 - 13s - loss: 0.3682 - accuracy: 0.8059 - val_loss: 0.3620 - val_accuracy: 0.8040 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 44/600\n",
            "1042/1042 - 13s - loss: 0.3666 - accuracy: 0.8069 - val_loss: 0.3613 - val_accuracy: 0.8064 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 45/600\n",
            "1042/1042 - 13s - loss: 0.3665 - accuracy: 0.8062 - val_loss: 0.3614 - val_accuracy: 0.8058 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 46/600\n",
            "1042/1042 - 13s - loss: 0.3662 - accuracy: 0.8075 - val_loss: 0.3607 - val_accuracy: 0.8065 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 47/600\n",
            "1042/1042 - 13s - loss: 0.3660 - accuracy: 0.8075 - val_loss: 0.3605 - val_accuracy: 0.8084 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 48/600\n",
            "1042/1042 - 13s - loss: 0.3665 - accuracy: 0.8052 - val_loss: 0.3602 - val_accuracy: 0.8054 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 49/600\n",
            "1042/1042 - 13s - loss: 0.3663 - accuracy: 0.8063 - val_loss: 0.3600 - val_accuracy: 0.8053 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 50/600\n",
            "1042/1042 - 13s - loss: 0.3660 - accuracy: 0.8073 - val_loss: 0.3601 - val_accuracy: 0.8074 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 51/600\n",
            "1042/1042 - 13s - loss: 0.3658 - accuracy: 0.8060 - val_loss: 0.3601 - val_accuracy: 0.8059 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 52/600\n",
            "1042/1042 - 13s - loss: 0.3659 - accuracy: 0.8071 - val_loss: 0.3598 - val_accuracy: 0.8075 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 53/600\n",
            "1042/1042 - 13s - loss: 0.3655 - accuracy: 0.8073 - val_loss: 0.3597 - val_accuracy: 0.8068 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 54/600\n",
            "1042/1042 - 13s - loss: 0.3658 - accuracy: 0.8062 - val_loss: 0.3601 - val_accuracy: 0.8054 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 55/600\n",
            "1042/1042 - 13s - loss: 0.3655 - accuracy: 0.8062 - val_loss: 0.3605 - val_accuracy: 0.8037 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 56/600\n",
            "1042/1042 - 13s - loss: 0.3648 - accuracy: 0.8070 - val_loss: 0.3596 - val_accuracy: 0.8062 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 57/600\n",
            "1042/1042 - 13s - loss: 0.3649 - accuracy: 0.8063 - val_loss: 0.3594 - val_accuracy: 0.8048 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 58/600\n",
            "1042/1042 - 13s - loss: 0.3647 - accuracy: 0.8073 - val_loss: 0.3594 - val_accuracy: 0.8076 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 59/600\n",
            "1042/1042 - 13s - loss: 0.3645 - accuracy: 0.8071 - val_loss: 0.3592 - val_accuracy: 0.8049 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 60/600\n",
            "1042/1042 - 13s - loss: 0.3648 - accuracy: 0.8054 - val_loss: 0.3592 - val_accuracy: 0.8052 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 61/600\n",
            "1042/1042 - 13s - loss: 0.3644 - accuracy: 0.8075 - val_loss: 0.3596 - val_accuracy: 0.8052 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 62/600\n",
            "1042/1042 - 13s - loss: 0.3647 - accuracy: 0.8058 - val_loss: 0.3591 - val_accuracy: 0.8074 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 63/600\n",
            "1042/1042 - 13s - loss: 0.3645 - accuracy: 0.8068 - val_loss: 0.3592 - val_accuracy: 0.8056 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 64/600\n",
            "1042/1042 - 13s - loss: 0.3644 - accuracy: 0.8072 - val_loss: 0.3591 - val_accuracy: 0.8046 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 65/600\n",
            "1042/1042 - 13s - loss: 0.3644 - accuracy: 0.8067 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 66/600\n",
            "1042/1042 - 13s - loss: 0.3643 - accuracy: 0.8068 - val_loss: 0.3591 - val_accuracy: 0.8074 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 67/600\n",
            "1042/1042 - 13s - loss: 0.3646 - accuracy: 0.8068 - val_loss: 0.3589 - val_accuracy: 0.8085 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 68/600\n",
            "1042/1042 - 13s - loss: 0.3642 - accuracy: 0.8076 - val_loss: 0.3593 - val_accuracy: 0.8040 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 69/600\n",
            "1042/1042 - 13s - loss: 0.3639 - accuracy: 0.8069 - val_loss: 0.3589 - val_accuracy: 0.8072 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 70/600\n",
            "1042/1042 - 13s - loss: 0.3638 - accuracy: 0.8084 - val_loss: 0.3589 - val_accuracy: 0.8065 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 71/600\n",
            "1042/1042 - 14s - loss: 0.3638 - accuracy: 0.8081 - val_loss: 0.3588 - val_accuracy: 0.8067 - lr: 1.9531e-05 - 14s/epoch - 13ms/step\n",
            "Epoch 72/600\n",
            "1042/1042 - 14s - loss: 0.3637 - accuracy: 0.8079 - val_loss: 0.3586 - val_accuracy: 0.8079 - lr: 1.9531e-05 - 14s/epoch - 14ms/step\n",
            "Epoch 73/600\n",
            "1042/1042 - 14s - loss: 0.3640 - accuracy: 0.8074 - val_loss: 0.3586 - val_accuracy: 0.8062 - lr: 1.9531e-05 - 14s/epoch - 13ms/step\n",
            "Epoch 74/600\n",
            "1042/1042 - 14s - loss: 0.3639 - accuracy: 0.8068 - val_loss: 0.3586 - val_accuracy: 0.8069 - lr: 1.9531e-05 - 14s/epoch - 13ms/step\n",
            "Epoch 75/600\n",
            "1042/1042 - 14s - loss: 0.3638 - accuracy: 0.8072 - val_loss: 0.3586 - val_accuracy: 0.8064 - lr: 1.9531e-05 - 14s/epoch - 13ms/step\n",
            "Epoch 76/600\n",
            "1042/1042 - 14s - loss: 0.3636 - accuracy: 0.8071 - val_loss: 0.3584 - val_accuracy: 0.8059 - lr: 9.7656e-06 - 14s/epoch - 13ms/step\n",
            "Epoch 77/600\n",
            "1042/1042 - 14s - loss: 0.3636 - accuracy: 0.8075 - val_loss: 0.3585 - val_accuracy: 0.8053 - lr: 9.7656e-06 - 14s/epoch - 13ms/step\n",
            "Epoch 78/600\n",
            "1042/1042 - 14s - loss: 0.3635 - accuracy: 0.8075 - val_loss: 0.3585 - val_accuracy: 0.8038 - lr: 9.7656e-06 - 14s/epoch - 13ms/step\n",
            "Epoch 79/600\n",
            "1042/1042 - 14s - loss: 0.3633 - accuracy: 0.8088 - val_loss: 0.3584 - val_accuracy: 0.8067 - lr: 9.7656e-06 - 14s/epoch - 13ms/step\n",
            "Epoch 80/600\n",
            "1042/1042 - 14s - loss: 0.3633 - accuracy: 0.8079 - val_loss: 0.3583 - val_accuracy: 0.8065 - lr: 4.8828e-06 - 14s/epoch - 13ms/step\n",
            "Epoch 81/600\n",
            "1042/1042 - 14s - loss: 0.3634 - accuracy: 0.8073 - val_loss: 0.3583 - val_accuracy: 0.8052 - lr: 4.8828e-06 - 14s/epoch - 13ms/step\n",
            "Epoch 82/600\n",
            "1042/1042 - 13s - loss: 0.3635 - accuracy: 0.8082 - val_loss: 0.3583 - val_accuracy: 0.8059 - lr: 4.8828e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 83/600\n",
            "1042/1042 - 13s - loss: 0.3634 - accuracy: 0.8077 - val_loss: 0.3583 - val_accuracy: 0.8057 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 84/600\n",
            "1042/1042 - 13s - loss: 0.3634 - accuracy: 0.8076 - val_loss: 0.3583 - val_accuracy: 0.8056 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 85/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8083 - val_loss: 0.3583 - val_accuracy: 0.8059 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 86/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8084 - val_loss: 0.3583 - val_accuracy: 0.8056 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 87/600\n",
            "1042/1042 - 13s - loss: 0.3634 - accuracy: 0.8080 - val_loss: 0.3583 - val_accuracy: 0.8055 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 88/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8081 - val_loss: 0.3583 - val_accuracy: 0.8057 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 89/600\n",
            "1042/1042 - 13s - loss: 0.3634 - accuracy: 0.8075 - val_loss: 0.3582 - val_accuracy: 0.8059 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 90/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8080 - val_loss: 0.3582 - val_accuracy: 0.8059 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 91/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8087 - val_loss: 0.3582 - val_accuracy: 0.8057 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 92/600\n",
            "1042/1042 - 13s - loss: 0.3634 - accuracy: 0.8077 - val_loss: 0.3582 - val_accuracy: 0.8057 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 93/600\n",
            "1042/1042 - 13s - loss: 0.3634 - accuracy: 0.8075 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 94/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8087 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 95/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8081 - val_loss: 0.3582 - val_accuracy: 0.8057 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 96/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8083 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 97/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8080 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 98/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8082 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 99/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8081 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 100/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8077 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 101/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8077 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 102/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8083 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 7.6294e-08 - 13s/epoch - 13ms/step\n",
            "Epoch 103/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8081 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 104/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8082 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 105/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8075 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 106/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8093 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 1.9073e-08 - 13s/epoch - 13ms/step\n",
            "Epoch 107/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8084 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 108/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8074 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 1.9073e-08 - 13s/epoch - 13ms/step\n",
            "Epoch 109/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8084 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 9.5367e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 110/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8093 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 9.5367e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 111/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8081 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 9.5367e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 112/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8080 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 4.7684e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 113/600\n",
            "1042/1042 - 13s - loss: 0.3634 - accuracy: 0.8076 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 4.7684e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 114/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8077 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 4.7684e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 115/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8077 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 2.3842e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 116/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8076 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 2.3842e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 117/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8086 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 2.3842e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 118/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8084 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 1.1921e-09 - 13s/epoch - 13ms/step\n",
            "Epoch 119/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8083 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 1.1921e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 120/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8084 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 1.1921e-09 - 13s/epoch - 13ms/step\n",
            "Epoch 121/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8093 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 5.9605e-10 - 13s/epoch - 12ms/step\n",
            "Epoch 122/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8090 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 5.9605e-10 - 13s/epoch - 12ms/step\n",
            "Epoch 123/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8087 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 5.9605e-10 - 13s/epoch - 13ms/step\n",
            "Epoch 124/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8081 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 2.9802e-10 - 13s/epoch - 12ms/step\n",
            "Epoch 125/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8089 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 2.9802e-10 - 13s/epoch - 12ms/step\n",
            "Epoch 126/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8079 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 2.9802e-10 - 13s/epoch - 12ms/step\n",
            "Epoch 127/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8080 - val_loss: 0.3582 - val_accuracy: 0.8056 - lr: 1.4901e-10 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12  5]\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12 13]\n",
            " ...\n",
            " [14 11  3  2 12  7]\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12  7]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12  5  7]\n",
            " [14 11  3 ... 12 13  5]\n",
            " [14 11  3 ... 12 13  1]\n",
            " ...\n",
            " [14 11  3 ... 12  7  1]\n",
            " [14 11  3 ... 12 13  5]\n",
            " [14 11  3 ... 12  7  5]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ...  5  7 13]\n",
            " [14 11  3 ... 13  5  9]\n",
            " [14 11  3 ... 13  1  7]\n",
            " ...\n",
            " [14 11  3 ...  7  1  5]\n",
            " [14 11  3 ... 13  5  9]\n",
            " [14 11  3 ...  7  5  1]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ...  7 13  9]\n",
            " [14 11  3 ...  5  9  1]\n",
            " [14 11  3 ...  1  7  5]\n",
            " ...\n",
            " [14 11  3 ...  1  5 13]\n",
            " [14 11  3 ...  5  9  7]\n",
            " [14 11  3 ...  5  1 13]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ... 13  9  1]\n",
            " [14 11  3 ...  9  1  7]\n",
            " [14 11  3 ...  7  5  9]\n",
            " ...\n",
            " [14 11  3 ...  5 13  9]\n",
            " [14 11  3 ...  9  7  1]\n",
            " [14 11  3 ...  1 13  9]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ...  9  1  8]\n",
            " [14 11  3 ...  1  7  8]\n",
            " [14 11  3 ...  5  9  8]\n",
            " ...\n",
            " [14 11  3 ... 13  9  8]\n",
            " [14 11  3 ...  7  1  8]\n",
            " [14 11  3 ... 13  9  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ...  1  8 10]\n",
            " [14 11  3 ...  7  8 10]\n",
            " [14 11  3 ...  9  8 10]\n",
            " ...\n",
            " [14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  1  8 10]\n",
            " [14 11  3 ...  9  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_45 (Bidirecti  (None, 128)              40960     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_45 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,895\n",
            "Trainable params: 42,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1040/1040 - 18s - loss: 0.7194 - accuracy: 0.7839 - val_loss: 0.4770 - val_accuracy: 0.8083 - lr: 0.0050 - 18s/epoch - 17ms/step\n",
            "Epoch 2/600\n",
            "1040/1040 - 13s - loss: 0.4801 - accuracy: 0.8075 - val_loss: 0.4726 - val_accuracy: 0.8060 - lr: 0.0050 - 13s/epoch - 13ms/step\n",
            "Epoch 3/600\n",
            "1040/1040 - 13s - loss: 0.4657 - accuracy: 0.8057 - val_loss: 0.4399 - val_accuracy: 0.8055 - lr: 0.0050 - 13s/epoch - 13ms/step\n",
            "Epoch 4/600\n",
            "1040/1040 - 13s - loss: 0.4585 - accuracy: 0.8062 - val_loss: 0.4390 - val_accuracy: 0.8065 - lr: 0.0050 - 13s/epoch - 13ms/step\n",
            "Epoch 5/600\n",
            "1040/1040 - 13s - loss: 0.4517 - accuracy: 0.8062 - val_loss: 0.4282 - val_accuracy: 0.8065 - lr: 0.0050 - 13s/epoch - 13ms/step\n",
            "Epoch 6/600\n",
            "1040/1040 - 13s - loss: 0.4487 - accuracy: 0.8057 - val_loss: 0.4241 - val_accuracy: 0.8038 - lr: 0.0050 - 13s/epoch - 13ms/step\n",
            "Epoch 7/600\n",
            "1040/1040 - 13s - loss: 0.4508 - accuracy: 0.8067 - val_loss: 0.4766 - val_accuracy: 0.8064 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 8/600\n",
            "1040/1040 - 13s - loss: 0.4457 - accuracy: 0.8064 - val_loss: 0.4265 - val_accuracy: 0.8063 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 9/600\n",
            "1040/1040 - 13s - loss: 0.4521 - accuracy: 0.8059 - val_loss: 0.4424 - val_accuracy: 0.8038 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 10/600\n",
            "1040/1040 - 13s - loss: 0.4152 - accuracy: 0.8059 - val_loss: 0.4081 - val_accuracy: 0.8057 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 11/600\n",
            "1040/1040 - 13s - loss: 0.4144 - accuracy: 0.8079 - val_loss: 0.4027 - val_accuracy: 0.8058 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 12/600\n",
            "1040/1040 - 13s - loss: 0.4126 - accuracy: 0.8063 - val_loss: 0.4132 - val_accuracy: 0.8079 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 13/600\n",
            "1040/1040 - 13s - loss: 0.4132 - accuracy: 0.8055 - val_loss: 0.4032 - val_accuracy: 0.8057 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 14/600\n",
            "1040/1040 - 13s - loss: 0.4131 - accuracy: 0.8064 - val_loss: 0.4005 - val_accuracy: 0.8072 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 15/600\n",
            "1040/1040 - 13s - loss: 0.4105 - accuracy: 0.8063 - val_loss: 0.3967 - val_accuracy: 0.8051 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 16/600\n",
            "1040/1040 - 13s - loss: 0.4102 - accuracy: 0.8061 - val_loss: 0.4126 - val_accuracy: 0.8070 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 17/600\n",
            "1040/1040 - 13s - loss: 0.4099 - accuracy: 0.8067 - val_loss: 0.4000 - val_accuracy: 0.8070 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 18/600\n",
            "1040/1040 - 13s - loss: 0.4092 - accuracy: 0.8057 - val_loss: 0.4015 - val_accuracy: 0.8074 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 19/600\n",
            "1040/1040 - 13s - loss: 0.3931 - accuracy: 0.8062 - val_loss: 0.3808 - val_accuracy: 0.8083 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 20/600\n",
            "1040/1040 - 13s - loss: 0.3917 - accuracy: 0.8068 - val_loss: 0.3807 - val_accuracy: 0.8073 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 21/600\n",
            "1040/1040 - 13s - loss: 0.3918 - accuracy: 0.8058 - val_loss: 0.3801 - val_accuracy: 0.8062 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 22/600\n",
            "1040/1040 - 13s - loss: 0.3913 - accuracy: 0.8066 - val_loss: 0.3841 - val_accuracy: 0.8062 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 23/600\n",
            "1040/1040 - 13s - loss: 0.3905 - accuracy: 0.8059 - val_loss: 0.3804 - val_accuracy: 0.8054 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 24/600\n",
            "1040/1040 - 13s - loss: 0.3900 - accuracy: 0.8058 - val_loss: 0.3794 - val_accuracy: 0.8054 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 25/600\n",
            "1040/1040 - 13s - loss: 0.3896 - accuracy: 0.8067 - val_loss: 0.3820 - val_accuracy: 0.8057 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 26/600\n",
            "1040/1040 - 13s - loss: 0.3897 - accuracy: 0.8070 - val_loss: 0.3796 - val_accuracy: 0.8058 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 27/600\n",
            "1040/1040 - 13s - loss: 0.3901 - accuracy: 0.8056 - val_loss: 0.3812 - val_accuracy: 0.8053 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 28/600\n",
            "1040/1040 - 13s - loss: 0.3793 - accuracy: 0.8064 - val_loss: 0.3739 - val_accuracy: 0.8053 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 29/600\n",
            "1040/1040 - 13s - loss: 0.3797 - accuracy: 0.8060 - val_loss: 0.3736 - val_accuracy: 0.8077 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 30/600\n",
            "1040/1040 - 13s - loss: 0.3789 - accuracy: 0.8051 - val_loss: 0.3733 - val_accuracy: 0.8052 - lr: 6.2500e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 31/600\n",
            "1040/1040 - 13s - loss: 0.3785 - accuracy: 0.8070 - val_loss: 0.3706 - val_accuracy: 0.8068 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 32/600\n",
            "1040/1040 - 13s - loss: 0.3784 - accuracy: 0.8064 - val_loss: 0.3772 - val_accuracy: 0.8060 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 33/600\n",
            "1040/1040 - 13s - loss: 0.3784 - accuracy: 0.8066 - val_loss: 0.3702 - val_accuracy: 0.8073 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 34/600\n",
            "1040/1040 - 13s - loss: 0.3780 - accuracy: 0.8070 - val_loss: 0.3696 - val_accuracy: 0.8072 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 35/600\n",
            "1040/1040 - 13s - loss: 0.3772 - accuracy: 0.8078 - val_loss: 0.3763 - val_accuracy: 0.8063 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 36/600\n",
            "1040/1040 - 13s - loss: 0.3781 - accuracy: 0.8054 - val_loss: 0.3702 - val_accuracy: 0.8045 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 37/600\n",
            "1040/1040 - 13s - loss: 0.3776 - accuracy: 0.8070 - val_loss: 0.3700 - val_accuracy: 0.8070 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 38/600\n",
            "1040/1040 - 13s - loss: 0.3720 - accuracy: 0.8078 - val_loss: 0.3666 - val_accuracy: 0.8055 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 39/600\n",
            "1040/1040 - 13s - loss: 0.3718 - accuracy: 0.8066 - val_loss: 0.3659 - val_accuracy: 0.8063 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 40/600\n",
            "1040/1040 - 13s - loss: 0.3717 - accuracy: 0.8050 - val_loss: 0.3651 - val_accuracy: 0.8067 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 41/600\n",
            "1040/1040 - 13s - loss: 0.3717 - accuracy: 0.8064 - val_loss: 0.3660 - val_accuracy: 0.8057 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 42/600\n",
            "1040/1040 - 13s - loss: 0.3712 - accuracy: 0.8063 - val_loss: 0.3638 - val_accuracy: 0.8070 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 43/600\n",
            "1040/1040 - 13s - loss: 0.3709 - accuracy: 0.8067 - val_loss: 0.3652 - val_accuracy: 0.8072 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 44/600\n",
            "1040/1040 - 13s - loss: 0.3709 - accuracy: 0.8075 - val_loss: 0.3653 - val_accuracy: 0.8060 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 45/600\n",
            "1040/1040 - 13s - loss: 0.3706 - accuracy: 0.8069 - val_loss: 0.3659 - val_accuracy: 0.8058 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 46/600\n",
            "1040/1040 - 13s - loss: 0.3680 - accuracy: 0.8066 - val_loss: 0.3636 - val_accuracy: 0.8049 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 47/600\n",
            "1040/1040 - 13s - loss: 0.3675 - accuracy: 0.8065 - val_loss: 0.3636 - val_accuracy: 0.8066 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 48/600\n",
            "1040/1040 - 13s - loss: 0.3676 - accuracy: 0.8057 - val_loss: 0.3651 - val_accuracy: 0.8059 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 49/600\n",
            "1040/1040 - 13s - loss: 0.3675 - accuracy: 0.8064 - val_loss: 0.3635 - val_accuracy: 0.8059 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 50/600\n",
            "1040/1040 - 13s - loss: 0.3672 - accuracy: 0.8055 - val_loss: 0.3621 - val_accuracy: 0.8037 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 51/600\n",
            "1040/1040 - 13s - loss: 0.3671 - accuracy: 0.8070 - val_loss: 0.3621 - val_accuracy: 0.8050 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 52/600\n",
            "1040/1040 - 13s - loss: 0.3668 - accuracy: 0.8067 - val_loss: 0.3622 - val_accuracy: 0.8055 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 53/600\n",
            "1040/1040 - 13s - loss: 0.3671 - accuracy: 0.8061 - val_loss: 0.3617 - val_accuracy: 0.8070 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 54/600\n",
            "1040/1040 - 13s - loss: 0.3669 - accuracy: 0.8066 - val_loss: 0.3623 - val_accuracy: 0.8061 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 55/600\n",
            "1040/1040 - 13s - loss: 0.3666 - accuracy: 0.8066 - val_loss: 0.3628 - val_accuracy: 0.8062 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 56/600\n",
            "1040/1040 - 13s - loss: 0.3665 - accuracy: 0.8073 - val_loss: 0.3630 - val_accuracy: 0.8061 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 57/600\n",
            "1040/1040 - 13s - loss: 0.3649 - accuracy: 0.8072 - val_loss: 0.3607 - val_accuracy: 0.8080 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 58/600\n",
            "1040/1040 - 13s - loss: 0.3647 - accuracy: 0.8078 - val_loss: 0.3606 - val_accuracy: 0.8062 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 59/600\n",
            "1040/1040 - 13s - loss: 0.3648 - accuracy: 0.8065 - val_loss: 0.3617 - val_accuracy: 0.8066 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 60/600\n",
            "1040/1040 - 13s - loss: 0.3646 - accuracy: 0.8084 - val_loss: 0.3609 - val_accuracy: 0.8057 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 61/600\n",
            "1040/1040 - 13s - loss: 0.3638 - accuracy: 0.8077 - val_loss: 0.3598 - val_accuracy: 0.8067 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 62/600\n",
            "1040/1040 - 13s - loss: 0.3637 - accuracy: 0.8071 - val_loss: 0.3597 - val_accuracy: 0.8061 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 63/600\n",
            "1040/1040 - 13s - loss: 0.3636 - accuracy: 0.8069 - val_loss: 0.3598 - val_accuracy: 0.8065 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 64/600\n",
            "1040/1040 - 13s - loss: 0.3636 - accuracy: 0.8072 - val_loss: 0.3599 - val_accuracy: 0.8074 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 65/600\n",
            "1040/1040 - 13s - loss: 0.3632 - accuracy: 0.8082 - val_loss: 0.3597 - val_accuracy: 0.8061 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 66/600\n",
            "1040/1040 - 13s - loss: 0.3631 - accuracy: 0.8081 - val_loss: 0.3598 - val_accuracy: 0.8064 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 67/600\n",
            "1040/1040 - 13s - loss: 0.3632 - accuracy: 0.8069 - val_loss: 0.3594 - val_accuracy: 0.8065 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 68/600\n",
            "1040/1040 - 13s - loss: 0.3631 - accuracy: 0.8080 - val_loss: 0.3594 - val_accuracy: 0.8070 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 69/600\n",
            "1040/1040 - 13s - loss: 0.3631 - accuracy: 0.8070 - val_loss: 0.3594 - val_accuracy: 0.8062 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 70/600\n",
            "1040/1040 - 13s - loss: 0.3631 - accuracy: 0.8074 - val_loss: 0.3595 - val_accuracy: 0.8063 - lr: 1.9531e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 71/600\n",
            "1040/1040 - 13s - loss: 0.3629 - accuracy: 0.8080 - val_loss: 0.3594 - val_accuracy: 0.8052 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 72/600\n",
            "1040/1040 - 13s - loss: 0.3628 - accuracy: 0.8082 - val_loss: 0.3594 - val_accuracy: 0.8040 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 73/600\n",
            "1040/1040 - 13s - loss: 0.3628 - accuracy: 0.8075 - val_loss: 0.3593 - val_accuracy: 0.8072 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 74/600\n",
            "1040/1040 - 13s - loss: 0.3628 - accuracy: 0.8077 - val_loss: 0.3592 - val_accuracy: 0.8073 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 75/600\n",
            "1040/1040 - 13s - loss: 0.3627 - accuracy: 0.8079 - val_loss: 0.3592 - val_accuracy: 0.8061 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 76/600\n",
            "1040/1040 - 13s - loss: 0.3626 - accuracy: 0.8080 - val_loss: 0.3593 - val_accuracy: 0.8054 - lr: 9.7656e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 77/600\n",
            "1040/1040 - 13s - loss: 0.3627 - accuracy: 0.8086 - val_loss: 0.3592 - val_accuracy: 0.8064 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 78/600\n",
            "1040/1040 - 13s - loss: 0.3626 - accuracy: 0.8070 - val_loss: 0.3591 - val_accuracy: 0.8065 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 79/600\n",
            "1040/1040 - 13s - loss: 0.3626 - accuracy: 0.8072 - val_loss: 0.3591 - val_accuracy: 0.8053 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 80/600\n",
            "1040/1040 - 13s - loss: 0.3627 - accuracy: 0.8074 - val_loss: 0.3591 - val_accuracy: 0.8069 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 81/600\n",
            "1040/1040 - 13s - loss: 0.3625 - accuracy: 0.8079 - val_loss: 0.3591 - val_accuracy: 0.8067 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 82/600\n",
            "1040/1040 - 13s - loss: 0.3625 - accuracy: 0.8075 - val_loss: 0.3591 - val_accuracy: 0.8061 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 83/600\n",
            "1040/1040 - 13s - loss: 0.3625 - accuracy: 0.8080 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 84/600\n",
            "1040/1040 - 13s - loss: 0.3625 - accuracy: 0.8075 - val_loss: 0.3590 - val_accuracy: 0.8061 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 85/600\n",
            "1040/1040 - 13s - loss: 0.3624 - accuracy: 0.8085 - val_loss: 0.3590 - val_accuracy: 0.8067 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 86/600\n",
            "1040/1040 - 13s - loss: 0.3623 - accuracy: 0.8086 - val_loss: 0.3590 - val_accuracy: 0.8061 - lr: 1.2207e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 87/600\n",
            "1040/1040 - 13s - loss: 0.3626 - accuracy: 0.8080 - val_loss: 0.3590 - val_accuracy: 0.8065 - lr: 1.2207e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 88/600\n",
            "1040/1040 - 13s - loss: 0.3624 - accuracy: 0.8074 - val_loss: 0.3590 - val_accuracy: 0.8066 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 89/600\n",
            "1040/1040 - 13s - loss: 0.3624 - accuracy: 0.8076 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 90/600\n",
            "1040/1040 - 14s - loss: 0.3625 - accuracy: 0.8075 - val_loss: 0.3590 - val_accuracy: 0.8066 - lr: 6.1035e-07 - 14s/epoch - 13ms/step\n",
            "Epoch 91/600\n",
            "1040/1040 - 15s - loss: 0.3624 - accuracy: 0.8085 - val_loss: 0.3590 - val_accuracy: 0.8066 - lr: 3.0518e-07 - 15s/epoch - 14ms/step\n",
            "Epoch 92/600\n",
            "1040/1040 - 13s - loss: 0.3624 - accuracy: 0.8069 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 93/600\n",
            "1040/1040 - 13s - loss: 0.3624 - accuracy: 0.8082 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 94/600\n",
            "1040/1040 - 13s - loss: 0.3624 - accuracy: 0.8089 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 95/600\n",
            "1040/1040 - 13s - loss: 0.3623 - accuracy: 0.8085 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 96/600\n",
            "1040/1040 - 13s - loss: 0.3624 - accuracy: 0.8081 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 97/600\n",
            "1040/1040 - 13s - loss: 0.3624 - accuracy: 0.8080 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 98/600\n",
            "1040/1040 - 13s - loss: 0.3623 - accuracy: 0.8080 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 99/600\n",
            "1040/1040 - 13s - loss: 0.3625 - accuracy: 0.8074 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 100/600\n",
            "1040/1040 - 13s - loss: 0.3625 - accuracy: 0.8077 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 101/600\n",
            "1040/1040 - 13s - loss: 0.3626 - accuracy: 0.8071 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 102/600\n",
            "1040/1040 - 13s - loss: 0.3623 - accuracy: 0.8083 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 103/600\n",
            "1040/1040 - 13s - loss: 0.3624 - accuracy: 0.8082 - val_loss: 0.3590 - val_accuracy: 0.8064 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12  9]\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12 13]\n",
            " ...\n",
            " [14 11  3  2 12  9]\n",
            " [14 11  3  2 12  9]\n",
            " [14 11  3  2 12  5]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12  9  1]\n",
            " [14 11  3 ... 12 13  5]\n",
            " [14 11  3 ... 12 13  9]\n",
            " ...\n",
            " [14 11  3 ... 12  9  7]\n",
            " [14 11  3 ... 12  9 13]\n",
            " [14 11  3 ... 12  5  7]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ...  9  1  7]\n",
            " [14 11  3 ... 13  5  7]\n",
            " [14 11  3 ... 13  9  1]\n",
            " ...\n",
            " [14 11  3 ...  9  7  5]\n",
            " [14 11  3 ...  9 13  7]\n",
            " [14 11  3 ...  5  7  1]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ...  1  7  5]\n",
            " [14 11  3 ...  5  7  9]\n",
            " [14 11  3 ...  9  1  5]\n",
            " ...\n",
            " [14 11  3 ...  7  5 13]\n",
            " [14 11  3 ... 13  7  1]\n",
            " [14 11  3 ...  7  1  9]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ...  7  5 13]\n",
            " [14 11  3 ...  7  9  1]\n",
            " [14 11  3 ...  1  5  7]\n",
            " ...\n",
            " [14 11  3 ...  5 13  1]\n",
            " [14 11  3 ...  7  1  5]\n",
            " [14 11  3 ...  1  9 13]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ...  5 13  8]\n",
            " [14 11  3 ...  9  1  8]\n",
            " [14 11  3 ...  5  7  8]\n",
            " ...\n",
            " [14 11  3 ... 13  1  8]\n",
            " [14 11  3 ...  1  5  8]\n",
            " [14 11  3 ...  9 13  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ... 13  8 10]\n",
            " [14 11  3 ...  1  8 10]\n",
            " [14 11  3 ...  7  8 10]\n",
            " ...\n",
            " [14 11  3 ...  1  8 10]\n",
            " [14 11  3 ...  5  8 10]\n",
            " [14 11  3 ... 13  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_46 (Bidirecti  (None, 128)              40960     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_46 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,895\n",
            "Trainable params: 42,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1041/1041 - 17s - loss: 0.7154 - accuracy: 0.7873 - val_loss: 0.4793 - val_accuracy: 0.8062 - lr: 0.0050 - 17s/epoch - 17ms/step\n",
            "Epoch 2/600\n",
            "1041/1041 - 13s - loss: 0.4822 - accuracy: 0.8071 - val_loss: 0.4569 - val_accuracy: 0.8062 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 3/600\n",
            "1041/1041 - 13s - loss: 0.4662 - accuracy: 0.8053 - val_loss: 0.4493 - val_accuracy: 0.8071 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 4/600\n",
            "1041/1041 - 13s - loss: 0.4557 - accuracy: 0.8068 - val_loss: 0.4327 - val_accuracy: 0.8070 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 5/600\n",
            "1041/1041 - 13s - loss: 0.4516 - accuracy: 0.8052 - val_loss: 0.4376 - val_accuracy: 0.8085 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 6/600\n",
            "1041/1041 - 13s - loss: 0.4534 - accuracy: 0.8051 - val_loss: 0.4191 - val_accuracy: 0.8048 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 7/600\n",
            "1041/1041 - 13s - loss: 0.4472 - accuracy: 0.8063 - val_loss: 0.4241 - val_accuracy: 0.8048 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 8/600\n",
            "1041/1041 - 13s - loss: 0.4757 - accuracy: 0.8058 - val_loss: 0.4395 - val_accuracy: 0.8063 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 9/600\n",
            "1041/1041 - 13s - loss: 0.4417 - accuracy: 0.8068 - val_loss: 0.4290 - val_accuracy: 0.8051 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 10/600\n",
            "1041/1041 - 13s - loss: 0.4136 - accuracy: 0.8057 - val_loss: 0.3986 - val_accuracy: 0.8076 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 11/600\n",
            "1041/1041 - 13s - loss: 0.4116 - accuracy: 0.8057 - val_loss: 0.3987 - val_accuracy: 0.8058 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 12/600\n",
            "1041/1041 - 13s - loss: 0.4108 - accuracy: 0.8084 - val_loss: 0.4040 - val_accuracy: 0.8070 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 13/600\n",
            "1041/1041 - 13s - loss: 0.4114 - accuracy: 0.8057 - val_loss: 0.3983 - val_accuracy: 0.8056 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 14/600\n",
            "1041/1041 - 13s - loss: 0.4108 - accuracy: 0.8054 - val_loss: 0.3929 - val_accuracy: 0.8070 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 15/600\n",
            "1041/1041 - 13s - loss: 0.4093 - accuracy: 0.8056 - val_loss: 0.3962 - val_accuracy: 0.8052 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 16/600\n",
            "1041/1041 - 13s - loss: 0.4110 - accuracy: 0.8055 - val_loss: 0.3934 - val_accuracy: 0.8058 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 17/600\n",
            "1041/1041 - 13s - loss: 0.4087 - accuracy: 0.8060 - val_loss: 0.3902 - val_accuracy: 0.8061 - lr: 0.0025 - 13s/epoch - 13ms/step\n",
            "Epoch 18/600\n",
            "1041/1041 - 13s - loss: 0.4081 - accuracy: 0.8051 - val_loss: 0.3994 - val_accuracy: 0.8069 - lr: 0.0025 - 13s/epoch - 13ms/step\n",
            "Epoch 19/600\n",
            "1041/1041 - 13s - loss: 0.4133 - accuracy: 0.8062 - val_loss: 0.3928 - val_accuracy: 0.8058 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 20/600\n",
            "1041/1041 - 13s - loss: 0.4076 - accuracy: 0.8058 - val_loss: 0.4041 - val_accuracy: 0.8074 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 21/600\n",
            "1041/1041 - 13s - loss: 0.3914 - accuracy: 0.8065 - val_loss: 0.3838 - val_accuracy: 0.8073 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 22/600\n",
            "1041/1041 - 13s - loss: 0.3915 - accuracy: 0.8055 - val_loss: 0.3796 - val_accuracy: 0.8084 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 23/600\n",
            "1041/1041 - 13s - loss: 0.3907 - accuracy: 0.8051 - val_loss: 0.3776 - val_accuracy: 0.8085 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 24/600\n",
            "1041/1041 - 13s - loss: 0.3905 - accuracy: 0.8057 - val_loss: 0.3777 - val_accuracy: 0.8046 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 25/600\n",
            "1041/1041 - 13s - loss: 0.3899 - accuracy: 0.8062 - val_loss: 0.3897 - val_accuracy: 0.8055 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 26/600\n",
            "1041/1041 - 13s - loss: 0.3890 - accuracy: 0.8063 - val_loss: 0.3768 - val_accuracy: 0.8066 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 27/600\n",
            "1041/1041 - 13s - loss: 0.3901 - accuracy: 0.8064 - val_loss: 0.3803 - val_accuracy: 0.8054 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 28/600\n",
            "1041/1041 - 13s - loss: 0.3896 - accuracy: 0.8072 - val_loss: 0.3804 - val_accuracy: 0.8072 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 29/600\n",
            "1041/1041 - 13s - loss: 0.3886 - accuracy: 0.8066 - val_loss: 0.3763 - val_accuracy: 0.8056 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 30/600\n",
            "1041/1041 - 13s - loss: 0.3893 - accuracy: 0.8058 - val_loss: 0.3795 - val_accuracy: 0.8055 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 31/600\n",
            "1041/1041 - 13s - loss: 0.3897 - accuracy: 0.8053 - val_loss: 0.3778 - val_accuracy: 0.8084 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 32/600\n",
            "1041/1041 - 13s - loss: 0.3887 - accuracy: 0.8060 - val_loss: 0.3795 - val_accuracy: 0.8055 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 33/600\n",
            "1041/1041 - 13s - loss: 0.3793 - accuracy: 0.8064 - val_loss: 0.3696 - val_accuracy: 0.8058 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 34/600\n",
            "1041/1041 - 13s - loss: 0.3790 - accuracy: 0.8052 - val_loss: 0.3716 - val_accuracy: 0.8049 - lr: 6.2500e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 35/600\n",
            "1041/1041 - 13s - loss: 0.3789 - accuracy: 0.8059 - val_loss: 0.3716 - val_accuracy: 0.8066 - lr: 6.2500e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 36/600\n",
            "1041/1041 - 13s - loss: 0.3784 - accuracy: 0.8063 - val_loss: 0.3756 - val_accuracy: 0.8065 - lr: 6.2500e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 37/600\n",
            "1041/1041 - 13s - loss: 0.3733 - accuracy: 0.8065 - val_loss: 0.3676 - val_accuracy: 0.8054 - lr: 3.1250e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 38/600\n",
            "1041/1041 - 14s - loss: 0.3732 - accuracy: 0.8068 - val_loss: 0.3658 - val_accuracy: 0.8049 - lr: 3.1250e-04 - 14s/epoch - 13ms/step\n",
            "Epoch 39/600\n",
            "1041/1041 - 14s - loss: 0.3725 - accuracy: 0.8061 - val_loss: 0.3677 - val_accuracy: 0.8055 - lr: 3.1250e-04 - 14s/epoch - 13ms/step\n",
            "Epoch 40/600\n",
            "1041/1041 - 13s - loss: 0.3721 - accuracy: 0.8069 - val_loss: 0.3675 - val_accuracy: 0.8059 - lr: 3.1250e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 41/600\n",
            "1041/1041 - 13s - loss: 0.3723 - accuracy: 0.8070 - val_loss: 0.3659 - val_accuracy: 0.8081 - lr: 3.1250e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 42/600\n",
            "1041/1041 - 13s - loss: 0.3693 - accuracy: 0.8079 - val_loss: 0.3646 - val_accuracy: 0.8080 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 43/600\n",
            "1041/1041 - 13s - loss: 0.3691 - accuracy: 0.8066 - val_loss: 0.3635 - val_accuracy: 0.8064 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 44/600\n",
            "1041/1041 - 13s - loss: 0.3689 - accuracy: 0.8074 - val_loss: 0.3640 - val_accuracy: 0.8048 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 45/600\n",
            "1041/1041 - 13s - loss: 0.3687 - accuracy: 0.8062 - val_loss: 0.3628 - val_accuracy: 0.8060 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 46/600\n",
            "1041/1041 - 13s - loss: 0.3687 - accuracy: 0.8061 - val_loss: 0.3628 - val_accuracy: 0.8074 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 47/600\n",
            "1041/1041 - 13s - loss: 0.3681 - accuracy: 0.8077 - val_loss: 0.3633 - val_accuracy: 0.8067 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 48/600\n",
            "1041/1041 - 13s - loss: 0.3682 - accuracy: 0.8060 - val_loss: 0.3626 - val_accuracy: 0.8067 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 49/600\n",
            "1041/1041 - 13s - loss: 0.3681 - accuracy: 0.8062 - val_loss: 0.3657 - val_accuracy: 0.8054 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 50/600\n",
            "1041/1041 - 13s - loss: 0.3680 - accuracy: 0.8076 - val_loss: 0.3629 - val_accuracy: 0.8063 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 51/600\n",
            "1041/1041 - 13s - loss: 0.3676 - accuracy: 0.8067 - val_loss: 0.3625 - val_accuracy: 0.8064 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 52/600\n",
            "1041/1041 - 13s - loss: 0.3661 - accuracy: 0.8070 - val_loss: 0.3614 - val_accuracy: 0.8058 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 53/600\n",
            "1041/1041 - 13s - loss: 0.3660 - accuracy: 0.8066 - val_loss: 0.3611 - val_accuracy: 0.8046 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 54/600\n",
            "1041/1041 - 13s - loss: 0.3659 - accuracy: 0.8070 - val_loss: 0.3613 - val_accuracy: 0.8072 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 55/600\n",
            "1041/1041 - 13s - loss: 0.3661 - accuracy: 0.8061 - val_loss: 0.3616 - val_accuracy: 0.8060 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 56/600\n",
            "1041/1041 - 13s - loss: 0.3658 - accuracy: 0.8068 - val_loss: 0.3607 - val_accuracy: 0.8082 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 57/600\n",
            "1041/1041 - 13s - loss: 0.3658 - accuracy: 0.8062 - val_loss: 0.3621 - val_accuracy: 0.8050 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 58/600\n",
            "1041/1041 - 13s - loss: 0.3659 - accuracy: 0.8060 - val_loss: 0.3613 - val_accuracy: 0.8059 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 59/600\n",
            "1041/1041 - 13s - loss: 0.3655 - accuracy: 0.8069 - val_loss: 0.3604 - val_accuracy: 0.8076 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 60/600\n",
            "1041/1041 - 13s - loss: 0.3655 - accuracy: 0.8068 - val_loss: 0.3606 - val_accuracy: 0.8068 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 61/600\n",
            "1041/1041 - 14s - loss: 0.3655 - accuracy: 0.8076 - val_loss: 0.3603 - val_accuracy: 0.8085 - lr: 7.8125e-05 - 14s/epoch - 13ms/step\n",
            "Epoch 62/600\n",
            "1041/1041 - 13s - loss: 0.3654 - accuracy: 0.8066 - val_loss: 0.3615 - val_accuracy: 0.8057 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 63/600\n",
            "1041/1041 - 13s - loss: 0.3646 - accuracy: 0.8074 - val_loss: 0.3602 - val_accuracy: 0.8059 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 64/600\n",
            "1041/1041 - 13s - loss: 0.3647 - accuracy: 0.8068 - val_loss: 0.3603 - val_accuracy: 0.8069 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 65/600\n",
            "1041/1041 - 13s - loss: 0.3645 - accuracy: 0.8080 - val_loss: 0.3598 - val_accuracy: 0.8055 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 66/600\n",
            "1041/1041 - 13s - loss: 0.3644 - accuracy: 0.8072 - val_loss: 0.3597 - val_accuracy: 0.8071 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 67/600\n",
            "1041/1041 - 13s - loss: 0.3644 - accuracy: 0.8065 - val_loss: 0.3596 - val_accuracy: 0.8072 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 68/600\n",
            "1041/1041 - 13s - loss: 0.3642 - accuracy: 0.8071 - val_loss: 0.3603 - val_accuracy: 0.8059 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 69/600\n",
            "1041/1041 - 13s - loss: 0.3644 - accuracy: 0.8077 - val_loss: 0.3598 - val_accuracy: 0.8048 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 70/600\n",
            "1041/1041 - 13s - loss: 0.3645 - accuracy: 0.8063 - val_loss: 0.3599 - val_accuracy: 0.8072 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 71/600\n",
            "1041/1041 - 13s - loss: 0.3639 - accuracy: 0.8065 - val_loss: 0.3597 - val_accuracy: 0.8060 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 72/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8075 - val_loss: 0.3594 - val_accuracy: 0.8060 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 73/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8069 - val_loss: 0.3593 - val_accuracy: 0.8062 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 74/600\n",
            "1041/1041 - 13s - loss: 0.3639 - accuracy: 0.8073 - val_loss: 0.3596 - val_accuracy: 0.8064 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 75/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8065 - val_loss: 0.3594 - val_accuracy: 0.8078 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 76/600\n",
            "1041/1041 - 13s - loss: 0.3636 - accuracy: 0.8077 - val_loss: 0.3596 - val_accuracy: 0.8068 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 77/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8081 - val_loss: 0.3593 - val_accuracy: 0.8069 - lr: 9.7656e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 78/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8075 - val_loss: 0.3592 - val_accuracy: 0.8060 - lr: 9.7656e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 79/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8072 - val_loss: 0.3591 - val_accuracy: 0.8071 - lr: 9.7656e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 80/600\n",
            "1041/1041 - 13s - loss: 0.3636 - accuracy: 0.8067 - val_loss: 0.3593 - val_accuracy: 0.8063 - lr: 9.7656e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 81/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8079 - val_loss: 0.3592 - val_accuracy: 0.8060 - lr: 9.7656e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 82/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8074 - val_loss: 0.3591 - val_accuracy: 0.8058 - lr: 9.7656e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 83/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8067 - val_loss: 0.3591 - val_accuracy: 0.8071 - lr: 4.8828e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 84/600\n",
            "1041/1041 - 13s - loss: 0.3634 - accuracy: 0.8077 - val_loss: 0.3591 - val_accuracy: 0.8067 - lr: 4.8828e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 85/600\n",
            "1041/1041 - 13s - loss: 0.3632 - accuracy: 0.8083 - val_loss: 0.3590 - val_accuracy: 0.8071 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 86/600\n",
            "1041/1041 - 13s - loss: 0.3633 - accuracy: 0.8074 - val_loss: 0.3591 - val_accuracy: 0.8066 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 87/600\n",
            "1041/1041 - 13s - loss: 0.3632 - accuracy: 0.8082 - val_loss: 0.3591 - val_accuracy: 0.8072 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 88/600\n",
            "1041/1041 - 13s - loss: 0.3635 - accuracy: 0.8068 - val_loss: 0.3591 - val_accuracy: 0.8076 - lr: 4.8828e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 89/600\n",
            "1041/1041 - 13s - loss: 0.3631 - accuracy: 0.8077 - val_loss: 0.3591 - val_accuracy: 0.8069 - lr: 2.4414e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 90/600\n",
            "1041/1041 - 13s - loss: 0.3633 - accuracy: 0.8077 - val_loss: 0.3590 - val_accuracy: 0.8070 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 91/600\n",
            "1041/1041 - 13s - loss: 0.3631 - accuracy: 0.8082 - val_loss: 0.3590 - val_accuracy: 0.8063 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 92/600\n",
            "1041/1041 - 13s - loss: 0.3629 - accuracy: 0.8081 - val_loss: 0.3590 - val_accuracy: 0.8066 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 93/600\n",
            "1041/1041 - 13s - loss: 0.3631 - accuracy: 0.8075 - val_loss: 0.3590 - val_accuracy: 0.8067 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 94/600\n",
            "1041/1041 - 13s - loss: 0.3632 - accuracy: 0.8081 - val_loss: 0.3590 - val_accuracy: 0.8068 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 95/600\n",
            "1041/1041 - 13s - loss: 0.3632 - accuracy: 0.8083 - val_loss: 0.3590 - val_accuracy: 0.8068 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 96/600\n",
            "1041/1041 - 13s - loss: 0.3632 - accuracy: 0.8079 - val_loss: 0.3590 - val_accuracy: 0.8066 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 97/600\n",
            "1041/1041 - 13s - loss: 0.3631 - accuracy: 0.8079 - val_loss: 0.3590 - val_accuracy: 0.8066 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12 13]\n",
            " [14 11  3  2 12  7]\n",
            " [14 11  3  2 12  9]\n",
            " ...\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12  1]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12 13  1]\n",
            " [14 11  3 ... 12  7 13]\n",
            " [14 11  3 ... 12  9 13]\n",
            " ...\n",
            " [14 11  3 ... 12 13  7]\n",
            " [14 11  3 ... 12 13  5]\n",
            " [14 11  3 ... 12  1  5]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ... 13  1  5]\n",
            " [14 11  3 ...  7 13  5]\n",
            " [14 11  3 ...  9 13  7]\n",
            " ...\n",
            " [14 11  3 ... 13  7  5]\n",
            " [14 11  3 ... 13  5  1]\n",
            " [14 11  3 ...  1  5 13]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ...  1  5  7]\n",
            " [14 11  3 ... 13  5  9]\n",
            " [14 11  3 ... 13  7  5]\n",
            " ...\n",
            " [14 11  3 ...  7  5  9]\n",
            " [14 11  3 ...  5  1  7]\n",
            " [14 11  3 ...  5 13  7]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ...  5  7  9]\n",
            " [14 11  3 ...  5  9  1]\n",
            " [14 11  3 ...  7  5  1]\n",
            " ...\n",
            " [14 11  3 ...  5  9  1]\n",
            " [14 11  3 ...  1  7  9]\n",
            " [14 11  3 ... 13  7  9]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ...  7  9  8]\n",
            " [14 11  3 ...  9  1  8]\n",
            " [14 11  3 ...  5  1  8]\n",
            " ...\n",
            " [14 11  3 ...  9  1  8]\n",
            " [14 11  3 ...  7  9  8]\n",
            " [14 11  3 ...  7  9  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  1  8 10]\n",
            " [14 11  3 ...  1  8 10]\n",
            " ...\n",
            " [14 11  3 ...  1  8 10]\n",
            " [14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  9  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n",
            "Model: \"sequential_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_47 (Bidirecti  (None, 128)              40960     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_47 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,895\n",
            "Trainable params: 42,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1041/1041 - 18s - loss: 0.7199 - accuracy: 0.7849 - val_loss: 0.4761 - val_accuracy: 0.8059 - lr: 0.0050 - 18s/epoch - 18ms/step\n",
            "Epoch 2/600\n",
            "1041/1041 - 13s - loss: 0.4776 - accuracy: 0.8054 - val_loss: 0.4514 - val_accuracy: 0.8053 - lr: 0.0050 - 13s/epoch - 13ms/step\n",
            "Epoch 3/600\n",
            "1041/1041 - 13s - loss: 0.4617 - accuracy: 0.8066 - val_loss: 0.4431 - val_accuracy: 0.8064 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 4/600\n",
            "1041/1041 - 13s - loss: 0.4546 - accuracy: 0.8051 - val_loss: 0.4341 - val_accuracy: 0.8070 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 5/600\n",
            "1041/1041 - 13s - loss: 0.4506 - accuracy: 0.8061 - val_loss: 0.4377 - val_accuracy: 0.8067 - lr: 0.0050 - 13s/epoch - 13ms/step\n",
            "Epoch 6/600\n",
            "1041/1041 - 13s - loss: 0.4524 - accuracy: 0.8058 - val_loss: 0.4227 - val_accuracy: 0.8063 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 7/600\n",
            "1041/1041 - 13s - loss: 0.4542 - accuracy: 0.8057 - val_loss: 0.4268 - val_accuracy: 0.8076 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 8/600\n",
            "1041/1041 - 13s - loss: 0.4414 - accuracy: 0.8056 - val_loss: 0.4268 - val_accuracy: 0.8073 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 9/600\n",
            "1041/1041 - 13s - loss: 0.4691 - accuracy: 0.8053 - val_loss: 0.4806 - val_accuracy: 0.8058 - lr: 0.0050 - 13s/epoch - 13ms/step\n",
            "Epoch 10/600\n",
            "1041/1041 - 13s - loss: 0.4282 - accuracy: 0.8074 - val_loss: 0.4056 - val_accuracy: 0.8064 - lr: 0.0025 - 13s/epoch - 13ms/step\n",
            "Epoch 11/600\n",
            "1041/1041 - 13s - loss: 0.4129 - accuracy: 0.8050 - val_loss: 0.3969 - val_accuracy: 0.8047 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 12/600\n",
            "1041/1041 - 13s - loss: 0.4111 - accuracy: 0.8069 - val_loss: 0.3939 - val_accuracy: 0.8072 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 13/600\n",
            "1041/1041 - 13s - loss: 0.4117 - accuracy: 0.8052 - val_loss: 0.3990 - val_accuracy: 0.8076 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 14/600\n",
            "1041/1041 - 13s - loss: 0.4109 - accuracy: 0.8050 - val_loss: 0.3920 - val_accuracy: 0.8065 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 15/600\n",
            "1041/1041 - 13s - loss: 0.4094 - accuracy: 0.8055 - val_loss: 0.3984 - val_accuracy: 0.8055 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 16/600\n",
            "1041/1041 - 13s - loss: 0.4092 - accuracy: 0.8061 - val_loss: 0.4027 - val_accuracy: 0.8064 - lr: 0.0025 - 13s/epoch - 13ms/step\n",
            "Epoch 17/600\n",
            "1041/1041 - 13s - loss: 0.4090 - accuracy: 0.8064 - val_loss: 0.3956 - val_accuracy: 0.8060 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 18/600\n",
            "1041/1041 - 13s - loss: 0.3925 - accuracy: 0.8062 - val_loss: 0.3820 - val_accuracy: 0.8073 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 19/600\n",
            "1041/1041 - 13s - loss: 0.3923 - accuracy: 0.8062 - val_loss: 0.3840 - val_accuracy: 0.8062 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 20/600\n",
            "1041/1041 - 13s - loss: 0.3914 - accuracy: 0.8060 - val_loss: 0.3895 - val_accuracy: 0.8071 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 21/600\n",
            "1041/1041 - 13s - loss: 0.3914 - accuracy: 0.8065 - val_loss: 0.3799 - val_accuracy: 0.8042 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 22/600\n",
            "1041/1041 - 13s - loss: 0.3911 - accuracy: 0.8050 - val_loss: 0.3863 - val_accuracy: 0.8058 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 23/600\n",
            "1041/1041 - 13s - loss: 0.3902 - accuracy: 0.8056 - val_loss: 0.3824 - val_accuracy: 0.8058 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 24/600\n",
            "1041/1041 - 13s - loss: 0.3903 - accuracy: 0.8064 - val_loss: 0.3764 - val_accuracy: 0.8057 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 25/600\n",
            "1041/1041 - 13s - loss: 0.3895 - accuracy: 0.8063 - val_loss: 0.3791 - val_accuracy: 0.8061 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 26/600\n",
            "1041/1041 - 13s - loss: 0.3900 - accuracy: 0.8062 - val_loss: 0.3794 - val_accuracy: 0.8058 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 27/600\n",
            "1041/1041 - 13s - loss: 0.3896 - accuracy: 0.8058 - val_loss: 0.3774 - val_accuracy: 0.8058 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 28/600\n",
            "1041/1041 - 13s - loss: 0.3796 - accuracy: 0.8065 - val_loss: 0.3701 - val_accuracy: 0.8069 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 29/600\n",
            "1041/1041 - 13s - loss: 0.3793 - accuracy: 0.8065 - val_loss: 0.3721 - val_accuracy: 0.8059 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 30/600\n",
            "1041/1041 - 13s - loss: 0.3792 - accuracy: 0.8062 - val_loss: 0.3711 - val_accuracy: 0.8051 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 31/600\n",
            "1041/1041 - 13s - loss: 0.3791 - accuracy: 0.8056 - val_loss: 0.3701 - val_accuracy: 0.8058 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 32/600\n",
            "1041/1041 - 13s - loss: 0.3738 - accuracy: 0.8058 - val_loss: 0.3668 - val_accuracy: 0.8042 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 33/600\n",
            "1041/1041 - 13s - loss: 0.3733 - accuracy: 0.8052 - val_loss: 0.3657 - val_accuracy: 0.8087 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 34/600\n",
            "1041/1041 - 13s - loss: 0.3730 - accuracy: 0.8060 - val_loss: 0.3654 - val_accuracy: 0.8064 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 35/600\n",
            "1041/1041 - 13s - loss: 0.3725 - accuracy: 0.8065 - val_loss: 0.3673 - val_accuracy: 0.8068 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 36/600\n",
            "1041/1041 - 13s - loss: 0.3723 - accuracy: 0.8066 - val_loss: 0.3682 - val_accuracy: 0.8047 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 37/600\n",
            "1041/1041 - 13s - loss: 0.3720 - accuracy: 0.8065 - val_loss: 0.3660 - val_accuracy: 0.8061 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 38/600\n",
            "1041/1041 - 13s - loss: 0.3688 - accuracy: 0.8073 - val_loss: 0.3644 - val_accuracy: 0.8061 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 39/600\n",
            "1041/1041 - 13s - loss: 0.3689 - accuracy: 0.8069 - val_loss: 0.3626 - val_accuracy: 0.8064 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 40/600\n",
            "1041/1041 - 13s - loss: 0.3688 - accuracy: 0.8062 - val_loss: 0.3629 - val_accuracy: 0.8068 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 41/600\n",
            "1041/1041 - 13s - loss: 0.3687 - accuracy: 0.8069 - val_loss: 0.3625 - val_accuracy: 0.8070 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 42/600\n",
            "1041/1041 - 13s - loss: 0.3686 - accuracy: 0.8063 - val_loss: 0.3624 - val_accuracy: 0.8051 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 43/600\n",
            "1041/1041 - 13s - loss: 0.3684 - accuracy: 0.8067 - val_loss: 0.3618 - val_accuracy: 0.8082 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 44/600\n",
            "1041/1041 - 13s - loss: 0.3683 - accuracy: 0.8061 - val_loss: 0.3617 - val_accuracy: 0.8073 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 45/600\n",
            "1041/1041 - 13s - loss: 0.3680 - accuracy: 0.8070 - val_loss: 0.3622 - val_accuracy: 0.8054 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 46/600\n",
            "1041/1041 - 13s - loss: 0.3680 - accuracy: 0.8063 - val_loss: 0.3631 - val_accuracy: 0.8063 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 47/600\n",
            "1041/1041 - 13s - loss: 0.3678 - accuracy: 0.8066 - val_loss: 0.3617 - val_accuracy: 0.8063 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 48/600\n",
            "1041/1041 - 13s - loss: 0.3664 - accuracy: 0.8064 - val_loss: 0.3610 - val_accuracy: 0.8055 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 49/600\n",
            "1041/1041 - 13s - loss: 0.3664 - accuracy: 0.8064 - val_loss: 0.3609 - val_accuracy: 0.8054 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 50/600\n",
            "1041/1041 - 13s - loss: 0.3662 - accuracy: 0.8067 - val_loss: 0.3606 - val_accuracy: 0.8085 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 51/600\n",
            "1041/1041 - 13s - loss: 0.3661 - accuracy: 0.8068 - val_loss: 0.3608 - val_accuracy: 0.8056 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 52/600\n",
            "1041/1041 - 13s - loss: 0.3660 - accuracy: 0.8068 - val_loss: 0.3606 - val_accuracy: 0.8060 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 53/600\n",
            "1041/1041 - 13s - loss: 0.3657 - accuracy: 0.8071 - val_loss: 0.3606 - val_accuracy: 0.8054 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 54/600\n",
            "1041/1041 - 13s - loss: 0.3648 - accuracy: 0.8081 - val_loss: 0.3603 - val_accuracy: 0.8048 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 55/600\n",
            "1041/1041 - 13s - loss: 0.3650 - accuracy: 0.8070 - val_loss: 0.3600 - val_accuracy: 0.8059 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 56/600\n",
            "1041/1041 - 13s - loss: 0.3650 - accuracy: 0.8058 - val_loss: 0.3600 - val_accuracy: 0.8057 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 57/600\n",
            "1041/1041 - 13s - loss: 0.3649 - accuracy: 0.8074 - val_loss: 0.3601 - val_accuracy: 0.8054 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 58/600\n",
            "1041/1041 - 13s - loss: 0.3649 - accuracy: 0.8071 - val_loss: 0.3600 - val_accuracy: 0.8063 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 59/600\n",
            "1041/1041 - 13s - loss: 0.3645 - accuracy: 0.8074 - val_loss: 0.3596 - val_accuracy: 0.8067 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 60/600\n",
            "1041/1041 - 13s - loss: 0.3646 - accuracy: 0.8075 - val_loss: 0.3595 - val_accuracy: 0.8069 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 61/600\n",
            "1041/1041 - 13s - loss: 0.3643 - accuracy: 0.8079 - val_loss: 0.3595 - val_accuracy: 0.8072 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 62/600\n",
            "1041/1041 - 13s - loss: 0.3645 - accuracy: 0.8067 - val_loss: 0.3596 - val_accuracy: 0.8057 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 63/600\n",
            "1041/1041 - 13s - loss: 0.3640 - accuracy: 0.8082 - val_loss: 0.3595 - val_accuracy: 0.8058 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 64/600\n",
            "1041/1041 - 13s - loss: 0.3642 - accuracy: 0.8082 - val_loss: 0.3595 - val_accuracy: 0.8063 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 65/600\n",
            "1041/1041 - 13s - loss: 0.3641 - accuracy: 0.8075 - val_loss: 0.3595 - val_accuracy: 0.8072 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 66/600\n",
            "1041/1041 - 13s - loss: 0.3640 - accuracy: 0.8077 - val_loss: 0.3594 - val_accuracy: 0.8057 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 67/600\n",
            "1041/1041 - 13s - loss: 0.3640 - accuracy: 0.8074 - val_loss: 0.3593 - val_accuracy: 0.8073 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 68/600\n",
            "1041/1041 - 13s - loss: 0.3639 - accuracy: 0.8079 - val_loss: 0.3593 - val_accuracy: 0.8066 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 69/600\n",
            "1041/1041 - 13s - loss: 0.3641 - accuracy: 0.8076 - val_loss: 0.3593 - val_accuracy: 0.8066 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 70/600\n",
            "1041/1041 - 13s - loss: 0.3639 - accuracy: 0.8087 - val_loss: 0.3593 - val_accuracy: 0.8064 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 71/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8076 - val_loss: 0.3593 - val_accuracy: 0.8060 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 72/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8080 - val_loss: 0.3593 - val_accuracy: 0.8066 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 73/600\n",
            "1041/1041 - 13s - loss: 0.3639 - accuracy: 0.8083 - val_loss: 0.3593 - val_accuracy: 0.8066 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 74/600\n",
            "1041/1041 - 13s - loss: 0.3640 - accuracy: 0.8073 - val_loss: 0.3593 - val_accuracy: 0.8069 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 75/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8078 - val_loss: 0.3593 - val_accuracy: 0.8066 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 76/600\n",
            "1041/1041 - 13s - loss: 0.3637 - accuracy: 0.8080 - val_loss: 0.3593 - val_accuracy: 0.8069 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 77/600\n",
            "1041/1041 - 13s - loss: 0.3637 - accuracy: 0.8084 - val_loss: 0.3593 - val_accuracy: 0.8066 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 78/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8078 - val_loss: 0.3592 - val_accuracy: 0.8066 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 79/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8081 - val_loss: 0.3592 - val_accuracy: 0.8066 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 80/600\n",
            "1041/1041 - 13s - loss: 0.3639 - accuracy: 0.8075 - val_loss: 0.3592 - val_accuracy: 0.8066 - lr: 6.1035e-07 - 13s/epoch - 13ms/step\n",
            "Epoch 81/600\n",
            "1041/1041 - 13s - loss: 0.3639 - accuracy: 0.8083 - val_loss: 0.3592 - val_accuracy: 0.8066 - lr: 3.0518e-07 - 13s/epoch - 13ms/step\n",
            "Epoch 82/600\n",
            "1041/1041 - 13s - loss: 0.3637 - accuracy: 0.8089 - val_loss: 0.3592 - val_accuracy: 0.8064 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 83/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8085 - val_loss: 0.3592 - val_accuracy: 0.8066 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 84/600\n",
            "1041/1041 - 13s - loss: 0.3638 - accuracy: 0.8085 - val_loss: 0.3592 - val_accuracy: 0.8064 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 85/600\n",
            "1041/1041 - 13s - loss: 0.3639 - accuracy: 0.8088 - val_loss: 0.3592 - val_accuracy: 0.8064 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 86/600\n",
            "1041/1041 - 13s - loss: 0.3637 - accuracy: 0.8086 - val_loss: 0.3592 - val_accuracy: 0.8064 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12  5]\n",
            " [14 11  3  2 12  1]\n",
            " [14 11  3  2 12  7]\n",
            " ...\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12  9]\n",
            " [14 11  3  2 12 13]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12  5  1]\n",
            " [14 11  3 ... 12  1  9]\n",
            " [14 11  3 ... 12  7  1]\n",
            " ...\n",
            " [14 11  3 ... 12 13  9]\n",
            " [14 11  3 ... 12  9  1]\n",
            " [14 11  3 ... 12 13  9]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ...  5  1 13]\n",
            " [14 11  3 ...  1  9  5]\n",
            " [14 11  3 ...  7  1  9]\n",
            " ...\n",
            " [14 11  3 ... 13  9  1]\n",
            " [14 11  3 ...  9  1  5]\n",
            " [14 11  3 ... 13  9  5]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ...  1 13  7]\n",
            " [14 11  3 ...  9  5  7]\n",
            " [14 11  3 ...  1  9  5]\n",
            " ...\n",
            " [14 11  3 ...  9  1  5]\n",
            " [14 11  3 ...  1  5 13]\n",
            " [14 11  3 ...  9  5  1]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ... 13  7  9]\n",
            " [14 11  3 ...  5  7 13]\n",
            " [14 11  3 ...  9  5 13]\n",
            " ...\n",
            " [14 11  3 ...  1  5  7]\n",
            " [14 11  3 ...  5 13  7]\n",
            " [14 11  3 ...  5  1  7]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ...  7  9  8]\n",
            " [14 11  3 ...  7 13  8]\n",
            " [14 11  3 ...  5 13  8]\n",
            " ...\n",
            " [14 11  3 ...  5  7  8]\n",
            " [14 11  3 ... 13  7  8]\n",
            " [14 11  3 ...  1  7  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ...  9  8 10]\n",
            " [14 11  3 ... 13  8 10]\n",
            " [14 11  3 ... 13  8 10]\n",
            " ...\n",
            " [14 11  3 ...  7  8 10]\n",
            " [14 11  3 ...  7  8 10]\n",
            " [14 11  3 ...  7  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n",
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_48 (Bidirecti  (None, 128)              40960     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_48 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,895\n",
            "Trainable params: 42,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1042/1042 - 17s - loss: 0.7167 - accuracy: 0.7842 - val_loss: 0.4917 - val_accuracy: 0.8068 - lr: 0.0050 - 17s/epoch - 17ms/step\n",
            "Epoch 2/600\n",
            "1042/1042 - 13s - loss: 0.4812 - accuracy: 0.8067 - val_loss: 0.4571 - val_accuracy: 0.8052 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 3/600\n",
            "1042/1042 - 13s - loss: 0.4640 - accuracy: 0.8067 - val_loss: 0.4394 - val_accuracy: 0.8042 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 4/600\n",
            "1042/1042 - 13s - loss: 0.4558 - accuracy: 0.8051 - val_loss: 0.4277 - val_accuracy: 0.8067 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 5/600\n",
            "1042/1042 - 13s - loss: 0.4472 - accuracy: 0.8063 - val_loss: 0.4257 - val_accuracy: 0.8078 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 6/600\n",
            "1042/1042 - 13s - loss: 0.4453 - accuracy: 0.8058 - val_loss: 0.4218 - val_accuracy: 0.8055 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 7/600\n",
            "1042/1042 - 13s - loss: 0.4419 - accuracy: 0.8067 - val_loss: 0.4227 - val_accuracy: 0.8050 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 8/600\n",
            "1042/1042 - 13s - loss: 0.4866 - accuracy: 0.8048 - val_loss: 0.4238 - val_accuracy: 0.8052 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 9/600\n",
            "1042/1042 - 13s - loss: 0.4388 - accuracy: 0.8055 - val_loss: 0.4207 - val_accuracy: 0.8052 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 10/600\n",
            "1042/1042 - 13s - loss: 0.4368 - accuracy: 0.8057 - val_loss: 0.4263 - val_accuracy: 0.8068 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 11/600\n",
            "1042/1042 - 13s - loss: 0.4407 - accuracy: 0.8055 - val_loss: 0.5680 - val_accuracy: 0.8067 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 12/600\n",
            "1042/1042 - 13s - loss: 0.4692 - accuracy: 0.8052 - val_loss: 0.4402 - val_accuracy: 0.8063 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 13/600\n",
            "1042/1042 - 13s - loss: 0.4116 - accuracy: 0.8059 - val_loss: 0.3962 - val_accuracy: 0.8046 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 14/600\n",
            "1042/1042 - 13s - loss: 0.4096 - accuracy: 0.8058 - val_loss: 0.4026 - val_accuracy: 0.8080 - lr: 0.0025 - 13s/epoch - 13ms/step\n",
            "Epoch 15/600\n",
            "1042/1042 - 13s - loss: 0.4097 - accuracy: 0.8064 - val_loss: 0.3915 - val_accuracy: 0.8056 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 16/600\n",
            "1042/1042 - 13s - loss: 0.4083 - accuracy: 0.8072 - val_loss: 0.3974 - val_accuracy: 0.8046 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 17/600\n",
            "1042/1042 - 13s - loss: 0.4080 - accuracy: 0.8055 - val_loss: 0.3948 - val_accuracy: 0.8073 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 18/600\n",
            "1042/1042 - 13s - loss: 0.4070 - accuracy: 0.8059 - val_loss: 0.3997 - val_accuracy: 0.8074 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 19/600\n",
            "1042/1042 - 13s - loss: 0.3917 - accuracy: 0.8065 - val_loss: 0.3821 - val_accuracy: 0.8063 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 20/600\n",
            "1042/1042 - 13s - loss: 0.3914 - accuracy: 0.8062 - val_loss: 0.3812 - val_accuracy: 0.8039 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 21/600\n",
            "1042/1042 - 13s - loss: 0.3910 - accuracy: 0.8055 - val_loss: 0.3807 - val_accuracy: 0.8048 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 22/600\n",
            "1042/1042 - 13s - loss: 0.3890 - accuracy: 0.8062 - val_loss: 0.3813 - val_accuracy: 0.8066 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 23/600\n",
            "1042/1042 - 13s - loss: 0.3888 - accuracy: 0.8053 - val_loss: 0.3778 - val_accuracy: 0.8049 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 24/600\n",
            "1042/1042 - 13s - loss: 0.3895 - accuracy: 0.8064 - val_loss: 0.3791 - val_accuracy: 0.8031 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 25/600\n",
            "1042/1042 - 13s - loss: 0.3887 - accuracy: 0.8046 - val_loss: 0.3817 - val_accuracy: 0.8066 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 26/600\n",
            "1042/1042 - 13s - loss: 0.3882 - accuracy: 0.8066 - val_loss: 0.3761 - val_accuracy: 0.8068 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 27/600\n",
            "1042/1042 - 13s - loss: 0.3883 - accuracy: 0.8054 - val_loss: 0.3765 - val_accuracy: 0.8085 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 28/600\n",
            "1042/1042 - 13s - loss: 0.3887 - accuracy: 0.8067 - val_loss: 0.3824 - val_accuracy: 0.8066 - lr: 0.0012 - 13s/epoch - 13ms/step\n",
            "Epoch 29/600\n",
            "1042/1042 - 13s - loss: 0.3882 - accuracy: 0.8063 - val_loss: 0.3787 - val_accuracy: 0.8060 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 30/600\n",
            "1042/1042 - 13s - loss: 0.3787 - accuracy: 0.8062 - val_loss: 0.3697 - val_accuracy: 0.8054 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 31/600\n",
            "1042/1042 - 13s - loss: 0.3780 - accuracy: 0.8062 - val_loss: 0.3713 - val_accuracy: 0.8052 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 32/600\n",
            "1042/1042 - 13s - loss: 0.3786 - accuracy: 0.8065 - val_loss: 0.3759 - val_accuracy: 0.8060 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 33/600\n",
            "1042/1042 - 13s - loss: 0.3774 - accuracy: 0.8051 - val_loss: 0.3717 - val_accuracy: 0.8054 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 34/600\n",
            "1042/1042 - 13s - loss: 0.3724 - accuracy: 0.8068 - val_loss: 0.3651 - val_accuracy: 0.8071 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 35/600\n",
            "1042/1042 - 13s - loss: 0.3722 - accuracy: 0.8059 - val_loss: 0.3645 - val_accuracy: 0.8056 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 36/600\n",
            "1042/1042 - 13s - loss: 0.3719 - accuracy: 0.8059 - val_loss: 0.3656 - val_accuracy: 0.8060 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 37/600\n",
            "1042/1042 - 13s - loss: 0.3713 - accuracy: 0.8063 - val_loss: 0.3642 - val_accuracy: 0.8080 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 38/600\n",
            "1042/1042 - 13s - loss: 0.3711 - accuracy: 0.8051 - val_loss: 0.3652 - val_accuracy: 0.8073 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 39/600\n",
            "1042/1042 - 13s - loss: 0.3711 - accuracy: 0.8047 - val_loss: 0.3636 - val_accuracy: 0.8068 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 40/600\n",
            "1042/1042 - 13s - loss: 0.3711 - accuracy: 0.8062 - val_loss: 0.3650 - val_accuracy: 0.8061 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 41/600\n",
            "1042/1042 - 13s - loss: 0.3707 - accuracy: 0.8062 - val_loss: 0.3643 - val_accuracy: 0.8039 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 42/600\n",
            "1042/1042 - 13s - loss: 0.3705 - accuracy: 0.8064 - val_loss: 0.3641 - val_accuracy: 0.8058 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 43/600\n",
            "1042/1042 - 13s - loss: 0.3677 - accuracy: 0.8064 - val_loss: 0.3615 - val_accuracy: 0.8070 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 44/600\n",
            "1042/1042 - 13s - loss: 0.3671 - accuracy: 0.8059 - val_loss: 0.3620 - val_accuracy: 0.8081 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 45/600\n",
            "1042/1042 - 13s - loss: 0.3670 - accuracy: 0.8070 - val_loss: 0.3628 - val_accuracy: 0.8044 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 46/600\n",
            "1042/1042 - 13s - loss: 0.3670 - accuracy: 0.8068 - val_loss: 0.3625 - val_accuracy: 0.8054 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 47/600\n",
            "1042/1042 - 13s - loss: 0.3656 - accuracy: 0.8058 - val_loss: 0.3600 - val_accuracy: 0.8072 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 48/600\n",
            "1042/1042 - 13s - loss: 0.3651 - accuracy: 0.8064 - val_loss: 0.3603 - val_accuracy: 0.8057 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 49/600\n",
            "1042/1042 - 13s - loss: 0.3652 - accuracy: 0.8067 - val_loss: 0.3608 - val_accuracy: 0.8055 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 50/600\n",
            "1042/1042 - 13s - loss: 0.3652 - accuracy: 0.8055 - val_loss: 0.3604 - val_accuracy: 0.8049 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 51/600\n",
            "1042/1042 - 13s - loss: 0.3642 - accuracy: 0.8069 - val_loss: 0.3594 - val_accuracy: 0.8059 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 52/600\n",
            "1042/1042 - 13s - loss: 0.3640 - accuracy: 0.8080 - val_loss: 0.3595 - val_accuracy: 0.8052 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 53/600\n",
            "1042/1042 - 13s - loss: 0.3640 - accuracy: 0.8065 - val_loss: 0.3594 - val_accuracy: 0.8053 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 54/600\n",
            "1042/1042 - 13s - loss: 0.3639 - accuracy: 0.8066 - val_loss: 0.3593 - val_accuracy: 0.8064 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 55/600\n",
            "1042/1042 - 13s - loss: 0.3635 - accuracy: 0.8076 - val_loss: 0.3591 - val_accuracy: 0.8066 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 56/600\n",
            "1042/1042 - 13s - loss: 0.3634 - accuracy: 0.8075 - val_loss: 0.3590 - val_accuracy: 0.8088 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 57/600\n",
            "1042/1042 - 13s - loss: 0.3635 - accuracy: 0.8068 - val_loss: 0.3590 - val_accuracy: 0.8063 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 58/600\n",
            "1042/1042 - 13s - loss: 0.3634 - accuracy: 0.8085 - val_loss: 0.3591 - val_accuracy: 0.8065 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 59/600\n",
            "1042/1042 - 13s - loss: 0.3634 - accuracy: 0.8066 - val_loss: 0.3590 - val_accuracy: 0.8046 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 60/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8070 - val_loss: 0.3589 - val_accuracy: 0.8067 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 61/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8083 - val_loss: 0.3588 - val_accuracy: 0.8065 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 62/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8062 - val_loss: 0.3589 - val_accuracy: 0.8060 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 63/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8072 - val_loss: 0.3588 - val_accuracy: 0.8052 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 64/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8079 - val_loss: 0.3588 - val_accuracy: 0.8063 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 65/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8086 - val_loss: 0.3587 - val_accuracy: 0.8062 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 66/600\n",
            "1042/1042 - 13s - loss: 0.3628 - accuracy: 0.8082 - val_loss: 0.3587 - val_accuracy: 0.8067 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 67/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8071 - val_loss: 0.3586 - val_accuracy: 0.8066 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 68/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8081 - val_loss: 0.3587 - val_accuracy: 0.8074 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 69/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8071 - val_loss: 0.3587 - val_accuracy: 0.8061 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 70/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8066 - val_loss: 0.3586 - val_accuracy: 0.8061 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 71/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8077 - val_loss: 0.3586 - val_accuracy: 0.8060 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 72/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8078 - val_loss: 0.3586 - val_accuracy: 0.8058 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 73/600\n",
            "1042/1042 - 13s - loss: 0.3628 - accuracy: 0.8083 - val_loss: 0.3586 - val_accuracy: 0.8059 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 74/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8072 - val_loss: 0.3586 - val_accuracy: 0.8054 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 75/600\n",
            "1042/1042 - 13s - loss: 0.3628 - accuracy: 0.8084 - val_loss: 0.3586 - val_accuracy: 0.8054 - lr: 1.2207e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 76/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8066 - val_loss: 0.3586 - val_accuracy: 0.8058 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 77/600\n",
            "1042/1042 - 13s - loss: 0.3628 - accuracy: 0.8088 - val_loss: 0.3586 - val_accuracy: 0.8061 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 78/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8081 - val_loss: 0.3586 - val_accuracy: 0.8061 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 79/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8084 - val_loss: 0.3586 - val_accuracy: 0.8061 - lr: 3.0518e-07 - 13s/epoch - 13ms/step\n",
            "Epoch 80/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8080 - val_loss: 0.3586 - val_accuracy: 0.8060 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 81/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8074 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 82/600\n",
            "1042/1042 - 13s - loss: 0.3628 - accuracy: 0.8081 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 83/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8078 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 84/600\n",
            "1042/1042 - 13s - loss: 0.3628 - accuracy: 0.8078 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 85/600\n",
            "1042/1042 - 13s - loss: 0.3628 - accuracy: 0.8083 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 86/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8073 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 87/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8086 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 88/600\n",
            "1042/1042 - 13s - loss: 0.3628 - accuracy: 0.8074 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 89/600\n",
            "1042/1042 - 13s - loss: 0.3628 - accuracy: 0.8072 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 90/600\n",
            "1042/1042 - 13s - loss: 0.3627 - accuracy: 0.8082 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 91/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8068 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 92/600\n",
            "1042/1042 - 13s - loss: 0.3628 - accuracy: 0.8081 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 93/600\n",
            "1042/1042 - 13s - loss: 0.3627 - accuracy: 0.8084 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 94/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8069 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 95/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8085 - val_loss: 0.3586 - val_accuracy: 0.8057 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12  9]\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12  7]\n",
            " ...\n",
            " [14 11  3  2 12  5]\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12  1]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12  9 13]\n",
            " [14 11  3 ... 12 13  5]\n",
            " [14 11  3 ... 12  7  9]\n",
            " ...\n",
            " [14 11  3 ... 12  5  1]\n",
            " [14 11  3 ... 12 13  5]\n",
            " [14 11  3 ... 12  1  9]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ...  9 13  7]\n",
            " [14 11  3 ... 13  5  7]\n",
            " [14 11  3 ...  7  9  1]\n",
            " ...\n",
            " [14 11  3 ...  5  1 13]\n",
            " [14 11  3 ... 13  5  9]\n",
            " [14 11  3 ...  1  9 13]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ... 13  7  5]\n",
            " [14 11  3 ...  5  7  1]\n",
            " [14 11  3 ...  9  1 13]\n",
            " ...\n",
            " [14 11  3 ...  1 13  9]\n",
            " [14 11  3 ...  5  9  1]\n",
            " [14 11  3 ...  9 13  7]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ...  7  5  1]\n",
            " [14 11  3 ...  7  1  9]\n",
            " [14 11  3 ...  1 13  5]\n",
            " ...\n",
            " [14 11  3 ... 13  9  7]\n",
            " [14 11  3 ...  9  1  7]\n",
            " [14 11  3 ... 13  7  5]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ...  5  1  8]\n",
            " [14 11  3 ...  1  9  8]\n",
            " [14 11  3 ... 13  5  8]\n",
            " ...\n",
            " [14 11  3 ...  9  7  8]\n",
            " [14 11  3 ...  1  7  8]\n",
            " [14 11  3 ...  7  5  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ...  1  8 10]\n",
            " [14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  5  8 10]\n",
            " ...\n",
            " [14 11  3 ...  7  8 10]\n",
            " [14 11  3 ...  7  8 10]\n",
            " [14 11  3 ...  5  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_49 (Bidirecti  (None, 128)              40960     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_49 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,895\n",
            "Trainable params: 42,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1042/1042 - 18s - loss: 0.7137 - accuracy: 0.7847 - val_loss: 0.4629 - val_accuracy: 0.8082 - lr: 0.0050 - 18s/epoch - 17ms/step\n",
            "Epoch 2/600\n",
            "1042/1042 - 13s - loss: 0.4786 - accuracy: 0.8057 - val_loss: 0.4450 - val_accuracy: 0.8073 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 3/600\n",
            "1042/1042 - 13s - loss: 0.4615 - accuracy: 0.8056 - val_loss: 0.4527 - val_accuracy: 0.8044 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 4/600\n",
            "1042/1042 - 13s - loss: 0.4565 - accuracy: 0.8045 - val_loss: 0.4347 - val_accuracy: 0.8053 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 5/600\n",
            "1042/1042 - 13s - loss: 0.4792 - accuracy: 0.8062 - val_loss: 0.4342 - val_accuracy: 0.8071 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 6/600\n",
            "1042/1042 - 13s - loss: 0.4483 - accuracy: 0.8057 - val_loss: 0.4246 - val_accuracy: 0.8045 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 7/600\n",
            "1042/1042 - 13s - loss: 0.4442 - accuracy: 0.8059 - val_loss: 0.4273 - val_accuracy: 0.8049 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 8/600\n",
            "1042/1042 - 13s - loss: 0.4448 - accuracy: 0.8064 - val_loss: 0.4264 - val_accuracy: 0.8048 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 9/600\n",
            "1042/1042 - 13s - loss: 0.4414 - accuracy: 0.8070 - val_loss: 0.4244 - val_accuracy: 0.8052 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 10/600\n",
            "1042/1042 - 13s - loss: 0.4661 - accuracy: 0.8053 - val_loss: 0.4268 - val_accuracy: 0.8056 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 11/600\n",
            "1042/1042 - 12s - loss: 0.4389 - accuracy: 0.8058 - val_loss: 0.4243 - val_accuracy: 0.8068 - lr: 0.0050 - 12s/epoch - 12ms/step\n",
            "Epoch 12/600\n",
            "1042/1042 - 13s - loss: 0.4399 - accuracy: 0.8065 - val_loss: 0.4174 - val_accuracy: 0.8047 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 13/600\n",
            "1042/1042 - 13s - loss: 0.4666 - accuracy: 0.8047 - val_loss: 0.4477 - val_accuracy: 0.8033 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 14/600\n",
            "1042/1042 - 13s - loss: 0.4405 - accuracy: 0.8059 - val_loss: 0.4291 - val_accuracy: 0.8042 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 15/600\n",
            "1042/1042 - 13s - loss: 0.4374 - accuracy: 0.8064 - val_loss: 0.4161 - val_accuracy: 0.8070 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 16/600\n",
            "1042/1042 - 13s - loss: 0.4377 - accuracy: 0.8075 - val_loss: 0.4273 - val_accuracy: 0.8056 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 17/600\n",
            "1042/1042 - 13s - loss: 0.4885 - accuracy: 0.8049 - val_loss: 0.4575 - val_accuracy: 0.8050 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 18/600\n",
            "1042/1042 - 13s - loss: 0.4414 - accuracy: 0.8056 - val_loss: 0.4236 - val_accuracy: 0.8055 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 19/600\n",
            "1042/1042 - 13s - loss: 0.4099 - accuracy: 0.8063 - val_loss: 0.3976 - val_accuracy: 0.8056 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 20/600\n",
            "1042/1042 - 13s - loss: 0.4082 - accuracy: 0.8054 - val_loss: 0.3938 - val_accuracy: 0.8056 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 21/600\n",
            "1042/1042 - 13s - loss: 0.4088 - accuracy: 0.8048 - val_loss: 0.4001 - val_accuracy: 0.8076 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 22/600\n",
            "1042/1042 - 13s - loss: 0.4085 - accuracy: 0.8055 - val_loss: 0.3954 - val_accuracy: 0.8065 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 23/600\n",
            "1042/1042 - 13s - loss: 0.4077 - accuracy: 0.8060 - val_loss: 0.3929 - val_accuracy: 0.8071 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 24/600\n",
            "1042/1042 - 13s - loss: 0.4078 - accuracy: 0.8063 - val_loss: 0.4025 - val_accuracy: 0.8051 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 25/600\n",
            "1042/1042 - 13s - loss: 0.4086 - accuracy: 0.8058 - val_loss: 0.4027 - val_accuracy: 0.8048 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 26/600\n",
            "1042/1042 - 13s - loss: 0.4092 - accuracy: 0.8053 - val_loss: 0.4677 - val_accuracy: 0.8065 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 27/600\n",
            "1042/1042 - 13s - loss: 0.3983 - accuracy: 0.8070 - val_loss: 0.3839 - val_accuracy: 0.8049 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 28/600\n",
            "1042/1042 - 13s - loss: 0.3906 - accuracy: 0.8059 - val_loss: 0.3818 - val_accuracy: 0.8063 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 29/600\n",
            "1042/1042 - 13s - loss: 0.3907 - accuracy: 0.8066 - val_loss: 0.3765 - val_accuracy: 0.8059 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 30/600\n",
            "1042/1042 - 13s - loss: 0.3896 - accuracy: 0.8064 - val_loss: 0.3797 - val_accuracy: 0.8074 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 31/600\n",
            "1042/1042 - 13s - loss: 0.3889 - accuracy: 0.8060 - val_loss: 0.3793 - val_accuracy: 0.8053 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 32/600\n",
            "1042/1042 - 13s - loss: 0.3891 - accuracy: 0.8055 - val_loss: 0.3776 - val_accuracy: 0.8080 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 33/600\n",
            "1042/1042 - 13s - loss: 0.3797 - accuracy: 0.8053 - val_loss: 0.3726 - val_accuracy: 0.8042 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 34/600\n",
            "1042/1042 - 13s - loss: 0.3786 - accuracy: 0.8067 - val_loss: 0.3700 - val_accuracy: 0.8057 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 35/600\n",
            "1042/1042 - 13s - loss: 0.3786 - accuracy: 0.8065 - val_loss: 0.3722 - val_accuracy: 0.8081 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 36/600\n",
            "1042/1042 - 13s - loss: 0.3788 - accuracy: 0.8055 - val_loss: 0.3746 - val_accuracy: 0.8089 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 37/600\n",
            "1042/1042 - 13s - loss: 0.3781 - accuracy: 0.8064 - val_loss: 0.3703 - val_accuracy: 0.8063 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 38/600\n",
            "1042/1042 - 13s - loss: 0.3730 - accuracy: 0.8070 - val_loss: 0.3660 - val_accuracy: 0.8058 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 39/600\n",
            "1042/1042 - 13s - loss: 0.3726 - accuracy: 0.8068 - val_loss: 0.3670 - val_accuracy: 0.8035 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 40/600\n",
            "1042/1042 - 13s - loss: 0.3723 - accuracy: 0.8055 - val_loss: 0.3648 - val_accuracy: 0.8069 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 41/600\n",
            "1042/1042 - 13s - loss: 0.3720 - accuracy: 0.8064 - val_loss: 0.3671 - val_accuracy: 0.8085 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 42/600\n",
            "1042/1042 - 13s - loss: 0.3721 - accuracy: 0.8055 - val_loss: 0.3654 - val_accuracy: 0.8076 - lr: 3.1250e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 43/600\n",
            "1042/1042 - 13s - loss: 0.3717 - accuracy: 0.8053 - val_loss: 0.3662 - val_accuracy: 0.8066 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 44/600\n",
            "1042/1042 - 13s - loss: 0.3688 - accuracy: 0.8061 - val_loss: 0.3625 - val_accuracy: 0.8076 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 45/600\n",
            "1042/1042 - 13s - loss: 0.3684 - accuracy: 0.8065 - val_loss: 0.3630 - val_accuracy: 0.8071 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 46/600\n",
            "1042/1042 - 13s - loss: 0.3683 - accuracy: 0.8063 - val_loss: 0.3631 - val_accuracy: 0.8043 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 47/600\n",
            "1042/1042 - 13s - loss: 0.3680 - accuracy: 0.8069 - val_loss: 0.3622 - val_accuracy: 0.8081 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 48/600\n",
            "1042/1042 - 13s - loss: 0.3682 - accuracy: 0.8065 - val_loss: 0.3619 - val_accuracy: 0.8072 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 49/600\n",
            "1042/1042 - 13s - loss: 0.3677 - accuracy: 0.8063 - val_loss: 0.3635 - val_accuracy: 0.8056 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 50/600\n",
            "1042/1042 - 13s - loss: 0.3676 - accuracy: 0.8065 - val_loss: 0.3618 - val_accuracy: 0.8073 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 51/600\n",
            "1042/1042 - 13s - loss: 0.3675 - accuracy: 0.8052 - val_loss: 0.3631 - val_accuracy: 0.8082 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 52/600\n",
            "1042/1042 - 13s - loss: 0.3675 - accuracy: 0.8066 - val_loss: 0.3630 - val_accuracy: 0.8042 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 53/600\n",
            "1042/1042 - 13s - loss: 0.3671 - accuracy: 0.8072 - val_loss: 0.3630 - val_accuracy: 0.8047 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 54/600\n",
            "1042/1042 - 13s - loss: 0.3659 - accuracy: 0.8067 - val_loss: 0.3605 - val_accuracy: 0.8086 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 55/600\n",
            "1042/1042 - 13s - loss: 0.3657 - accuracy: 0.8054 - val_loss: 0.3605 - val_accuracy: 0.8074 - lr: 7.8125e-05 - 13s/epoch - 13ms/step\n",
            "Epoch 56/600\n",
            "1042/1042 - 13s - loss: 0.3656 - accuracy: 0.8055 - val_loss: 0.3604 - val_accuracy: 0.8078 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 57/600\n",
            "1042/1042 - 13s - loss: 0.3653 - accuracy: 0.8066 - val_loss: 0.3603 - val_accuracy: 0.8038 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 58/600\n",
            "1042/1042 - 13s - loss: 0.3655 - accuracy: 0.8063 - val_loss: 0.3606 - val_accuracy: 0.8064 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 59/600\n",
            "1042/1042 - 13s - loss: 0.3653 - accuracy: 0.8067 - val_loss: 0.3603 - val_accuracy: 0.8047 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 60/600\n",
            "1042/1042 - 13s - loss: 0.3646 - accuracy: 0.8069 - val_loss: 0.3596 - val_accuracy: 0.8060 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 61/600\n",
            "1042/1042 - 13s - loss: 0.3645 - accuracy: 0.8054 - val_loss: 0.3598 - val_accuracy: 0.8070 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 62/600\n",
            "1042/1042 - 13s - loss: 0.3643 - accuracy: 0.8073 - val_loss: 0.3597 - val_accuracy: 0.8056 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 63/600\n",
            "1042/1042 - 13s - loss: 0.3644 - accuracy: 0.8055 - val_loss: 0.3595 - val_accuracy: 0.8068 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 64/600\n",
            "1042/1042 - 13s - loss: 0.3644 - accuracy: 0.8050 - val_loss: 0.3595 - val_accuracy: 0.8047 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 65/600\n",
            "1042/1042 - 13s - loss: 0.3642 - accuracy: 0.8073 - val_loss: 0.3596 - val_accuracy: 0.8038 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 66/600\n",
            "1042/1042 - 13s - loss: 0.3642 - accuracy: 0.8063 - val_loss: 0.3596 - val_accuracy: 0.8060 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 67/600\n",
            "1042/1042 - 13s - loss: 0.3639 - accuracy: 0.8061 - val_loss: 0.3593 - val_accuracy: 0.8040 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 68/600\n",
            "1042/1042 - 13s - loss: 0.3635 - accuracy: 0.8065 - val_loss: 0.3596 - val_accuracy: 0.8052 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 69/600\n",
            "1042/1042 - 13s - loss: 0.3638 - accuracy: 0.8068 - val_loss: 0.3590 - val_accuracy: 0.8081 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 70/600\n",
            "1042/1042 - 13s - loss: 0.3637 - accuracy: 0.8071 - val_loss: 0.3593 - val_accuracy: 0.8044 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 71/600\n",
            "1042/1042 - 13s - loss: 0.3634 - accuracy: 0.8082 - val_loss: 0.3592 - val_accuracy: 0.8087 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 72/600\n",
            "1042/1042 - 13s - loss: 0.3635 - accuracy: 0.8074 - val_loss: 0.3591 - val_accuracy: 0.8073 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 73/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8074 - val_loss: 0.3590 - val_accuracy: 0.8056 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 74/600\n",
            "1042/1042 - 13s - loss: 0.3634 - accuracy: 0.8063 - val_loss: 0.3589 - val_accuracy: 0.8080 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 75/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8073 - val_loss: 0.3589 - val_accuracy: 0.8088 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 76/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8071 - val_loss: 0.3589 - val_accuracy: 0.8049 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 77/600\n",
            "1042/1042 - 13s - loss: 0.3635 - accuracy: 0.8068 - val_loss: 0.3590 - val_accuracy: 0.8056 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 78/600\n",
            "1042/1042 - 13s - loss: 0.3633 - accuracy: 0.8071 - val_loss: 0.3588 - val_accuracy: 0.8070 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 79/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8071 - val_loss: 0.3588 - val_accuracy: 0.8070 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 80/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8071 - val_loss: 0.3588 - val_accuracy: 0.8076 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 81/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8077 - val_loss: 0.3588 - val_accuracy: 0.8074 - lr: 2.4414e-06 - 13s/epoch - 13ms/step\n",
            "Epoch 82/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8068 - val_loss: 0.3588 - val_accuracy: 0.8063 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 83/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8076 - val_loss: 0.3588 - val_accuracy: 0.8068 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 84/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8070 - val_loss: 0.3588 - val_accuracy: 0.8072 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 85/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8072 - val_loss: 0.3588 - val_accuracy: 0.8074 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 86/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8080 - val_loss: 0.3588 - val_accuracy: 0.8074 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 87/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8070 - val_loss: 0.3588 - val_accuracy: 0.8070 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 88/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8078 - val_loss: 0.3588 - val_accuracy: 0.8068 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 89/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8079 - val_loss: 0.3588 - val_accuracy: 0.8066 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 90/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8079 - val_loss: 0.3588 - val_accuracy: 0.8064 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 91/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8078 - val_loss: 0.3588 - val_accuracy: 0.8064 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 92/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8076 - val_loss: 0.3588 - val_accuracy: 0.8064 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 93/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8077 - val_loss: 0.3588 - val_accuracy: 0.8064 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 94/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8074 - val_loss: 0.3588 - val_accuracy: 0.8061 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 95/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8081 - val_loss: 0.3588 - val_accuracy: 0.8061 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 96/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8076 - val_loss: 0.3588 - val_accuracy: 0.8061 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 97/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8065 - val_loss: 0.3588 - val_accuracy: 0.8061 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 98/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8075 - val_loss: 0.3588 - val_accuracy: 0.8064 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 99/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8073 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 100/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8080 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 101/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8070 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 102/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8082 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 103/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8075 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 104/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8073 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 105/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8067 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 106/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8076 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 9.5367e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 107/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8069 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 9.5367e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 108/600\n",
            "1042/1042 - 13s - loss: 0.3631 - accuracy: 0.8073 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 9.5367e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 109/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8078 - val_loss: 0.3588 - val_accuracy: 0.8059 - lr: 4.7684e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 110/600\n",
            "1042/1042 - 13s - loss: 0.3632 - accuracy: 0.8064 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 4.7684e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 111/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8075 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 4.7684e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 112/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8078 - val_loss: 0.3588 - val_accuracy: 0.8062 - lr: 2.3842e-09 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12  9]\n",
            " [14 11  3  2 12  7]\n",
            " [14 11  3  2 12  1]\n",
            " ...\n",
            " [14 11  3  2 12  7]\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12  9]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12  9  7]\n",
            " [14 11  3 ... 12  7  5]\n",
            " [14 11  3 ... 12  1  5]\n",
            " ...\n",
            " [14 11  3 ... 12  7 13]\n",
            " [14 11  3 ... 12 13  1]\n",
            " [14 11  3 ... 12  9  5]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ...  9  7  1]\n",
            " [14 11  3 ...  7  5  1]\n",
            " [14 11  3 ...  1  5  7]\n",
            " ...\n",
            " [14 11  3 ...  7 13  9]\n",
            " [14 11  3 ... 13  1  5]\n",
            " [14 11  3 ...  9  5  1]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ...  7  1  5]\n",
            " [14 11  3 ...  5  1 13]\n",
            " [14 11  3 ...  5  7 13]\n",
            " ...\n",
            " [14 11  3 ... 13  9  1]\n",
            " [14 11  3 ...  1  5  7]\n",
            " [14 11  3 ...  5  1 13]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ...  1  5 13]\n",
            " [14 11  3 ...  1 13  9]\n",
            " [14 11  3 ...  7 13  9]\n",
            " ...\n",
            " [14 11  3 ...  9  1  5]\n",
            " [14 11  3 ...  5  7  9]\n",
            " [14 11  3 ...  1 13  7]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ...  5 13  8]\n",
            " [14 11  3 ... 13  9  8]\n",
            " [14 11  3 ... 13  9  8]\n",
            " ...\n",
            " [14 11  3 ...  1  5  8]\n",
            " [14 11  3 ...  7  9  8]\n",
            " [14 11  3 ... 13  7  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ... 13  8 10]\n",
            " [14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  9  8 10]\n",
            " ...\n",
            " [14 11  3 ...  5  8 10]\n",
            " [14 11  3 ...  9  8 10]\n",
            " [14 11  3 ...  7  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n",
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_50 (Bidirecti  (None, 128)              40960     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_50 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,895\n",
            "Trainable params: 42,895\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/600\n",
            "1042/1042 - 18s - loss: 0.7181 - accuracy: 0.7829 - val_loss: 0.4814 - val_accuracy: 0.8044 - lr: 0.0050 - 18s/epoch - 17ms/step\n",
            "Epoch 2/600\n",
            "1042/1042 - 13s - loss: 0.4797 - accuracy: 0.8068 - val_loss: 0.4458 - val_accuracy: 0.8052 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 3/600\n",
            "1042/1042 - 13s - loss: 0.4630 - accuracy: 0.8050 - val_loss: 0.4472 - val_accuracy: 0.8059 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 4/600\n",
            "1042/1042 - 13s - loss: 0.4538 - accuracy: 0.8068 - val_loss: 0.4427 - val_accuracy: 0.8075 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 5/600\n",
            "1042/1042 - 13s - loss: 0.4500 - accuracy: 0.8061 - val_loss: 0.4351 - val_accuracy: 0.8056 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 6/600\n",
            "1042/1042 - 13s - loss: 0.4474 - accuracy: 0.8067 - val_loss: 0.4418 - val_accuracy: 0.8070 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 7/600\n",
            "1042/1042 - 13s - loss: 0.4824 - accuracy: 0.8046 - val_loss: 0.4344 - val_accuracy: 0.8058 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 8/600\n",
            "1042/1042 - 13s - loss: 0.4423 - accuracy: 0.8059 - val_loss: 0.4233 - val_accuracy: 0.8066 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 9/600\n",
            "1042/1042 - 13s - loss: 0.4399 - accuracy: 0.8060 - val_loss: 0.4222 - val_accuracy: 0.8080 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 10/600\n",
            "1042/1042 - 13s - loss: 0.4417 - accuracy: 0.8056 - val_loss: 0.4319 - val_accuracy: 0.8082 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 11/600\n",
            "1042/1042 - 13s - loss: 0.4786 - accuracy: 0.8048 - val_loss: 0.4944 - val_accuracy: 0.8069 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 12/600\n",
            "1042/1042 - 13s - loss: 0.4493 - accuracy: 0.8075 - val_loss: 0.4261 - val_accuracy: 0.8054 - lr: 0.0050 - 13s/epoch - 12ms/step\n",
            "Epoch 13/600\n",
            "1042/1042 - 13s - loss: 0.4127 - accuracy: 0.8057 - val_loss: 0.4003 - val_accuracy: 0.8057 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 14/600\n",
            "1042/1042 - 13s - loss: 0.4112 - accuracy: 0.8073 - val_loss: 0.3940 - val_accuracy: 0.8078 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 15/600\n",
            "1042/1042 - 12s - loss: 0.4104 - accuracy: 0.8064 - val_loss: 0.3984 - val_accuracy: 0.8040 - lr: 0.0025 - 12s/epoch - 12ms/step\n",
            "Epoch 16/600\n",
            "1042/1042 - 13s - loss: 0.4096 - accuracy: 0.8053 - val_loss: 0.4036 - val_accuracy: 0.8064 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 17/600\n",
            "1042/1042 - 13s - loss: 0.4097 - accuracy: 0.8062 - val_loss: 0.3952 - val_accuracy: 0.8062 - lr: 0.0025 - 13s/epoch - 12ms/step\n",
            "Epoch 18/600\n",
            "1042/1042 - 13s - loss: 0.3937 - accuracy: 0.8057 - val_loss: 0.3874 - val_accuracy: 0.8056 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 19/600\n",
            "1042/1042 - 13s - loss: 0.3929 - accuracy: 0.8053 - val_loss: 0.3800 - val_accuracy: 0.8072 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 20/600\n",
            "1042/1042 - 13s - loss: 0.3915 - accuracy: 0.8056 - val_loss: 0.3817 - val_accuracy: 0.8048 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 21/600\n",
            "1042/1042 - 13s - loss: 0.3911 - accuracy: 0.8061 - val_loss: 0.3838 - val_accuracy: 0.8069 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 22/600\n",
            "1042/1042 - 13s - loss: 0.3912 - accuracy: 0.8060 - val_loss: 0.3786 - val_accuracy: 0.8066 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 23/600\n",
            "1042/1042 - 13s - loss: 0.3905 - accuracy: 0.8061 - val_loss: 0.3815 - val_accuracy: 0.8075 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 24/600\n",
            "1042/1042 - 13s - loss: 0.3899 - accuracy: 0.8067 - val_loss: 0.3805 - val_accuracy: 0.8070 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 25/600\n",
            "1042/1042 - 13s - loss: 0.3900 - accuracy: 0.8065 - val_loss: 0.3798 - val_accuracy: 0.8084 - lr: 0.0012 - 13s/epoch - 12ms/step\n",
            "Epoch 26/600\n",
            "1042/1042 - 13s - loss: 0.3803 - accuracy: 0.8067 - val_loss: 0.3731 - val_accuracy: 0.8076 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 27/600\n",
            "1042/1042 - 13s - loss: 0.3793 - accuracy: 0.8069 - val_loss: 0.3731 - val_accuracy: 0.8073 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 28/600\n",
            "1042/1042 - 13s - loss: 0.3795 - accuracy: 0.8068 - val_loss: 0.3706 - val_accuracy: 0.8075 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 29/600\n",
            "1042/1042 - 13s - loss: 0.3785 - accuracy: 0.8064 - val_loss: 0.3703 - val_accuracy: 0.8079 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 30/600\n",
            "1042/1042 - 13s - loss: 0.3788 - accuracy: 0.8060 - val_loss: 0.3720 - val_accuracy: 0.8054 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 31/600\n",
            "1042/1042 - 13s - loss: 0.3783 - accuracy: 0.8056 - val_loss: 0.3712 - val_accuracy: 0.8065 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 32/600\n",
            "1042/1042 - 13s - loss: 0.3779 - accuracy: 0.8065 - val_loss: 0.3685 - val_accuracy: 0.8063 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 33/600\n",
            "1042/1042 - 13s - loss: 0.3778 - accuracy: 0.8052 - val_loss: 0.3704 - val_accuracy: 0.8069 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 34/600\n",
            "1042/1042 - 13s - loss: 0.3781 - accuracy: 0.8060 - val_loss: 0.3701 - val_accuracy: 0.8062 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 35/600\n",
            "1042/1042 - 13s - loss: 0.3774 - accuracy: 0.8057 - val_loss: 0.3708 - val_accuracy: 0.8067 - lr: 6.2500e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 36/600\n",
            "1042/1042 - 13s - loss: 0.3717 - accuracy: 0.8077 - val_loss: 0.3657 - val_accuracy: 0.8038 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 37/600\n",
            "1042/1042 - 13s - loss: 0.3717 - accuracy: 0.8063 - val_loss: 0.3683 - val_accuracy: 0.8055 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 38/600\n",
            "1042/1042 - 13s - loss: 0.3713 - accuracy: 0.8069 - val_loss: 0.3646 - val_accuracy: 0.8088 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 39/600\n",
            "1042/1042 - 13s - loss: 0.3712 - accuracy: 0.8059 - val_loss: 0.3658 - val_accuracy: 0.8085 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 40/600\n",
            "1042/1042 - 13s - loss: 0.3710 - accuracy: 0.8064 - val_loss: 0.3647 - val_accuracy: 0.8060 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 41/600\n",
            "1042/1042 - 13s - loss: 0.3705 - accuracy: 0.8071 - val_loss: 0.3644 - val_accuracy: 0.8057 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 42/600\n",
            "1042/1042 - 13s - loss: 0.3706 - accuracy: 0.8075 - val_loss: 0.3650 - val_accuracy: 0.8084 - lr: 3.1250e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 43/600\n",
            "1042/1042 - 13s - loss: 0.3709 - accuracy: 0.8065 - val_loss: 0.3692 - val_accuracy: 0.8055 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 44/600\n",
            "1042/1042 - 13s - loss: 0.3706 - accuracy: 0.8057 - val_loss: 0.3643 - val_accuracy: 0.8061 - lr: 3.1250e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 45/600\n",
            "1042/1042 - 13s - loss: 0.3673 - accuracy: 0.8061 - val_loss: 0.3641 - val_accuracy: 0.8055 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 46/600\n",
            "1042/1042 - 13s - loss: 0.3673 - accuracy: 0.8069 - val_loss: 0.3630 - val_accuracy: 0.8061 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 47/600\n",
            "1042/1042 - 13s - loss: 0.3668 - accuracy: 0.8069 - val_loss: 0.3617 - val_accuracy: 0.8065 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 48/600\n",
            "1042/1042 - 13s - loss: 0.3669 - accuracy: 0.8061 - val_loss: 0.3616 - val_accuracy: 0.8050 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 49/600\n",
            "1042/1042 - 13s - loss: 0.3668 - accuracy: 0.8057 - val_loss: 0.3623 - val_accuracy: 0.8037 - lr: 1.5625e-04 - 13s/epoch - 13ms/step\n",
            "Epoch 50/600\n",
            "1042/1042 - 13s - loss: 0.3664 - accuracy: 0.8070 - val_loss: 0.3612 - val_accuracy: 0.8076 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 51/600\n",
            "1042/1042 - 13s - loss: 0.3665 - accuracy: 0.8073 - val_loss: 0.3628 - val_accuracy: 0.8047 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 52/600\n",
            "1042/1042 - 13s - loss: 0.3663 - accuracy: 0.8072 - val_loss: 0.3614 - val_accuracy: 0.8075 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 53/600\n",
            "1042/1042 - 13s - loss: 0.3663 - accuracy: 0.8053 - val_loss: 0.3611 - val_accuracy: 0.8065 - lr: 1.5625e-04 - 13s/epoch - 12ms/step\n",
            "Epoch 54/600\n",
            "1042/1042 - 13s - loss: 0.3648 - accuracy: 0.8061 - val_loss: 0.3605 - val_accuracy: 0.8041 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 55/600\n",
            "1042/1042 - 13s - loss: 0.3645 - accuracy: 0.8069 - val_loss: 0.3603 - val_accuracy: 0.8076 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 56/600\n",
            "1042/1042 - 13s - loss: 0.3644 - accuracy: 0.8067 - val_loss: 0.3608 - val_accuracy: 0.8044 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 57/600\n",
            "1042/1042 - 13s - loss: 0.3642 - accuracy: 0.8079 - val_loss: 0.3599 - val_accuracy: 0.8086 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 58/600\n",
            "1042/1042 - 13s - loss: 0.3642 - accuracy: 0.8078 - val_loss: 0.3597 - val_accuracy: 0.8086 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 59/600\n",
            "1042/1042 - 13s - loss: 0.3643 - accuracy: 0.8069 - val_loss: 0.3597 - val_accuracy: 0.8081 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 60/600\n",
            "1042/1042 - 13s - loss: 0.3641 - accuracy: 0.8067 - val_loss: 0.3594 - val_accuracy: 0.8050 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 61/600\n",
            "1042/1042 - 13s - loss: 0.3639 - accuracy: 0.8069 - val_loss: 0.3601 - val_accuracy: 0.8079 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 62/600\n",
            "1042/1042 - 13s - loss: 0.3642 - accuracy: 0.8068 - val_loss: 0.3601 - val_accuracy: 0.8063 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 63/600\n",
            "1042/1042 - 13s - loss: 0.3639 - accuracy: 0.8068 - val_loss: 0.3604 - val_accuracy: 0.8090 - lr: 7.8125e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 64/600\n",
            "1042/1042 - 13s - loss: 0.3630 - accuracy: 0.8075 - val_loss: 0.3589 - val_accuracy: 0.8070 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 65/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8068 - val_loss: 0.3595 - val_accuracy: 0.8060 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 66/600\n",
            "1042/1042 - 13s - loss: 0.3629 - accuracy: 0.8068 - val_loss: 0.3589 - val_accuracy: 0.8068 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 67/600\n",
            "1042/1042 - 13s - loss: 0.3628 - accuracy: 0.8063 - val_loss: 0.3589 - val_accuracy: 0.8073 - lr: 3.9062e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 68/600\n",
            "1042/1042 - 13s - loss: 0.3625 - accuracy: 0.8068 - val_loss: 0.3588 - val_accuracy: 0.8053 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 69/600\n",
            "1042/1042 - 13s - loss: 0.3624 - accuracy: 0.8064 - val_loss: 0.3587 - val_accuracy: 0.8081 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 70/600\n",
            "1042/1042 - 13s - loss: 0.3623 - accuracy: 0.8080 - val_loss: 0.3585 - val_accuracy: 0.8058 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 71/600\n",
            "1042/1042 - 13s - loss: 0.3623 - accuracy: 0.8065 - val_loss: 0.3585 - val_accuracy: 0.8066 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 72/600\n",
            "1042/1042 - 13s - loss: 0.3623 - accuracy: 0.8066 - val_loss: 0.3584 - val_accuracy: 0.8079 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 73/600\n",
            "1042/1042 - 13s - loss: 0.3623 - accuracy: 0.8072 - val_loss: 0.3584 - val_accuracy: 0.8067 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 74/600\n",
            "1042/1042 - 13s - loss: 0.3621 - accuracy: 0.8092 - val_loss: 0.3585 - val_accuracy: 0.8062 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 75/600\n",
            "1042/1042 - 13s - loss: 0.3621 - accuracy: 0.8079 - val_loss: 0.3586 - val_accuracy: 0.8049 - lr: 1.9531e-05 - 13s/epoch - 12ms/step\n",
            "Epoch 76/600\n",
            "1042/1042 - 13s - loss: 0.3620 - accuracy: 0.8074 - val_loss: 0.3583 - val_accuracy: 0.8058 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 77/600\n",
            "1042/1042 - 13s - loss: 0.3618 - accuracy: 0.8086 - val_loss: 0.3583 - val_accuracy: 0.8049 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 78/600\n",
            "1042/1042 - 13s - loss: 0.3619 - accuracy: 0.8067 - val_loss: 0.3582 - val_accuracy: 0.8082 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 79/600\n",
            "1042/1042 - 13s - loss: 0.3619 - accuracy: 0.8077 - val_loss: 0.3583 - val_accuracy: 0.8066 - lr: 9.7656e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 80/600\n",
            "1042/1042 - 13s - loss: 0.3620 - accuracy: 0.8079 - val_loss: 0.3582 - val_accuracy: 0.8058 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 81/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8086 - val_loss: 0.3582 - val_accuracy: 0.8076 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 82/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8079 - val_loss: 0.3582 - val_accuracy: 0.8051 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 83/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8084 - val_loss: 0.3582 - val_accuracy: 0.8057 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 84/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8082 - val_loss: 0.3582 - val_accuracy: 0.8053 - lr: 4.8828e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 85/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8068 - val_loss: 0.3581 - val_accuracy: 0.8079 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 86/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8076 - val_loss: 0.3581 - val_accuracy: 0.8056 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 87/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8075 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 2.4414e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 88/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8064 - val_loss: 0.3581 - val_accuracy: 0.8078 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 89/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8066 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 90/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8081 - val_loss: 0.3581 - val_accuracy: 0.8072 - lr: 1.2207e-06 - 13s/epoch - 12ms/step\n",
            "Epoch 91/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8079 - val_loss: 0.3581 - val_accuracy: 0.8072 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 92/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8082 - val_loss: 0.3581 - val_accuracy: 0.8074 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 93/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8074 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 6.1035e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 94/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8078 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 95/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8084 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 96/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8071 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 3.0518e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 97/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8074 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 98/600\n",
            "1042/1042 - 13s - loss: 0.3615 - accuracy: 0.8076 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 99/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8067 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 1.5259e-07 - 13s/epoch - 12ms/step\n",
            "Epoch 100/600\n",
            "1042/1042 - 13s - loss: 0.3615 - accuracy: 0.8092 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 101/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8087 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 102/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8083 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 7.6294e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 103/600\n",
            "1042/1042 - 13s - loss: 0.3615 - accuracy: 0.8089 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 104/600\n",
            "1042/1042 - 13s - loss: 0.3615 - accuracy: 0.8084 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 105/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8073 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 3.8147e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 106/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8069 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 107/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8087 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 108/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8074 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 1.9073e-08 - 13s/epoch - 12ms/step\n",
            "Epoch 109/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8082 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 9.5367e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 110/600\n",
            "1042/1042 - 13s - loss: 0.3615 - accuracy: 0.8092 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 9.5367e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 111/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8080 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 9.5367e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 112/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8071 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 4.7684e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 113/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8086 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 4.7684e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 114/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8071 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 4.7684e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 115/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8079 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 2.3842e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 116/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8077 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 2.3842e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 117/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8077 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 2.3842e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 118/600\n",
            "1042/1042 - 13s - loss: 0.3616 - accuracy: 0.8079 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 1.1921e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 119/600\n",
            "1042/1042 - 13s - loss: 0.3617 - accuracy: 0.8071 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 1.1921e-09 - 13s/epoch - 12ms/step\n",
            "Epoch 120/600\n",
            "1042/1042 - 13s - loss: 0.3615 - accuracy: 0.8082 - val_loss: 0.3581 - val_accuracy: 0.8080 - lr: 1.1921e-09 - 13s/epoch - 12ms/step\n",
            "[[14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " ...\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]\n",
            " [14  0  0 ...  0  0  0]]\n",
            "finding activity nr 2\n",
            "[[14]\n",
            " [14]\n",
            " [14]\n",
            " ...\n",
            " [14]\n",
            " [14]\n",
            " [14]]\n",
            "finding activity nr 3\n",
            "[[14 11]\n",
            " [14 11]\n",
            " [14 11]\n",
            " ...\n",
            " [14 11]\n",
            " [14 11]\n",
            " [14 11]]\n",
            "finding activity nr 4\n",
            "[[14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " ...\n",
            " [14 11  3]\n",
            " [14 11  3]\n",
            " [14 11  3]]\n",
            "finding activity nr 5\n",
            "[[14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " ...\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]\n",
            " [14 11  3  2]]\n",
            "finding activity nr 6\n",
            "[[14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " ...\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]\n",
            " [14 11  3  2 12]]\n",
            "finding activity nr 7\n",
            "[[14 11  3  2 12  5]\n",
            " [14 11  3  2 12  5]\n",
            " [14 11  3  2 12 13]\n",
            " ...\n",
            " [14 11  3  2 12 13]\n",
            " [14 11  3  2 12  9]\n",
            " [14 11  3  2 12 13]]\n",
            "finding activity nr 8\n",
            "[[14 11  3 ... 12  5  7]\n",
            " [14 11  3 ... 12  5 13]\n",
            " [14 11  3 ... 12 13  1]\n",
            " ...\n",
            " [14 11  3 ... 12 13  9]\n",
            " [14 11  3 ... 12  9  5]\n",
            " [14 11  3 ... 12 13  7]]\n",
            "finding activity nr 9\n",
            "[[14 11  3 ...  5  7  1]\n",
            " [14 11  3 ...  5 13  1]\n",
            " [14 11  3 ... 13  1  5]\n",
            " ...\n",
            " [14 11  3 ... 13  9  7]\n",
            " [14 11  3 ...  9  5  1]\n",
            " [14 11  3 ... 13  7  9]]\n",
            "finding activity nr 10\n",
            "[[14 11  3 ...  7  1  9]\n",
            " [14 11  3 ... 13  1  9]\n",
            " [14 11  3 ...  1  5  7]\n",
            " ...\n",
            " [14 11  3 ...  9  7  1]\n",
            " [14 11  3 ...  5  1  7]\n",
            " [14 11  3 ...  7  9  1]]\n",
            "finding activity nr 11\n",
            "[[14 11  3 ...  1  9 13]\n",
            " [14 11  3 ...  1  9  7]\n",
            " [14 11  3 ...  5  7  9]\n",
            " ...\n",
            " [14 11  3 ...  7  1  5]\n",
            " [14 11  3 ...  1  7 13]\n",
            " [14 11  3 ...  9  1  5]]\n",
            "finding activity nr 12\n",
            "[[14 11  3 ...  9 13  8]\n",
            " [14 11  3 ...  9  7  8]\n",
            " [14 11  3 ...  7  9  8]\n",
            " ...\n",
            " [14 11  3 ...  1  5  8]\n",
            " [14 11  3 ...  7 13  8]\n",
            " [14 11  3 ...  1  5  8]]\n",
            "finding activity nr 13\n",
            "[[14 11  3 ... 13  8 10]\n",
            " [14 11  3 ...  7  8 10]\n",
            " [14 11  3 ...  9  8 10]\n",
            " ...\n",
            " [14 11  3 ...  5  8 10]\n",
            " [14 11  3 ... 13  8 10]\n",
            " [14 11  3 ...  5  8 10]]\n",
            "finding activity nr 14\n",
            "[[14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " ...\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]\n",
            " [14 11  3 ...  8 10  6]]\n",
            "finding activity nr 15\n",
            "[[14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " ...\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]\n",
            " [14 11  3 ... 10  6  4]]\n",
            "[[14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " ...\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]\n",
            " [14 11  3 ...  6  4 15]]\n",
            "(12000, 15)\n"
          ]
        }
      ],
      "source": [
        "do_experiment('Model1', False, 6, 120)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Exp_Model1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}